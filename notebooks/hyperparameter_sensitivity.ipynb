{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Importing our custom module(s)\n",
    "import losses\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# PyTorch\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(path):\n",
    "    df = pd.read_csv(path, index_col='Unnamed: 0')\n",
    "    return df\n",
    "\n",
    "def get_val_nll(df):\n",
    "    return df.val_or_test_nll.values[-1]\n",
    "\n",
    "def get_val_acc1(df):\n",
    "    if 'val_or_test_acc' in df.columns:\n",
    "        return df.val_or_test_acc.values[-1] if df.val_or_test_acc.values[-1] < 1 else df.val_or_test_acc.values[-1]/100\n",
    "    elif 'val_or_test_acc1' in df.columns:\n",
    "        return df.val_or_test_acc1.values[-1] if df.val_or_test_acc1.values[-1] < 1 else df.val_or_test_acc1.values[-1]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_hyperparams(\n",
    "    bb_weight_decays, \n",
    "    clf_weight_decays, \n",
    "    experiments_path, # Gets best hyperparameters from experiments_path\n",
    "    lr_0s, \n",
    "    ns, \n",
    "    prior_type, # Gets best hyperparameters for a single prior_type\n",
    "    random_states, \n",
    "    weight_decays\n",
    "):\n",
    "    hyperparam_names = ['bb_weight_decay', 'clf_weight_decay', 'lr_0', 'n', 'random_state', 'weight_decay']\n",
    "    columns = ['model_name', 'n', 'prior_type', 'random_state', 'val_acc1', 'val_nll']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for hyperparams in itertools.product(bb_weight_decays, clf_weight_decays, lr_0s, ns, random_states, weight_decays):\n",
    "        model_name = f'{prior_type}_' + '_'.join(f'{hyperparam_name}={hyperparam}' for hyperparam_name, hyperparam in zip(hyperparam_names, hyperparams) if hyperparam is not None)\n",
    "        bb_weight_decay, clf_weight_decay, lr_0, n, random_state, weight_decay = hyperparams\n",
    "        if not os.path.exists(f'{experiments_path}/{model_name}.csv'):\n",
    "            print(model_name)\n",
    "            pass\n",
    "        else:\n",
    "            temp_df = get_df(f'{experiments_path}/{model_name}.csv')\n",
    "            val_acc1 = get_val_acc1(temp_df)\n",
    "            val_nll = get_val_nll(temp_df)\n",
    "            df.loc[df.shape[0]] = [model_name, n, prior_type, random_state, val_acc1, val_nll]\n",
    "    \n",
    "    df['rank_value'] = df.groupby(['n', 'random_state'])['val_nll'].rank()\n",
    "    df = df[(df['rank_value'] <= 3)|(df['rank_value'] == df['rank_value'].max()/4)|(df['rank_value'] == df['rank_value'].max()/2)].reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_results(\n",
    "    df,\n",
    "    experiments_path\n",
    "):\n",
    "    columns = ['model_name', 'n', 'prior_type', 'random_state', 'rank_value', 'test_acc1', 'test_nll']\n",
    "    results_df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for row_index, row in df.iterrows():\n",
    "        model_name = row.model_name\n",
    "        prior_type, n, random_state = row.prior_type, row.n, row.random_state\n",
    "        if not os.path.exists(f'{experiments_path}/{model_name}.csv'):\n",
    "            #print(model_name)\n",
    "            pass\n",
    "        else:\n",
    "            temp_df = get_df(f'{experiments_path}/{model_name}.csv')\n",
    "            test_acc1 = get_val_acc1(temp_df)\n",
    "            test_nll = get_val_nll(temp_df)\n",
    "            results_df.loc[results_df.shape[0]] = [model_name, n, prior_type, random_state, row.rank_value, test_acc1, test_nll]\n",
    "                \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>random_state</th>\n",
       "      <th>val_acc1</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>rank_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nonlearned_lr_0=0.01_n=1000_random_state=1001_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.697320</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nonlearned_lr_0=0.01_n=1000_random_state=2001_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.803543</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nonlearned_lr_0=0.01_n=1000_random_state=2001_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.916837</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nonlearned_lr_0=0.01_n=1000_random_state=3001_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.434508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nonlearned_lr_0=0.01_n=1000_random_state=3001_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.472507</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nonlearned_lr_0=0.01_n=1000_random_state=3001_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.519339</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nonlearned_lr_0=0.001_n=1000_random_state=1001...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.841034</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nonlearned_lr_0=0.001_n=1000_random_state=3001...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.621079</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=100...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.725388</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=100...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.670592</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=100...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.730266</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=200...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.825210</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=200...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.854257</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=200...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.822878</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=300...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.586080</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_name     n  prior_type  \\\n",
       "0   nonlearned_lr_0=0.01_n=1000_random_state=1001_...  1000  nonlearned   \n",
       "1   nonlearned_lr_0=0.01_n=1000_random_state=2001_...  1000  nonlearned   \n",
       "2   nonlearned_lr_0=0.01_n=1000_random_state=2001_...  1000  nonlearned   \n",
       "3   nonlearned_lr_0=0.01_n=1000_random_state=3001_...  1000  nonlearned   \n",
       "4   nonlearned_lr_0=0.01_n=1000_random_state=3001_...  1000  nonlearned   \n",
       "5   nonlearned_lr_0=0.01_n=1000_random_state=3001_...  1000  nonlearned   \n",
       "6   nonlearned_lr_0=0.001_n=1000_random_state=1001...  1000  nonlearned   \n",
       "7   nonlearned_lr_0=0.001_n=1000_random_state=3001...  1000  nonlearned   \n",
       "8   nonlearned_lr_0=0.0001_n=1000_random_state=100...  1000  nonlearned   \n",
       "9   nonlearned_lr_0=0.0001_n=1000_random_state=100...  1000  nonlearned   \n",
       "10  nonlearned_lr_0=0.0001_n=1000_random_state=100...  1000  nonlearned   \n",
       "11  nonlearned_lr_0=0.0001_n=1000_random_state=200...  1000  nonlearned   \n",
       "12  nonlearned_lr_0=0.0001_n=1000_random_state=200...  1000  nonlearned   \n",
       "13  nonlearned_lr_0=0.0001_n=1000_random_state=200...  1000  nonlearned   \n",
       "14  nonlearned_lr_0=0.0001_n=1000_random_state=300...  1000  nonlearned   \n",
       "\n",
       "    random_state  val_acc1   val_nll  rank_value  \n",
       "0           1001     0.770  0.697320         2.0  \n",
       "1           2001     0.820  0.803543         1.0  \n",
       "2           2001     0.805  0.916837        12.0  \n",
       "3           3001     0.865  0.434508         1.0  \n",
       "4           3001     0.865  0.472507         2.0  \n",
       "5           3001     0.875  0.519339         3.0  \n",
       "6           1001     0.765  0.841034        12.0  \n",
       "7           3001     0.840  0.621079        12.0  \n",
       "8           1001     0.740  0.725388         3.0  \n",
       "9           1001     0.755  0.670592         1.0  \n",
       "10          1001     0.760  0.730266         6.0  \n",
       "11          2001     0.735  0.825210         3.0  \n",
       "12          2001     0.725  0.854257         6.0  \n",
       "13          2001     0.750  0.822878         2.0  \n",
       "14          3001     0.805  0.586080         6.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/tuned_CIFAR-10'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [1000]\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "prior_type = 'nonlearned'\n",
    "random_states = [1001, 2001, 3001]\n",
    "wandb_project = 'tuned_C'\n",
    "weight_decays = [0.01, 0.001, 0.0001, 1e-05, 1e-06, 0.0]\n",
    "\n",
    "std_prior = get_best_hyperparams([None], [None], experiments_path, lr_0s, ns, prior_type, random_states, weight_decays)\n",
    "std_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_CIFAR-10'\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "wandb_project = 'retrained_C'\n",
    "\n",
    "pattern = re.compile(r'(\\w+)_lr_0=([\\d.]+)_n=(\\d+)_random_state=(\\d+)_weight_decay=([\\d.]+(?:e[-+]?\\d+)?)')\n",
    "for row_index, row in std_prior.iterrows():\n",
    "    model_name = row.model_name\n",
    "    match = pattern.match(model_name)\n",
    "    prior_type, lr_0, n, random_state, weight_decay = match.groups()\n",
    "    if not os.path.exists(f'{experiments_path}/{model_name}.csv'):\n",
    "        print(f'    \"python ../src/main_CIFAR-10.py --bb_weight_decay={weight_decay} --clf_weight_decay={weight_decay} --dataset_path=\\'{dataset_path}\\' --experiments_path=\\'{experiments_path}\\' --lr_0={lr_0} --n={n} --model_name=\\'{model_name}\\' --prior_path=\\'{prior_path}\\' --prior_type=\\'{prior_type}\\' --random_state={random_state} --save --wandb --wandb_project=\\'{wandb_project}\\'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>random_state</th>\n",
       "      <th>val_acc1</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>rank_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adapted_lr_0=0.1_n=1000_random_state=1001_weig...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.523390</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adapted_lr_0=0.1_n=1000_random_state=2001_weig...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.667335</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=1001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.579450</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=1001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.605200</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=2001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.765132</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=2001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=2001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.766194</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=3001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.464546</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=3001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.411353</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=3001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.441444</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=3001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.392827</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>adapted_lr_0=0.001_n=1000_random_state=1001_we...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.768309</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>adapted_lr_0=0.0001_n=1000_random_state=1001_w...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.704458</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>adapted_lr_0=0.0001_n=1000_random_state=2001_w...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.832395</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adapted_lr_0=0.0001_n=1000_random_state=3001_w...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.603384</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_name     n prior_type  \\\n",
       "0   adapted_lr_0=0.1_n=1000_random_state=1001_weig...  1000    adapted   \n",
       "1   adapted_lr_0=0.1_n=1000_random_state=2001_weig...  1000    adapted   \n",
       "2   adapted_lr_0=0.01_n=1000_random_state=1001_wei...  1000    adapted   \n",
       "3   adapted_lr_0=0.01_n=1000_random_state=1001_wei...  1000    adapted   \n",
       "4   adapted_lr_0=0.01_n=1000_random_state=2001_wei...  1000    adapted   \n",
       "5   adapted_lr_0=0.01_n=1000_random_state=2001_wei...  1000    adapted   \n",
       "6   adapted_lr_0=0.01_n=1000_random_state=2001_wei...  1000    adapted   \n",
       "7   adapted_lr_0=0.01_n=1000_random_state=3001_wei...  1000    adapted   \n",
       "8   adapted_lr_0=0.01_n=1000_random_state=3001_wei...  1000    adapted   \n",
       "9   adapted_lr_0=0.01_n=1000_random_state=3001_wei...  1000    adapted   \n",
       "10  adapted_lr_0=0.01_n=1000_random_state=3001_wei...  1000    adapted   \n",
       "11  adapted_lr_0=0.001_n=1000_random_state=1001_we...  1000    adapted   \n",
       "12  adapted_lr_0=0.0001_n=1000_random_state=1001_w...  1000    adapted   \n",
       "13  adapted_lr_0=0.0001_n=1000_random_state=2001_w...  1000    adapted   \n",
       "14  adapted_lr_0=0.0001_n=1000_random_state=3001_w...  1000    adapted   \n",
       "\n",
       "    random_state  val_acc1   val_nll  rank_value  \n",
       "0           1001     0.835  0.523390         1.0  \n",
       "1           2001     0.815  0.667335         1.0  \n",
       "2           1001     0.850  0.579450         2.0  \n",
       "3           1001     0.825  0.605200         3.0  \n",
       "4           2001     0.805  0.765132         2.0  \n",
       "5           2001     0.835  0.877337        12.0  \n",
       "6           2001     0.850  0.766194         3.0  \n",
       "7           3001     0.855  0.464546         6.0  \n",
       "8           3001     0.885  0.411353         2.0  \n",
       "9           3001     0.885  0.441444         3.0  \n",
       "10          3001     0.910  0.392827         1.0  \n",
       "11          1001     0.770  0.768309        12.0  \n",
       "12          1001     0.765  0.704458         6.0  \n",
       "13          2001     0.740  0.832395         6.0  \n",
       "14          3001     0.805  0.603384        12.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/tuned_CIFAR-10'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [1000]\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "prior_type = 'adapted'\n",
    "random_states = [1001, 2001, 3001]\n",
    "wandb_project = 'tuned_C'\n",
    "weight_decays = [0.01, 0.001, 0.0001, 1e-05, 1e-06, 0.0]\n",
    "\n",
    "learned_prior_iso = get_best_hyperparams([None], [None], experiments_path, lr_0s, ns, prior_type, random_states, weight_decays)\n",
    "learned_prior_iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_CIFAR-10'\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "wandb_project = 'retrained_C'\n",
    "\n",
    "pattern = re.compile(r'(\\w+)_lr_0=([\\d.]+)_n=(\\d+)_random_state=(\\d+)_weight_decay=([\\d.]+(?:e[-+]?\\d+)?)')\n",
    "for row_index, row in learned_prior_iso.iterrows():\n",
    "    model_name = row.model_name\n",
    "    match = pattern.match(model_name)\n",
    "    prior_type, lr_0, n, random_state, weight_decay = match.groups()\n",
    "    if not os.path.exists(f'{experiments_path}/{model_name}.csv'):\n",
    "        print(f'    \"python ../src/main_CIFAR-10.py --bb_weight_decay={weight_decay} --clf_weight_decay={weight_decay} --dataset_path=\\'{dataset_path}\\' --experiments_path=\\'{experiments_path}\\' --lr_0={lr_0} --n={n} --model_name=\\'{model_name}\\' --prior_path=\\'{prior_path}\\' --prior_type=\\'{prior_type}\\' --random_state={random_state} --save --wandb --wandb_project=\\'{wandb_project}\\'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>random_state</th>\n",
       "      <th>val_acc1</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>rank_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=10.0_clf_weight...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.624078</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=10.0_clf_weight...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.299455</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=10.0_clf_weight...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.499381</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.609634</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.300820</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.333704</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.859697</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.436516</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=1000.0_clf_weig...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.822845</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=10000.0_clf_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.440524</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=10000.0_clf_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.666217</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100000.0_clf_we...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.638589</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100000000.0_clf...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.584899</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=1000000000.0_cl...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.712171</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_name     n      prior_type  \\\n",
       "0   LearnedPriorLR_bb_weight_decay=10.0_clf_weight...  1000  LearnedPriorLR   \n",
       "1   LearnedPriorLR_bb_weight_decay=10.0_clf_weight...  1000  LearnedPriorLR   \n",
       "2   LearnedPriorLR_bb_weight_decay=10.0_clf_weight...  1000  LearnedPriorLR   \n",
       "3   LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...  1000  LearnedPriorLR   \n",
       "4   LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...  1000  LearnedPriorLR   \n",
       "5   LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...  1000  LearnedPriorLR   \n",
       "6   LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...  1000  LearnedPriorLR   \n",
       "7   LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...  1000  LearnedPriorLR   \n",
       "8   LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...  1000  LearnedPriorLR   \n",
       "9   LearnedPriorLR_bb_weight_decay=1000.0_clf_weig...  1000  LearnedPriorLR   \n",
       "10  LearnedPriorLR_bb_weight_decay=10000.0_clf_wei...  1000  LearnedPriorLR   \n",
       "11  LearnedPriorLR_bb_weight_decay=10000.0_clf_wei...  1000  LearnedPriorLR   \n",
       "12  LearnedPriorLR_bb_weight_decay=100000.0_clf_we...  1000  LearnedPriorLR   \n",
       "13  LearnedPriorLR_bb_weight_decay=100000000.0_clf...  1000  LearnedPriorLR   \n",
       "14  LearnedPriorLR_bb_weight_decay=1000000000.0_cl...  1000  LearnedPriorLR   \n",
       "\n",
       "    random_state  val_acc1   val_nll  rank_value  \n",
       "0           2001     0.810  0.624078         2.0  \n",
       "1           3001     0.895  0.299455         1.0  \n",
       "2           1001     0.860  0.499381         3.0  \n",
       "3           1001     0.860  0.455539         2.0  \n",
       "4           2001     0.830  0.609634         1.0  \n",
       "5           3001     0.925  0.300820         2.0  \n",
       "6           3001     0.900  0.333704         3.0  \n",
       "7           2001     0.810  0.859697       120.0  \n",
       "8           1001     0.875  0.436516         1.0  \n",
       "9           2001     0.725  0.822845        60.0  \n",
       "10          3001     0.890  0.440524        60.0  \n",
       "11          1001     0.770  0.666217        60.0  \n",
       "12          2001     0.815  0.638589         3.0  \n",
       "13          3001     0.830  0.584899       120.0  \n",
       "14          1001     0.830  0.712171       120.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_weight_decays = np.logspace(0, 9, num=10)\n",
    "clf_weight_decays = [0.01, 0.001, 0.0001, 1e-05, 1e-06, 0.0]\n",
    "dataset_path = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/tuned_CIFAR-10'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [1000]\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "prior_type = 'LearnedPriorLR'\n",
    "random_states = [1001, 2001, 3001]\n",
    "wandb_project = 'tuned_C'\n",
    "\n",
    "learned_prior_lr = get_best_hyperparams(bb_weight_decays, clf_weight_decays, experiments_path, lr_0s, ns, prior_type, random_states, [None])\n",
    "learned_prior_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_CIFAR-10'\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "wandb_project = 'retrained_C'\n",
    "\n",
    "pattern = re.compile(r'(\\w+)_bb_weight_decay=([\\d.]+)_clf_weight_decay=([\\d.]+(?:e[-+]?\\d+)?)_lr_0=([\\d.]+)_n=(\\d+)_random_state=(\\d+)')\n",
    "for row_index, row in learned_prior_lr.iterrows():\n",
    "    model_name = row.model_name\n",
    "    match = pattern.match(model_name)\n",
    "    prior_type, bb_weight_decay, clf_weight_decay, lr_0, n, random_state = match.groups()\n",
    "    if not os.path.exists(f'{experiments_path}/{model_name}.csv'):\n",
    "        print(f'    \"python ../src/main_CIFAR-10.py --bb_weight_decay={bb_weight_decay} --clf_weight_decay={clf_weight_decay} --dataset_path=\\'{dataset_path}\\' --experiments_path=\\'{experiments_path}\\' --lr_0={lr_0} --n={n} --model_name=\\'{model_name}\\' --prior_path=\\'{prior_path}\\' --prior_type=\\'{prior_type}\\' --random_state={random_state} --save --wandb --wandb_project=\\'{wandb_project}\\'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>random_state</th>\n",
       "      <th>rank_value</th>\n",
       "      <th>test_acc1</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nonlearned_lr_0=0.01_n=1000_random_state=1001_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8109</td>\n",
       "      <td>0.756265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nonlearned_lr_0=0.01_n=1000_random_state=2001_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8181</td>\n",
       "      <td>0.790316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nonlearned_lr_0=0.01_n=1000_random_state=2001_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.8105</td>\n",
       "      <td>0.811299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nonlearned_lr_0=0.01_n=1000_random_state=3001_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>0.655546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nonlearned_lr_0=0.01_n=1000_random_state=3001_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8258</td>\n",
       "      <td>0.734187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nonlearned_lr_0=0.01_n=1000_random_state=3001_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8254</td>\n",
       "      <td>0.768437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nonlearned_lr_0=0.001_n=1000_random_state=1001...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.7858</td>\n",
       "      <td>0.848463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nonlearned_lr_0=0.001_n=1000_random_state=3001...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.8036</td>\n",
       "      <td>0.785231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=100...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.698573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=100...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.689700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=100...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>0.703297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=200...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.690048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=200...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7836</td>\n",
       "      <td>0.673171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=200...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.690943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nonlearned_lr_0=0.0001_n=1000_random_state=300...</td>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7877</td>\n",
       "      <td>0.672319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adapted_lr_0=0.1_n=1000_random_state=1001_weig...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>0.622891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adapted_lr_0=0.1_n=1000_random_state=2001_weig...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8201</td>\n",
       "      <td>0.620353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=1001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.655918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=1001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.651079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=2001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8302</td>\n",
       "      <td>0.639243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=2001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>0.753552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=2001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8177</td>\n",
       "      <td>0.815991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=3001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>0.632023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=3001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8389</td>\n",
       "      <td>0.607567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=3001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8304</td>\n",
       "      <td>0.711657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adapted_lr_0=0.01_n=1000_random_state=3001_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.782873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>adapted_lr_0=0.001_n=1000_random_state=1001_we...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.836763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>adapted_lr_0=0.0001_n=1000_random_state=1001_w...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>0.703297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>adapted_lr_0=0.0001_n=1000_random_state=2001_w...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7777</td>\n",
       "      <td>0.679178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adapted_lr_0=0.0001_n=1000_random_state=3001_w...</td>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.7918</td>\n",
       "      <td>0.666669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=10.0_clf_weight...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8254</td>\n",
       "      <td>0.604381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=10.0_clf_weight...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8347</td>\n",
       "      <td>0.578842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=10.0_clf_weight...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>0.575579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8355</td>\n",
       "      <td>0.547720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8326</td>\n",
       "      <td>0.564979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8388</td>\n",
       "      <td>0.564082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8305</td>\n",
       "      <td>0.613806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>0.641961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8386</td>\n",
       "      <td>0.582078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=1000.0_clf_weig...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>0.679502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=10000.0_clf_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>0.631943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=10000.0_clf_wei...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7747</td>\n",
       "      <td>0.700052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100000.0_clf_we...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8285</td>\n",
       "      <td>0.638150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=100000000.0_clf...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>0.672726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LearnedPriorLR_bb_weight_decay=1000000000.0_cl...</td>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.832353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_name     n      prior_type  \\\n",
       "0   nonlearned_lr_0=0.01_n=1000_random_state=1001_...  1000      nonlearned   \n",
       "1   nonlearned_lr_0=0.01_n=1000_random_state=2001_...  1000      nonlearned   \n",
       "2   nonlearned_lr_0=0.01_n=1000_random_state=2001_...  1000      nonlearned   \n",
       "3   nonlearned_lr_0=0.01_n=1000_random_state=3001_...  1000      nonlearned   \n",
       "4   nonlearned_lr_0=0.01_n=1000_random_state=3001_...  1000      nonlearned   \n",
       "5   nonlearned_lr_0=0.01_n=1000_random_state=3001_...  1000      nonlearned   \n",
       "6   nonlearned_lr_0=0.001_n=1000_random_state=1001...  1000      nonlearned   \n",
       "7   nonlearned_lr_0=0.001_n=1000_random_state=3001...  1000      nonlearned   \n",
       "8   nonlearned_lr_0=0.0001_n=1000_random_state=100...  1000      nonlearned   \n",
       "9   nonlearned_lr_0=0.0001_n=1000_random_state=100...  1000      nonlearned   \n",
       "10  nonlearned_lr_0=0.0001_n=1000_random_state=100...  1000      nonlearned   \n",
       "11  nonlearned_lr_0=0.0001_n=1000_random_state=200...  1000      nonlearned   \n",
       "12  nonlearned_lr_0=0.0001_n=1000_random_state=200...  1000      nonlearned   \n",
       "13  nonlearned_lr_0=0.0001_n=1000_random_state=200...  1000      nonlearned   \n",
       "14  nonlearned_lr_0=0.0001_n=1000_random_state=300...  1000      nonlearned   \n",
       "0   adapted_lr_0=0.1_n=1000_random_state=1001_weig...  1000         adapted   \n",
       "1   adapted_lr_0=0.1_n=1000_random_state=2001_weig...  1000         adapted   \n",
       "2   adapted_lr_0=0.01_n=1000_random_state=1001_wei...  1000         adapted   \n",
       "3   adapted_lr_0=0.01_n=1000_random_state=1001_wei...  1000         adapted   \n",
       "4   adapted_lr_0=0.01_n=1000_random_state=2001_wei...  1000         adapted   \n",
       "5   adapted_lr_0=0.01_n=1000_random_state=2001_wei...  1000         adapted   \n",
       "6   adapted_lr_0=0.01_n=1000_random_state=2001_wei...  1000         adapted   \n",
       "7   adapted_lr_0=0.01_n=1000_random_state=3001_wei...  1000         adapted   \n",
       "8   adapted_lr_0=0.01_n=1000_random_state=3001_wei...  1000         adapted   \n",
       "9   adapted_lr_0=0.01_n=1000_random_state=3001_wei...  1000         adapted   \n",
       "10  adapted_lr_0=0.01_n=1000_random_state=3001_wei...  1000         adapted   \n",
       "11  adapted_lr_0=0.001_n=1000_random_state=1001_we...  1000         adapted   \n",
       "12  adapted_lr_0=0.0001_n=1000_random_state=1001_w...  1000         adapted   \n",
       "13  adapted_lr_0=0.0001_n=1000_random_state=2001_w...  1000         adapted   \n",
       "14  adapted_lr_0=0.0001_n=1000_random_state=3001_w...  1000         adapted   \n",
       "0   LearnedPriorLR_bb_weight_decay=10.0_clf_weight...  1000  LearnedPriorLR   \n",
       "1   LearnedPriorLR_bb_weight_decay=10.0_clf_weight...  1000  LearnedPriorLR   \n",
       "2   LearnedPriorLR_bb_weight_decay=10.0_clf_weight...  1000  LearnedPriorLR   \n",
       "3   LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...  1000  LearnedPriorLR   \n",
       "4   LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...  1000  LearnedPriorLR   \n",
       "5   LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...  1000  LearnedPriorLR   \n",
       "6   LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...  1000  LearnedPriorLR   \n",
       "7   LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...  1000  LearnedPriorLR   \n",
       "8   LearnedPriorLR_bb_weight_decay=100.0_clf_weigh...  1000  LearnedPriorLR   \n",
       "9   LearnedPriorLR_bb_weight_decay=1000.0_clf_weig...  1000  LearnedPriorLR   \n",
       "10  LearnedPriorLR_bb_weight_decay=10000.0_clf_wei...  1000  LearnedPriorLR   \n",
       "11  LearnedPriorLR_bb_weight_decay=10000.0_clf_wei...  1000  LearnedPriorLR   \n",
       "12  LearnedPriorLR_bb_weight_decay=100000.0_clf_we...  1000  LearnedPriorLR   \n",
       "13  LearnedPriorLR_bb_weight_decay=100000000.0_clf...  1000  LearnedPriorLR   \n",
       "14  LearnedPriorLR_bb_weight_decay=1000000000.0_cl...  1000  LearnedPriorLR   \n",
       "\n",
       "    random_state  rank_value  test_acc1  test_nll  \n",
       "0           1001         2.0     0.8109  0.756265  \n",
       "1           2001         1.0     0.8181  0.790316  \n",
       "2           2001        12.0     0.8105  0.811299  \n",
       "3           3001         1.0     0.8275  0.655546  \n",
       "4           3001         2.0     0.8258  0.734187  \n",
       "5           3001         3.0     0.8254  0.768437  \n",
       "6           1001        12.0     0.7858  0.848463  \n",
       "7           3001        12.0     0.8036  0.785231  \n",
       "8           1001         3.0     0.7755  0.698573  \n",
       "9           1001         1.0     0.7818  0.689700  \n",
       "10          1001         6.0     0.7749  0.703297  \n",
       "11          2001         3.0     0.7755  0.690048  \n",
       "12          2001         6.0     0.7836  0.673171  \n",
       "13          2001         2.0     0.7772  0.690943  \n",
       "14          3001         6.0     0.7877  0.672319  \n",
       "0           1001         1.0     0.8163  0.622891  \n",
       "1           2001         1.0     0.8201  0.620353  \n",
       "2           1001         2.0     0.8200  0.655918  \n",
       "3           1001         3.0     0.8271  0.651079  \n",
       "4           2001         2.0     0.8302  0.639243  \n",
       "5           2001        12.0     0.8174  0.753552  \n",
       "6           2001         3.0     0.8177  0.815991  \n",
       "7           3001         6.0     0.8283  0.632023  \n",
       "8           3001         2.0     0.8389  0.607567  \n",
       "9           3001         3.0     0.8304  0.711657  \n",
       "10          3001         1.0     0.8210  0.782873  \n",
       "11          1001        12.0     0.7899  0.836763  \n",
       "12          1001         6.0     0.7749  0.703297  \n",
       "13          2001         6.0     0.7777  0.679178  \n",
       "14          3001        12.0     0.7918  0.666669  \n",
       "0           2001         2.0     0.8254  0.604381  \n",
       "1           3001         1.0     0.8347  0.578842  \n",
       "2           1001         3.0     0.8395  0.575579  \n",
       "3           1001         2.0     0.8355  0.547720  \n",
       "4           2001         1.0     0.8326  0.564979  \n",
       "5           3001         2.0     0.8388  0.564082  \n",
       "6           3001         3.0     0.8305  0.613806  \n",
       "7           2001       120.0     0.8247  0.641961  \n",
       "8           1001         1.0     0.8386  0.582078  \n",
       "9           2001        60.0     0.7779  0.679502  \n",
       "10          3001        60.0     0.8330  0.631943  \n",
       "11          1001        60.0     0.7747  0.700052  \n",
       "12          2001         3.0     0.8285  0.638150  \n",
       "13          3001       120.0     0.7885  0.672726  \n",
       "14          1001       120.0     0.7909  0.832353  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_CIFAR-10'\n",
    "std_prior_results = get_results(std_prior, experiments_path)\n",
    "learned_prior_iso_results = get_results(learned_prior_iso, experiments_path)\n",
    "learned_prior_lr_results = get_results(learned_prior_lr, experiments_path)\n",
    "results = pd.concat([std_prior_results, learned_prior_iso_results, learned_prior_lr_results])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3529636/2113699187.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results.rank_value[results.rank_value==6] = 4\n",
      "/tmp/ipykernel_3529636/2113699187.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results.rank_value[results.rank_value==60] = 4\n",
      "/tmp/ipykernel_3529636/2113699187.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results.rank_value[results.rank_value==12] = 5\n",
      "/tmp/ipykernel_3529636/2113699187.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results.rank_value[results.rank_value==120] = 5\n"
     ]
    }
   ],
   "source": [
    "results.rank_value[results.rank_value==6] = 4\n",
    "results.rank_value[results.rank_value==60] = 4\n",
    "results.rank_value[results.rank_value==12] = 5\n",
    "results.rank_value[results.rank_value==120] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>rank_value</th>\n",
       "      <th>model_name</th>\n",
       "      <th>random_state</th>\n",
       "      <th>test_acc1</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_acc1_mean</th>\n",
       "      <th>test_acc1_std</th>\n",
       "      <th>test_acc1_min</th>\n",
       "      <th>test_acc1_max</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_std</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(LearnedPriorLR_bb_weight_decay=10.0_clf_weigh...</td>\n",
       "      <td>(3001, 2001, 1001)</td>\n",
       "      <td>(0.8346999999999999, 0.8326000000000002, 0.838...</td>\n",
       "      <td>(0.5788421309471129, 0.5649791242122649, 0.582...</td>\n",
       "      <td>0.835300</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.8326</td>\n",
       "      <td>0.8386</td>\n",
       "      <td>0.575300</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>0.564979</td>\n",
       "      <td>0.582078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(LearnedPriorLR_bb_weight_decay=10.0_clf_weigh...</td>\n",
       "      <td>(2001, 1001, 3001)</td>\n",
       "      <td>(0.8254000000000002, 0.8355, 0.8387999999999998)</td>\n",
       "      <td>(0.6043808805465699, 0.5477198763847351, 0.564...</td>\n",
       "      <td>0.833233</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.8254</td>\n",
       "      <td>0.8388</td>\n",
       "      <td>0.572061</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.547720</td>\n",
       "      <td>0.604381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(LearnedPriorLR_bb_weight_decay=10.0_clf_weigh...</td>\n",
       "      <td>(1001, 3001, 2001)</td>\n",
       "      <td>(0.8395, 0.8305000000000002, 0.8285000000000003)</td>\n",
       "      <td>(0.5755792673110963, 0.6138064291000366, 0.638...</td>\n",
       "      <td>0.832833</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.8285</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>0.609179</td>\n",
       "      <td>0.025753</td>\n",
       "      <td>0.575579</td>\n",
       "      <td>0.638150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(LearnedPriorLR_bb_weight_decay=1000.0_clf_wei...</td>\n",
       "      <td>(2001, 3001, 1001)</td>\n",
       "      <td>(0.7779000997543335, 0.8329999446868896, 0.774...</td>\n",
       "      <td>(0.6795024831771853, 0.6319433521270758, 0.700...</td>\n",
       "      <td>0.795200</td>\n",
       "      <td>0.026760</td>\n",
       "      <td>0.7747</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>0.670499</td>\n",
       "      <td>0.028525</td>\n",
       "      <td>0.631943</td>\n",
       "      <td>0.700052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>(LearnedPriorLR_bb_weight_decay=100.0_clf_weig...</td>\n",
       "      <td>(2001, 3001, 1001)</td>\n",
       "      <td>(0.8246999979019165, 0.7885000109672546, 0.790...</td>\n",
       "      <td>(0.6419614248275759, 0.6727255256652831, 0.832...</td>\n",
       "      <td>0.801367</td>\n",
       "      <td>0.016528</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>0.715680</td>\n",
       "      <td>0.083451</td>\n",
       "      <td>0.641961</td>\n",
       "      <td>0.832353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(adapted_lr_0=0.1_n=1000_random_state=1001_wei...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(0.8163000345230103, 0.820099949836731, 0.8209...</td>\n",
       "      <td>(0.6228910679817198, 0.6203525841712954, 0.782...</td>\n",
       "      <td>0.819133</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.675372</td>\n",
       "      <td>0.076022</td>\n",
       "      <td>0.620353</td>\n",
       "      <td>0.782873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(adapted_lr_0=0.01_n=1000_random_state=1001_we...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(0.8200000000000003, 0.8301999999999998, 0.838...</td>\n",
       "      <td>(0.6559176585674283, 0.6392433458805082, 0.607...</td>\n",
       "      <td>0.829700</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.8389</td>\n",
       "      <td>0.634243</td>\n",
       "      <td>0.020053</td>\n",
       "      <td>0.607567</td>\n",
       "      <td>0.655918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(adapted_lr_0=0.01_n=1000_random_state=1001_we...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(0.8271000000000001, 0.8177000000000002, 0.830...</td>\n",
       "      <td>(0.6510786563873295, 0.8159913855552676, 0.711...</td>\n",
       "      <td>0.825067</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>0.8177</td>\n",
       "      <td>0.8304</td>\n",
       "      <td>0.726242</td>\n",
       "      <td>0.068111</td>\n",
       "      <td>0.651079</td>\n",
       "      <td>0.815991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(adapted_lr_0=0.01_n=1000_random_state=3001_we...</td>\n",
       "      <td>(3001, 1001, 2001)</td>\n",
       "      <td>(0.8282999992370605, 0.7748998999595642, 0.777...</td>\n",
       "      <td>(0.6320229287147522, 0.7032971774101259, 0.679...</td>\n",
       "      <td>0.793633</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>0.671499</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.632023</td>\n",
       "      <td>0.703297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>5.0</td>\n",
       "      <td>(adapted_lr_0=0.01_n=1000_random_state=2001_we...</td>\n",
       "      <td>(2001, 1001, 3001)</td>\n",
       "      <td>(0.8174000382423401, 0.789900004863739, 0.7918...</td>\n",
       "      <td>(0.7535515274047848, 0.8367634561538695, 0.666...</td>\n",
       "      <td>0.799700</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>0.752328</td>\n",
       "      <td>0.069446</td>\n",
       "      <td>0.666669</td>\n",
       "      <td>0.836763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(nonlearned_lr_0=0.01_n=1000_random_state=2001...</td>\n",
       "      <td>(2001, 3001, 1001)</td>\n",
       "      <td>(0.8181000351905823, 0.8274999856948853, 0.781...</td>\n",
       "      <td>(0.7903160516738894, 0.6555460529327394, 0.689...</td>\n",
       "      <td>0.809133</td>\n",
       "      <td>0.019705</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>0.711854</td>\n",
       "      <td>0.057206</td>\n",
       "      <td>0.655546</td>\n",
       "      <td>0.790316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(nonlearned_lr_0=0.01_n=1000_random_state=1001...</td>\n",
       "      <td>(1001, 3001, 2001)</td>\n",
       "      <td>(0.8108999999999997, 0.8258, 0.7771999999999994)</td>\n",
       "      <td>(0.7562649005889897, 0.7341868192672732, 0.690...</td>\n",
       "      <td>0.804633</td>\n",
       "      <td>0.020330</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.8258</td>\n",
       "      <td>0.727132</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>0.690943</td>\n",
       "      <td>0.756265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(nonlearned_lr_0=0.01_n=1000_random_state=3001...</td>\n",
       "      <td>(3001, 1001, 2001)</td>\n",
       "      <td>(0.8254000000000002, 0.7754999999999999, 0.7755)</td>\n",
       "      <td>(0.7684367781639103, 0.6985733027458191, 0.690...</td>\n",
       "      <td>0.792133</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.8254</td>\n",
       "      <td>0.719020</td>\n",
       "      <td>0.035116</td>\n",
       "      <td>0.690048</td>\n",
       "      <td>0.768437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(nonlearned_lr_0=0.0001_n=1000_random_state=10...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(0.7748998999595642, 0.7836000323295593, 0.787...</td>\n",
       "      <td>(0.7032971774101259, 0.6731713531494142, 0.672...</td>\n",
       "      <td>0.782067</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>0.7877</td>\n",
       "      <td>0.682929</td>\n",
       "      <td>0.014406</td>\n",
       "      <td>0.672319</td>\n",
       "      <td>0.703297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>5.0</td>\n",
       "      <td>(nonlearned_lr_0=0.01_n=1000_random_state=2001...</td>\n",
       "      <td>(2001, 1001, 3001)</td>\n",
       "      <td>(0.8104999661445618, 0.785800039768219, 0.8036...</td>\n",
       "      <td>(0.811298715686798, 0.8484628473281863, 0.7852...</td>\n",
       "      <td>0.799967</td>\n",
       "      <td>0.010406</td>\n",
       "      <td>0.7858</td>\n",
       "      <td>0.8105</td>\n",
       "      <td>0.814998</td>\n",
       "      <td>0.025946</td>\n",
       "      <td>0.785231</td>\n",
       "      <td>0.848463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n      prior_type  rank_value  \\\n",
       "0   1000  LearnedPriorLR         1.0   \n",
       "1   1000  LearnedPriorLR         2.0   \n",
       "2   1000  LearnedPriorLR         3.0   \n",
       "3   1000  LearnedPriorLR         4.0   \n",
       "4   1000  LearnedPriorLR         5.0   \n",
       "5   1000         adapted         1.0   \n",
       "6   1000         adapted         2.0   \n",
       "7   1000         adapted         3.0   \n",
       "8   1000         adapted         4.0   \n",
       "9   1000         adapted         5.0   \n",
       "10  1000      nonlearned         1.0   \n",
       "11  1000      nonlearned         2.0   \n",
       "12  1000      nonlearned         3.0   \n",
       "13  1000      nonlearned         4.0   \n",
       "14  1000      nonlearned         5.0   \n",
       "\n",
       "                                           model_name        random_state  \\\n",
       "0   (LearnedPriorLR_bb_weight_decay=10.0_clf_weigh...  (3001, 2001, 1001)   \n",
       "1   (LearnedPriorLR_bb_weight_decay=10.0_clf_weigh...  (2001, 1001, 3001)   \n",
       "2   (LearnedPriorLR_bb_weight_decay=10.0_clf_weigh...  (1001, 3001, 2001)   \n",
       "3   (LearnedPriorLR_bb_weight_decay=1000.0_clf_wei...  (2001, 3001, 1001)   \n",
       "4   (LearnedPriorLR_bb_weight_decay=100.0_clf_weig...  (2001, 3001, 1001)   \n",
       "5   (adapted_lr_0=0.1_n=1000_random_state=1001_wei...  (1001, 2001, 3001)   \n",
       "6   (adapted_lr_0=0.01_n=1000_random_state=1001_we...  (1001, 2001, 3001)   \n",
       "7   (adapted_lr_0=0.01_n=1000_random_state=1001_we...  (1001, 2001, 3001)   \n",
       "8   (adapted_lr_0=0.01_n=1000_random_state=3001_we...  (3001, 1001, 2001)   \n",
       "9   (adapted_lr_0=0.01_n=1000_random_state=2001_we...  (2001, 1001, 3001)   \n",
       "10  (nonlearned_lr_0=0.01_n=1000_random_state=2001...  (2001, 3001, 1001)   \n",
       "11  (nonlearned_lr_0=0.01_n=1000_random_state=1001...  (1001, 3001, 2001)   \n",
       "12  (nonlearned_lr_0=0.01_n=1000_random_state=3001...  (3001, 1001, 2001)   \n",
       "13  (nonlearned_lr_0=0.0001_n=1000_random_state=10...  (1001, 2001, 3001)   \n",
       "14  (nonlearned_lr_0=0.01_n=1000_random_state=2001...  (2001, 1001, 3001)   \n",
       "\n",
       "                                            test_acc1  \\\n",
       "0   (0.8346999999999999, 0.8326000000000002, 0.838...   \n",
       "1    (0.8254000000000002, 0.8355, 0.8387999999999998)   \n",
       "2    (0.8395, 0.8305000000000002, 0.8285000000000003)   \n",
       "3   (0.7779000997543335, 0.8329999446868896, 0.774...   \n",
       "4   (0.8246999979019165, 0.7885000109672546, 0.790...   \n",
       "5   (0.8163000345230103, 0.820099949836731, 0.8209...   \n",
       "6   (0.8200000000000003, 0.8301999999999998, 0.838...   \n",
       "7   (0.8271000000000001, 0.8177000000000002, 0.830...   \n",
       "8   (0.8282999992370605, 0.7748998999595642, 0.777...   \n",
       "9   (0.8174000382423401, 0.789900004863739, 0.7918...   \n",
       "10  (0.8181000351905823, 0.8274999856948853, 0.781...   \n",
       "11   (0.8108999999999997, 0.8258, 0.7771999999999994)   \n",
       "12   (0.8254000000000002, 0.7754999999999999, 0.7755)   \n",
       "13  (0.7748998999595642, 0.7836000323295593, 0.787...   \n",
       "14  (0.8104999661445618, 0.785800039768219, 0.8036...   \n",
       "\n",
       "                                             test_nll  test_acc1_mean  \\\n",
       "0   (0.5788421309471129, 0.5649791242122649, 0.582...        0.835300   \n",
       "1   (0.6043808805465699, 0.5477198763847351, 0.564...        0.833233   \n",
       "2   (0.5755792673110963, 0.6138064291000366, 0.638...        0.832833   \n",
       "3   (0.6795024831771853, 0.6319433521270758, 0.700...        0.795200   \n",
       "4   (0.6419614248275759, 0.6727255256652831, 0.832...        0.801367   \n",
       "5   (0.6228910679817198, 0.6203525841712954, 0.782...        0.819133   \n",
       "6   (0.6559176585674283, 0.6392433458805082, 0.607...        0.829700   \n",
       "7   (0.6510786563873295, 0.8159913855552676, 0.711...        0.825067   \n",
       "8   (0.6320229287147522, 0.7032971774101259, 0.679...        0.793633   \n",
       "9   (0.7535515274047848, 0.8367634561538695, 0.666...        0.799700   \n",
       "10  (0.7903160516738894, 0.6555460529327394, 0.689...        0.809133   \n",
       "11  (0.7562649005889897, 0.7341868192672732, 0.690...        0.804633   \n",
       "12  (0.7684367781639103, 0.6985733027458191, 0.690...        0.792133   \n",
       "13  (0.7032971774101259, 0.6731713531494142, 0.672...        0.782067   \n",
       "14  (0.811298715686798, 0.8484628473281863, 0.7852...        0.799967   \n",
       "\n",
       "    test_acc1_std  test_acc1_min  test_acc1_max  test_nll_mean  test_nll_std  \\\n",
       "0        0.002486         0.8326         0.8386       0.575300      0.007416   \n",
       "1        0.005700         0.8254         0.8388       0.572061      0.023810   \n",
       "2        0.004784         0.8285         0.8395       0.609179      0.025753   \n",
       "3        0.026760         0.7747         0.8330       0.670499      0.028525   \n",
       "4        0.016528         0.7885         0.8247       0.715680      0.083451   \n",
       "5        0.002037         0.8163         0.8210       0.675372      0.076022   \n",
       "6        0.007724         0.8200         0.8389       0.634243      0.020053   \n",
       "7        0.005380         0.8177         0.8304       0.726242      0.068111   \n",
       "8        0.024540         0.7749         0.8283       0.671499      0.029600   \n",
       "9        0.012540         0.7899         0.8174       0.752328      0.069446   \n",
       "10       0.019705         0.7818         0.8275       0.711854      0.057206   \n",
       "11       0.020330         0.7772         0.8258       0.727132      0.027130   \n",
       "12       0.023523         0.7755         0.8254       0.719020      0.035116   \n",
       "13       0.005337         0.7749         0.7877       0.682929      0.014406   \n",
       "14       0.010406         0.7858         0.8105       0.814998      0.025946   \n",
       "\n",
       "    test_nll_min  test_nll_max  \n",
       "0       0.564979      0.582078  \n",
       "1       0.547720      0.604381  \n",
       "2       0.575579      0.638150  \n",
       "3       0.631943      0.700052  \n",
       "4       0.641961      0.832353  \n",
       "5       0.620353      0.782873  \n",
       "6       0.607567      0.655918  \n",
       "7       0.651079      0.815991  \n",
       "8       0.632023      0.703297  \n",
       "9       0.666669      0.836763  \n",
       "10      0.655546      0.790316  \n",
       "11      0.690943      0.756265  \n",
       "12      0.690048      0.768437  \n",
       "13      0.672319      0.703297  \n",
       "14      0.785231      0.848463  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_results = results.groupby(['n', 'prior_type', 'rank_value']).agg(lambda x: tuple(x))\n",
    "columns = ['test_acc1', 'test_nll']\n",
    "for column in columns:\n",
    "    grouped_results[f'{column}_mean'] = grouped_results[column].apply(lambda item: np.mean(item))\n",
    "    grouped_results[f'{column}_std'] = grouped_results[column].apply(lambda item: np.std(item))\n",
    "    grouped_results[f'{column}_min'] = grouped_results[column].apply(lambda item: np.min(item))\n",
    "    grouped_results[f'{column}_max'] = grouped_results[column].apply(lambda item: np.max(item))\n",
    "grouped_results = grouped_results.reset_index()\n",
    "grouped_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>rank_value</th>\n",
       "      <th>test_acc1_mean</th>\n",
       "      <th>test_acc1_min</th>\n",
       "      <th>test_acc1_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.835300</td>\n",
       "      <td>0.8326</td>\n",
       "      <td>0.8386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.833233</td>\n",
       "      <td>0.8254</td>\n",
       "      <td>0.8388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.832833</td>\n",
       "      <td>0.8285</td>\n",
       "      <td>0.8395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.795200</td>\n",
       "      <td>0.7747</td>\n",
       "      <td>0.8330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.801367</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>0.8247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819133</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>0.8210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.829700</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.825067</td>\n",
       "      <td>0.8177</td>\n",
       "      <td>0.8304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.793633</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>0.8283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.799700</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.8174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809133</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.8275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.804633</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.8258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.792133</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.8254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.782067</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>0.7877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.799967</td>\n",
       "      <td>0.7858</td>\n",
       "      <td>0.8105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n      prior_type  rank_value  test_acc1_mean  test_acc1_min  \\\n",
       "0   1000  LearnedPriorLR         1.0        0.835300         0.8326   \n",
       "1   1000  LearnedPriorLR         2.0        0.833233         0.8254   \n",
       "2   1000  LearnedPriorLR         3.0        0.832833         0.8285   \n",
       "3   1000  LearnedPriorLR         4.0        0.795200         0.7747   \n",
       "4   1000  LearnedPriorLR         5.0        0.801367         0.7885   \n",
       "5   1000         adapted         1.0        0.819133         0.8163   \n",
       "6   1000         adapted         2.0        0.829700         0.8200   \n",
       "7   1000         adapted         3.0        0.825067         0.8177   \n",
       "8   1000         adapted         4.0        0.793633         0.7749   \n",
       "9   1000         adapted         5.0        0.799700         0.7899   \n",
       "10  1000      nonlearned         1.0        0.809133         0.7818   \n",
       "11  1000      nonlearned         2.0        0.804633         0.7772   \n",
       "12  1000      nonlearned         3.0        0.792133         0.7755   \n",
       "13  1000      nonlearned         4.0        0.782067         0.7749   \n",
       "14  1000      nonlearned         5.0        0.799967         0.7858   \n",
       "\n",
       "    test_acc1_max  \n",
       "0          0.8386  \n",
       "1          0.8388  \n",
       "2          0.8395  \n",
       "3          0.8330  \n",
       "4          0.8247  \n",
       "5          0.8210  \n",
       "6          0.8389  \n",
       "7          0.8304  \n",
       "8          0.8283  \n",
       "9          0.8174  \n",
       "10         0.8275  \n",
       "11         0.8258  \n",
       "12         0.8254  \n",
       "13         0.7877  \n",
       "14         0.8105  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_results[['n', 'prior_type', 'rank_value', 'test_acc1_mean', 'test_acc1_min', 'test_acc1_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>rank_value</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.575300</td>\n",
       "      <td>0.564979</td>\n",
       "      <td>0.582078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.572061</td>\n",
       "      <td>0.547720</td>\n",
       "      <td>0.604381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.609179</td>\n",
       "      <td>0.575579</td>\n",
       "      <td>0.638150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.670499</td>\n",
       "      <td>0.631943</td>\n",
       "      <td>0.700052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>LearnedPriorLR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.715680</td>\n",
       "      <td>0.641961</td>\n",
       "      <td>0.832353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.675372</td>\n",
       "      <td>0.620353</td>\n",
       "      <td>0.782873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.634243</td>\n",
       "      <td>0.607567</td>\n",
       "      <td>0.655918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.726242</td>\n",
       "      <td>0.651079</td>\n",
       "      <td>0.815991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.671499</td>\n",
       "      <td>0.632023</td>\n",
       "      <td>0.703297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.752328</td>\n",
       "      <td>0.666669</td>\n",
       "      <td>0.836763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711854</td>\n",
       "      <td>0.655546</td>\n",
       "      <td>0.790316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.727132</td>\n",
       "      <td>0.690943</td>\n",
       "      <td>0.756265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.719020</td>\n",
       "      <td>0.690048</td>\n",
       "      <td>0.768437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.682929</td>\n",
       "      <td>0.672319</td>\n",
       "      <td>0.703297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.814998</td>\n",
       "      <td>0.785231</td>\n",
       "      <td>0.848463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n      prior_type  rank_value  test_nll_mean  test_nll_min  \\\n",
       "0   1000  LearnedPriorLR         1.0       0.575300      0.564979   \n",
       "1   1000  LearnedPriorLR         2.0       0.572061      0.547720   \n",
       "2   1000  LearnedPriorLR         3.0       0.609179      0.575579   \n",
       "3   1000  LearnedPriorLR         4.0       0.670499      0.631943   \n",
       "4   1000  LearnedPriorLR         5.0       0.715680      0.641961   \n",
       "5   1000         adapted         1.0       0.675372      0.620353   \n",
       "6   1000         adapted         2.0       0.634243      0.607567   \n",
       "7   1000         adapted         3.0       0.726242      0.651079   \n",
       "8   1000         adapted         4.0       0.671499      0.632023   \n",
       "9   1000         adapted         5.0       0.752328      0.666669   \n",
       "10  1000      nonlearned         1.0       0.711854      0.655546   \n",
       "11  1000      nonlearned         2.0       0.727132      0.690943   \n",
       "12  1000      nonlearned         3.0       0.719020      0.690048   \n",
       "13  1000      nonlearned         4.0       0.682929      0.672319   \n",
       "14  1000      nonlearned         5.0       0.814998      0.785231   \n",
       "\n",
       "    test_nll_max  \n",
       "0       0.582078  \n",
       "1       0.604381  \n",
       "2       0.638150  \n",
       "3       0.700052  \n",
       "4       0.832353  \n",
       "5       0.782873  \n",
       "6       0.655918  \n",
       "7       0.815991  \n",
       "8       0.703297  \n",
       "9       0.836763  \n",
       "10      0.790316  \n",
       "11      0.756265  \n",
       "12      0.768437  \n",
       "13      0.703297  \n",
       "14      0.848463  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_results[['n', 'prior_type', 'rank_value', 'test_nll_mean', 'test_nll_min', 'test_nll_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJsAAANvCAYAAAB6U9ucAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAC4jAAAuIwF4pT92AAEAAElEQVR4nOzdd3jUVdrG8XvSE0IgAUIvIQHpvYmiSBEXCFYQwVdlFxHQRVFUih1BcdVVVBBciqggRaVKUWwICFIkNJHQIaGXFBKSkHn/YDPLBJJMkjOZmeT7uS6unZP8zjMP62gy95xzfhar1WoVAAAAAAAAYICXqxsAAAAAAABA8UHYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACM8XF1A3CNzMxMrVu3Tvv27VN8fLzKlCmjqlWrqkOHDgoNDXV1ewAAAAAAwEMRNjlZZmamdu/erU2bNtn+bNu2TSkpKbZrfvzxR3Xs2LFI+snIyNCECRM0adIkxcXFXfN9Pz8/RUdH6+2331atWrWKpCcAAAAAAFB8WKxWq9XVTRRX9957r1auXKnk5ORcryuqsOnEiRPq2bOnNm3alOe1ISEhmjVrlu68806n9wUAAAAAAIoPVjY50ebNm/MMmopKSkqK7rzzTrugqWrVqnrwwQcVGRmpM2fOaPny5frll18kSQkJCerbt69++OEH3Xjjja5qGwAAAAAAeBjCpiLi7++vJk2aqFWrVkpMTNTnn39epM//0ksvacOGDbbxfffdp88//1z+/v62r40cOVKzZ8/WI488ovT0dKWmpur+++/XX3/9pYCAgCLtFwAAAAAAeCbuRudEDz30kKZOnaotW7YoMTFRGzdu1KRJk9S5c+ci7ePo0aP68MMPbeMmTZpo9uzZdkFTln79+um1116zjY8cOaKPPvqoSPoEAAAAAACej7DJiV577TU9+uijat68uXx9fV3Wx+TJk5Wammobv/XWW7n2M2LECFWtWtU2fv/9953aHwAAAAAAKD4Im0qAb775xva4Zs2auv3223O93sfHRwMGDLCNjxw54tCh4gAAAAAAAIRNxdyBAwe0e/du27hLly6yWCx5zuvatavdeOnSpcZ7AwAAAAAAxQ9hUzG3bds2u3G7du0cmtemTRv5+Pzv/PiYmBijfQEAAAAAgOKJsKmYu3pVkyRFRUU5NC8gIEBVqlSxjXft2mW0LwAAAAAAUDwRNhVz+/fvtxvXqFHD4blXX5u9DgAAAAAAwPUQNhVzCQkJduOwsDCH54aGhtoep6en69KlS8b6AgAAAAAAxZNP3pfAkyUlJdmNAwICHJ4bGBh4TS1/f/9C9XPy5EmdOnUqX3MSEhK0adMmhYSEqGzZsqpevXqh+wAAAAAAoLi6dOmSjhw5YhvfeuutKlu2bJE9P2FTMZeammo39vPzc3hu9kAnJSWl0P1MmjRJr776aqHrAAAAAAAAxyxcuFB33nlnkT0f2+iKuewrmdLS0hyem33bXPaVTgAAAAAAANkRNhVzwcHBduPsK51yk30lU/ZaAAAAAAAA2bGNrpgLCQmxG587d87hfZrnz5+3Pfb19TVyTtLQoUPVu3fvfM3ZtWuX+vTpYxsvXLhQUVFRhe4FAAAAAIDiKDY2VnfddZdtXL169SJ9fsKmYi4iIsJufPjw4Wu+lpNDhw7ZHteuXdtIP+Hh4QoPDy9UjaioKDVs2NBIPwAAAAAAFHdFfZMtttEVcw0aNLAbx8bGOjQvNTVVcXFxOdYBAAAAAAC4HsKmYq5p06Z24/Xr1zs0b+PGjcrIyLCNGzdubLQvAAAAAABQPBE2FXMRERGqV6+ebfz999/LarXmOe+7776zG/fs2dN4bwAAAAAAoPghbCoB7r77btvjQ4cOadWqVblen5GRoRkzZtjG1apVU6tWrZzWHwAAAAAAKD4ImzzQwYMHZbFYbH86duyY6/VDhgyxOwzsueeeU3p6eo7Xv/322zp27Jht/OSTT8pisRS6bwAAAAAAUPwRNpUA1atX1+OPP24bx8TEqH///rp06dI1186ZM0cvv/yybVy1alU98cQTRdInAAAAAADwfD6ubqA4+/rrr/Xcc89d8/XExES7cf/+/RUYGHjNdW+99ZbuueceI72MHTtWv/zyizZt2iRJmj9/vtatW6f/+7//U+3atXXu3Dl9++23+vnnn21z/P39NXfuXAUEBBjpAQAAAAAAFH+ETU6UkJCgffv25XldXFxcjvNNCQoK0pIlS9SjRw9t2bJFknTs2DG9+eab172+dOnS+vTTT3XTTTcZ6wEAAAAAABR/bKMrQSpVqqTffvtNr732mipVqnTda/z8/HTPPfdo27ZtdgeLAwAAAAAAOMJitVqtrm4CRe/y5ctat26dYmNjdeLECZUuXVrVqlVThw4dFBYW5ur27OzcuVONGjWyjXfs2KGGDRu6sCMAAAAAANyXq99Hs42uhPL29laHDh3UoUMHV7cCAAAAAACKEbbRAQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIzxcXUDAAAAQFHau3ev5s+fr8OHDyspKUnBwcGqUaOGevfurTp16ri6PQAAPB5hEwDkgTclyA9Pfr14cu9AXqxWq5YsWaKPPvpIq1atuu41Y8aM0e23367HH39c0dHRslgsRdwlAADFg8VqtVpd3QSQm507d6pRo0a28Y4dO9SwYUMXdoSSwJE3JZJ4UwJJnv168eTeAUclJSXpgQce0NKlSx2eEx0drdmzZys4ONiJnQEA4Byufh9N2AS35+p/SVDy8KYE+eHJrxdP7h1wVFJSkjp37qyNGzfme26bNm20evVqXu8AAI/j6vfRHBAOAFfJelOSnzffkrRkyRJ17txZSUlJTuoM7siTXy+e3DvgKKvVqgceeKBAQZMkbdy4Uf369ROfzQIAkD+ETQDwX7wpQX548uvFk3sH8mPJkiX5DlSvV2PJkiWGOgKK1t69ezV+/HgNHjxYDz74oAYPHqzx48dr7969rm4NQDFH2AQA/8WbEuSHJ79ePLl3ID8++ugjI3UmTZpkpA5QFKxWqxYvXqxu3bqpbt26GjNmjKZMmaIvvvhCU6ZM0ZgxY1S3bl1169ZNixcv5oMDAE7B3egA4L9Mvinp1auXkVpwX578evHk3uE+3P3uhXv37s310Pv8WLlypWJjYxUVFWWkHuAs+TmLb9WqVVq1ahVn8QFwCsImABBvSpA/nvx68eTe4XqO3L1wzJgxbnH3wvnz5xutN2/ePI0ePdpoTXgGdw9WsxT0MPyss/g4DB+ASYRNgAfxlF92PBFvSpAfnvx68eTe4VqetmLi8OHDRusdOXLEaD24N08KViVzZ/EtWrTIpX8PAMUHYRPg5jztlx1PxZsS9+Luwaonv162b99utN6OHTuM1oN78sQVE6bvmJiYmGi0HtyXpwWrktmz+NgeDcAEwibAjXniLzueKj4+3mi9uLg4o/VKAk8KVj35Tezu3buN1tu1a5fReiWNuwerkueumDD9c7B06dJG68E9eWKwKnEWH+AJP09LGsImwE156i87nurAgQNG6x08eNBoveLO04JVT34Tm5aWZrReenq60XolgScFq5LnrpioUaOG0XrVq1c3Wg/ux1ODVc7iQ0nlaT9PSxrCJsANeeovO+6g1shlBZp39KDZlUg7DxzLdy8H3+xhtAdP4YnBqie/ifXz8zNaz9fX12i94s7TglXJc1dM9O7dW2PGjDFWr0+fPsZqwT15arDKWXwoiTzx52lJ4+XqBgBcy+QvO+5i7969Gj9+vAYPHqwHH3xQgwcP1vjx47V3715Xt3aFxfB/Di3eZusVU6aCVavVariz3LVu3dpovbZt2xqtl5v69esbrdegQQOj9YqzrGA1v/99zwpWTW/fdIQzVkwA7spksFqUPPkcQaAgPPHnaUnEyibADXnqp8jZedLSVou32f8cmq5XXHnqp8i///670XobNmxQ586d8z2vICv5LsSZXdm0/Jgvq/gc4KkrVt1lxURBXutnf/hPvufkpkW/ZxXWaWC+5pTE17qn8uStaJ58jiCQX57687QkYmUT4GaKy6fISUlJ6tWrl+688848/z6rVq3SnXfeqTvvvNNlnzR4BZg9M8crgOW5juBT5CuK8lPkoBtuMluv3s1G6xVXnrpi1ZPvXnjp6E7D9TgMvzhzRrBaVDz5HEEgvzz152lJxEfvgJtxl0+RCyMpKUm33XabNm3alK95S5Ys0W233aYff/yxyPdS+1etr7T4v8zVq8bWory4y6fI79zfM99zfv9ta77n5Gbjt4v1zv0FCJwihuR7im9YVVn8g2W9VPhg1xJQWr6hVQpdpyTw1BWrnnz3wsxUsx9emK4H9+LJHyJ48jmCcC+ecEc3T/15WhKxsglwM578y450ZWlr79698x00Zdm0aZP69OlT5GfwlG7e3a3rFUee/Cmyn4/Zz2r8fYvus5/0s8eMBE2SZE1NVPo5s4frF0eevGKVuxeipPDkrWi9e/c2Wo/D8EsWq9WqxYsXq1u3bqpbt67GjBmjKVOm6IsvvtCUKVM0ZswY1a1bV926ddPixYuL/Hf0q3nyz9OSiLAJcDOe/MuOJC1evFgrVqwoVI3ly5dr8eLFhjpyjG9YVfmG1zZTKzyS1R4O8ORgNTQo0Gi9soFm6+Xm4p61Zuv9+avResWRRwerHnz3QrZHIz88eStanTp1dPvttxup1a1btyI7awqu52nHXnjyz9OSiLAJcDOe/MuOJL3yyitG6rz66qtG6uRHmZv6GarzgJE6xZ0nB6tNqlc2Wq+p4Xq5yUg4abjeKaP1iiNPDlY9+e6F/lXN9s726OLN07eiPf7440bqDB061EgduD9PvKObJ/88LYk4swlwM578y87evXv1xx9/GKm1devWIr2TiyQF1WmrgIiWSj2wucA1Amq3VFCdoruNvSfz5GC1QulSCvLz1cW0wm8JCvLzVfnSpQx05RhrWqrheilG6xVH7hKsFuR8sgu7zG4xOL99S4H6KMj5ZKWbd1fipkX5f65c6qH46t27t8aMGWOsXlFvRYuOjlbPnj0LdXBydHS0oqOjDXYFd+Wpd3Rzl5+ncAwrmwA348n77idPnuzW9fJisVhU4a6R8qtUsIDLr1KUKtw5ktuoOsiTg9VTiclGgiZJupiWrtOJyUZqOcLiF2C4XtFtAfRUnhysevIqPrZHIz88fSuaxWLRnDlz1KZNmwLNb9OmjWbPns3vMIbs3btX48eP1+DBg/Xggw9q8ODBGj9+vPbu3evq1iR57h3dPPnnaUlE2ATAmF9/NXt2i+l6jvDyC1TFB95QYGT+flkLjGyjig+8IS/eeDvMk4PVmCPxRuttM1wvNz4h4YbrVTBarzjy5GDV07E9Gvnh6VvRgoODtXr16nyvToqOjtbq1auL/E7AxY0nHbRt8o5uRYmfp56FsAlwM5588N3Jk2bPgjlx4oTReo7y8gtUhXtfVIV7XlRARItcrw2IaKEK97yoCve+SNCUT578KfK5i2a3jp1PKbqtaEE33GS2Xr2bjdYrjghW/6cog1Xpf9ujC4Pt0SVH1la0wtZw5Va04OBgLVq0SIsWLVK3bt1yvbZbt262awmaCseTDtr25Du6efLP05KIM5uK2M6dOxUTE6O4uDh5e3uratWqatWqlSIiIoq0j/3792vLli2Kj49XQkKCAgMDVa5cOTVp0kSNGzeWj+HbesNx7nLwXUHO1DgVb/YW6Kfi4/LfRwHO9bgei8WioDptFVSnrdLPHtPFPWuVkXBK1rQUWfwC5RNSQUH1bmZbRSENHTrUyC88Q4aY+efuqLSMDKP1LqWbrZcb37CqCqjVXKkHtxa6VkBEC/4dcEBWsGritU6wmj9Z26NPzBmltOP5f0PE9uiSJWsrWufOnQt0lo27bEWzWCzq1auXevXqpb1792r+/Pk6cuSIEhMTVbp0aVWvXl19+vThrnOGZB20nd/XTNZB20W9qswZH2yPHj3aaM2cePLP05KIRKGILFiwQGPHjlVMTMx1v9++fXuNGzdOHTt2dFoPly9f1tSpU/Xhhx9q165dOV5Xvnx5Pfzwwxo9erTCwsKc1g+uz5MPvrPI7C9XXm7yy71vWFWVuZFPPvA/foYDeX/fov1xXLpFTyNhU+nmPQx0UzI8/vjjRn45LurtOZ4crGbJ2h59evG/lLLP8TeDgZFtVL7Xs6xaLWGytqL169cvX+fRREdHa/bs2W63QqhOnTpFFgSURJ540La7fLBdUJ7687QkYhudk12+fFkDBgxQ7969cwyaJGndunXq3LmzXnrpJaf0cerUKd10000aOnRorkGTJJ0+fVrvvPOO6tev75Izc0o6Tz74rpSfr9F6Qb5m68H9mNrrX9SHyYcGmX3zWTawaN/MBka1UWBk68LXiCrYQbQlkaduz/H0YDUL26ORH2xFg6M88aBtT/5gW/Lcn6clESubnGz48OGaOXOmbRwUFKT+/furWbNmSktL04YNG/TVV18pPT1dmZmZGjt2rEJDQzV8+HBjPaSlpen222+3uyW9v7+/evXqpXbt2iksLExJSUnavn27FixYoLNnz0q6cv7O3/72N23cuFH169c31g9y58kH31UODdHJJHN31aoSFmKsFtyPM84MKKrl0E2qV9byHXuM1SvKO3RJV7ZYlO/1nE58OUZp8X/le75f5boqH/2sy7eKeBJP3Z7j6cHq1dgejfxgKxocYfKg7V69ehmplRdP/mBb8tyfpyURYZMTLVu2TB988IFt3KBBA61YseKaN//btm1T9+7dFRd35bybESNGqEuXLmrcuLGRPt5//327oKlp06b65ptvrntO1Ntvv62BAwfaDpVOSkrSsGHD9N133xnpBXnr3bu3xowZY6xeUR58V6VMiNHDXyuHEDYVZ558ZkCF0qVUt2J5/XXidKFr3VCpgsqXLmWgq/zx8gtUxb7jdHrJv5QSm4+tRVFtVD6arUUF4Ynbczw9WM0J26ORH2xFw/V46odmnvzBdhZP/HlaErGNzkkyMzM1atQo2zgoKEhLliy57r+MTZs21fz58+Xl5WWba/IH2tUrqwIDA7VkyZIcDyQvXbq0vvjiCzVp0sT2tdWrV9uCMDifJ9+hq4nhNxHu8qYEzuHpZwbcFFXLSJ32kTWN1CkIL7/AK9uF8rO16B62FhWGp23PyQpWTXBVsAoAzuCpd5AuLnd087SfpyURK5ucZPXq1dq+fbttPGzYMNWuXTvH69u3b6/evXtr7ty5kqSlS5caSbdTU1Ptzmjq2bNnnumzj4+PHn30Uf3zn/+UdOXgu5iYGFWpwrLyouKpB99VKF1KdcLLae/JM4WuVbdied6UFHOefmZAgyrhql85XLvjTxaqRoMq4Qa7yj+2FhU9T9uec1NULSOr+FwZrAKAaZ76oVlxuqObp/08LWkIm5zkm2++sRsPHDgwzzmPPvqoLWySpIULF2rEiBGF6uPMGfs3/Y7+i1anTh27cdY5TigaWQffFebAQVcdfHdznQgjYZOpVSNwX8XhzIAH2zXXxz9v0JGz5/M9v3pYWfVv29ytzgxga1HR84TtOcUlWAUAkzz5QzNP/WA7N57w87SkIWxykmXLltkeR0ZGKjIyMs85HTp0UEBAgFJTUyVdWd1U2LCpbNmyslgsslqtkqTkZMcOb85+XXg4vyAWxEeDfyjw3NvCB2t7eKwOnfwz33NrhtdTxwqPadKQHwv8/AXFmxI4qjicGeDv66PBt7bVFxu2alec46/5BlXC1b9tc5fdmQvIj+IYrAJAYXnyh2ae/ME2PAdnNjnB+fPn7ZZVtmvXzqF5fn5+atmypW0cExNT6F5KlSqlpk2b2sY//OBY+LF69Wrb44CAALVpw+2ti5q/b6CG9XxbjWremK95jWreqGE935a/r2vOVMl6U1I9rGyB5vOmpOQoLmcG+Pv6aMBNrTTgpla6oVKFXK+9oVIF27UETfAkWcFqfj8IaFAlXINvbcvrHUCxExQU5Nb1cpN1R7eCvsfjjm5wBD/5nWD37t124/zsEY2MjNTatWslSefOndPx48dVqVKlQvXzz3/+U//4xz8kSTt27NCkSZNyXfL4+++/a9q0abbxoEGDFMJdwVzC3zdQj3Ubq+2H1mvNzsXaffT3HK+tX621OjTspcY1b3T5f/hZ7QFHFLczAxpWraiGVSvqVGKyYo7E63xKii6lZ8jf10dlAwPVtHplziGDR8sKVnfFndS6fYe05/ipHK+9oVIFtY+sqQZVwl3+MwkAcC3u6AZn4x2dE+zfv99unJ+tItmv3b9/f6HDpgEDBmjx4sVatGiRJOmJJ57Qjh07NGzYMNWrV8923fHjxzVr1iy99tprunTpkqQrqfX48eML9fwoHIvFoia12qtJrfY6eeGotu77WeeST+lS2kX5+wUptFQFtYjsqAplqrq6VTu8KSlZCrpltJalg6TCh001dXOhtq2aVKF0KXVuwEGUKJ4IVgHgiosXL7p1PUcEBwdr4cKFevHFFzVlypRrzvu9Wrly5fTYY49p7Nixtruou5OsA8IPHz6spKQkBQcHq0aNGurdu/c15xGjaBA2OUFCQoLdOCwszOG5oaGhdmMTB8VZLBbNmzdPzz//vD788ENlZGRo8uTJmjx5skJCQhQWFqakpCSdPv2/O834+vpq4MCBeuutt1SqlLlfGE+ePKlTp3IOHa4nNjbW2PN7uvAy1dStRX9Xt+Ew3pQgL41r3qhGNdppx+HfClyjUc0b1Tif200BFB7BKoCSzJMPCM+SlJSkBx54wKGzm86cOaPx48dr+/btbrOyyWq1asmSJfroo49yXCk/ZswY3X777Xr88ccVHR3NB9tFiLDJCbL/hycgIMDhuYGB9ufsmPqPmJ+fn/79739r8ODBeuyxx/Tzzz9LuhKMZQ/HatSoocmTJ6t79+5GnvtqkyZN0quvvmq8Ltwfb0pwPRaLRQO6vKCJS0cU+DD8AZ3H8IsDAHgAVh6gOPHkA8KlK+8zO3furI0bN+Zr3pIlS9S5c2etXr26UP8f1Bq5LO+LcpGZlqLTi99Syr6cjxnJsmrVKq1atUqBUW1UPvpZefkV7mzbg2/2KNT8koKwyQmy7iaXxc/Pz+G5/v7+duOUlBQjPWVmZur999/Xm2++qZMncz9D5/Dhw+rRo4e6du2qjz/+WLVr1zbSAwBcT9Zh+DNWj9OOQ+sdnteo5o0a0HmMyw7DBwDkjZUHcHcF3YYftyXdaB/HNqflu5fHP+5UoOeyWq164IEH8h00Zdm4caP69eunRYsWueTf18y0FJ34cozS4v/K17yU2I068eUYVew7rtCBE/JG2OQE2VcypaWlOTw366ykLNlXOhVEamqq7rnnHi1fvtz2tS5duuiJJ55Q27ZtVa5cOSUnJysmJkaff/65pk+frsuXL+u7775Tq1at9P3336tFixaF7gMAcuKph+EDAHKWny06WSsPOHwYnqJ55K1a8vt0Y/VaRHbM95x37u9ZoOfaeeyElq7dVKC5WZYsWaJ/dGijhlUrFqxAxJACTbNarTq9+K18B01Z0uL/0ukl/1KFe17k90gnI2xyguw/HLOvdMpN9pVMJn7QPvnkk3ZB0/jx4zVq1Ci7a8qWLatbbrlFt9xyi/r27asePXooNTVV586d0z333KMdO3YY6WXo0KH5vt15bGys7rrrrkI/NwD35qmH4QMAruXqLTqAs4WXqaZ61Vrpz6OFC22kKx+kFeXvN2tjDxqrU+CwqYBSYjc6tHUuzxqxGxVUp62hrnA9hE1OEBISYjc+d+6cw3PPnz9vNy7s3t3du3frk08+sY179ep1TdCUXadOnTRu3Dg988wzkqRDhw5pypQptnFhhIeHKzw8vNB1ABRvnnYYPgDgfzx9iw7gqFsa3mkkbOrQsJeBbhxzKjFZf504nfeFDvjrxGmdTkwu0pv9JG7Je6WkQ3W2LiNscjLCJieIiIiwGx8+fNjhuYcOHbIbF/a8pLlz58pqtdrGTzzxhEPzHnvsMY0aNcq2BfDrr782EjahcLJWe5xNOqm09BT5+QYqLDhczSNvVXiZaq5uDwAAQEuWLHFo61xeNZYsWaJevYruTbg7KOyhya5SUg9MblzzRjWo3lq7jhR8pU2D6m2K9K66MUfijdbbdiS+yG4ClH72mFIPbjVSK/XAFqWfi5NvaBUj9XAtwiYnaNCggd04NjbW4bn79u2zPQ4NDVWlSpUK1cu2bdvsxq1atXJoXqlSpVSvXj3FxMRIknbu3FmoPlBwVqtV2w+t1y87F+X4ycmS36erXrVWuqXhnZxjAwAAXOqjjz4yUmfSpEkFCpsKeo6NWyjgOTZwnas+1y/YfDNtOCz+QkLeF+XD8QuJRuvl5uKetWbr/fmrytzYx2hN/A9hkxOULVtWNWrUsK1oWr/esbsrpaWlafPmzbZx48aNC91LcnKy3Tg/e99LlfrfckhTd8VD/lxKT9GM71/XjsO/5Xntn0c36c+jm7hDFwA4UUHvWgSUFHv37s3xrnP5tXLlSsXGxioqqmhWTQD5tf3Q+lxvauKI3Uc2avuh9WpSq72hrnJ3MiHJaL0TCUUXNqWdPGi23qlDeV+EAiNscpLu3bvr448/lnRltdL+/fvz3BK3Zs0au8PEe/Ys/KcyoaGhduPjx4+revXqDs2Nj//fEsty5coVuhfkz6X0FE1cOkKHTv6Zr3k7Dq3XxKUjNKzn2wRO8FhsGQUAzzR//nyj9ebNm6fRo0cbrZlfpxKTFXMkXucupigtI0N+Pj4KDQpUk+qVVaEIz6opiPSzx3Rxz1plJJyUNS1VFr8A+YSEK+iGm+Qbxg03CuuXnYuM1Fmzc3GRhU0ZmWbXUl0u7NKufEg/e8RsvTOOH3eD/CNscpK7777bFjZJ0ieffKI33ngj1zlXH+Qtycgd2LJ/EvTdd9/p73//e57z9u7dq4MHD9rGdevWLXQvcJzVatWM71/Pd9CU5dDJPzVj9Tg91m0sW+rgMdgyipJo99FNWv3HPJ1LPqX0jDT5+vgptFQFdW7WR/WrObb1HXAn+Tmr1BFHjph9c+koq9WqXXEntTb2YI6HKS/fsUd1K5bXTVG11KBKuNv8TLJarUqJ3ajELUtzPN/m/C+zFFCruUq36KnAqDZu07snOXnhqJHDwSVp99HfderCsSK5I52Pl9l/1t5F+NqxXs5w63qwR9jkJF26dFGjRo20Y8cOSdIHH3ygQYMGXXN4eJZ169bZfRLUo0cP1alT57rXHjx40K7Orbfeqp9++um6195xxx0aP368bTx+/Hj17t07z7vcPf/883bjbt265Xo9zNp+aL1DW+dys+PQ+iJdkgsUBltGUZJkZmZq6aYZWrtrqZIvXXt2xonzh/Xnsc0q5R+imxr0VM9WA+Tl5eWCToH8u3plvAlxcXFG6zniUnqGPv9tq3bHn8zz2r9OnNZfJ06rQZVw9W/bXP6+rn17lZmWotOL33Lo1vCpB7cq9eBWBUa1UfnoZ+Xlx8/T/Ni672ej9bbs+6lI7sRbISRYcQbPWQov4/gxLYVl8TL775fperDHby5O4uXlZRfyJCcnKzo6+rqfzsTExKhPnz7KzMy0zR03bpyRPjp06KDWrVvbxvv27VP37t119OjR615/8eJFDRw4UN98843tayEhIRo0aJCRfuAYk0tyAXeXtWU0vwFr1pbRS+mcKQfPkXDxrMZ81lurts6+btB0teRLCVq1dbbGfN5HCRfPFlGHQOGYDpuOHz9utF5eLqVn6OOfNzgUNF1tV9xJffzzBl1Kd91Kicy0FJ34coxDQdPVUmI36sSXY5SZxs/T/DiblL/XSF7OJZ8yWi8nVcqEGK1XOcRsvdz4ljd7lIJveceOl0HBEDY5UXR0tIYOHWob79y5U/Xr19djjz2myZMna+LEierXr59atWqlY8eO2a6bMGGCmjZtaqyPKVOm2B0M/uuvvyoqKkp9+vTRO++8o5kzZ+qjjz7SY489pho1amjatGl2899//33ObCpCzliSC7grU1tGrUV4XgBQUAkXz+qVOf+nxNTz+ZqXmHJOr8z5PwInwMmsVqs+/22rjpw9X6D5R86e1xcbtrrkZ5LVatXpxW8pLf6vAs1Pi/9Lp5f8i5+n+ZBm+MOuS2kXjdbLSZPqlY3Wa2q4Xm78Klx/l1DB69UyWg/2WDfmZBMnTlRiYqI+++wzSVdWOE2dOvW611osFo0cOVIjRoww2kPz5s21bNky9e3b1/Zp06VLlzR//vxcD3EMCAjQv//9bz3yyCNG+0HuPHVJLlAQbBlFSZGZmak35j+qtIzUvC++jrSMVL2xYJDGPTiPLXVwa5UqVXLrernZFXcy3yuarldjV9xJNaxa0VBXjkmJ3ZjvFU3XrRG7UUF12hrqqnjzM7yN398vyGi9nFQoXUp1wstp78kzha5Vt2J5lS/CQ/KDbrhJ53+ZZa5evZuN1cK1+G3Fyby9vTVr1izNnTtXjRo1yvG6du3a6fvvv7fbemfSLbfcoh07dmjMmDF5/tAOCgrSgAEDtHXrVg0ePNgp/SBnnrokFygItoyipFi6aUa+VzRll5hyTks3zTDTEOAkVapUcet6uVkbe9Ct6uRHwuYlZupsWWqkTkkQFhxutF5oqQpG6+Xm5jpmVgjdFFXLSB1H+YZVlX/NZkZq+ddqLt/QovvvS0nEyqYi0qdPH/Xp00c7duxQTEyM4uLi5O3trSpVqqh169aqXbu2w7Vq1apVoCWuYWFhev311zV27Fjt3r1bf/zxh06dOqXExEQFBgYqLCxMDRo0ULNmzeTv75/v+jDDU5fkAvnlqXdxAQpi7S4zb+DW7lqqXm3+YaQWkJuPBv9QoHlxW9KN9nFsc1qBe8mPU4nJOd51Lr/+OnFapxOTi2zFR/rZY7p06A8jtS4d3Kr0c3G8CXdA88hbteT36cbqtYjsaKxWXhpUCVf9yuGFWsnXoEq4GlQxG7g5IqRltE4ZeL2HtOhZ+GaQK8KmItaoUaNcVzgVBYvFogYNGqhBgwYu7QPX56lLcoH8YssoSordRzfleRi4o5IvJWjP0S26oVoLI/UA0zz1DXjMEbMHm287Eq/ODaKM1szJxT1rzdb781eVubGP0ZrFUXiZaqpXrZWRD87qV2tdpB+YWSwWPdiuuT7+eUOBziirHlZW/ds2l8ViMd9cHgKj2igwsnWhto0GRrVRYFQbg13hethGB7gZT16SC+QHW0ZRUqz+Y57Ret/98aXRegCk+AtmAuEsxw3eWj4vaacOGK530Gi94uyWhncaqdOhYS8jdfLD39dHg29tm+/VSQ2qhGvwrW3l7+uadSsWi0Xlez0nv8p1CzTfr3JdlY9+1iVBWUlD2AS4meaRtxqtV5RLcoH8YMsoSgrTQej5i2a2+gDO4IxVq0XhZEKS0XonEooubEo/fdRwvSNG6xVnjWveqEY12hWqRqOaN6pxzRsNdZQ//r4+GnBTKw24qZVuqJT7B9Q3VKpgu9ZVQVMWL79AVew7Lt+rkwKj2qhi33Hy8jO7kwTXxzY6wM148pJcID/YMoqSIj0jzWi9tPRLRusBJnnqqtWMzPyfh5qbywU4X7WgrJkZbl2vOLNYLBrQ5QVNXDpCh07+me/5NcPraUDnMS5dZWOxWNSwakU1rFpRpxKTFXMkXudTUnQpPUP+vj4qGxioptUrF+ld5xzh5ReoCve8qJTYjUrcukypB7bkeG1ARAuVbt5DgVFtWNFUhAibADd0S8M7jYRNrliSCziKLaMoKXx9/IzW8/PlJh5wX566atXHy+wbUO8ifENr8Tb7ls50veLO3zdQw3q+rRmrx2nHofUOz2tU80YN6DxG/oY/fCuMCqVLFdlZYyZYLBYF1WmroDptlX72mC7uWauMhFOypqXI4hcon5AKCqp3Mwfeuwj/JQHcUNaS3B2HfytwDVcuyQUc4amHyAL5FVqqgk6cP2ysXtmg8sZqAaZ56qrVCiHBijN4zlJ4mWBjtfLiG1Zd6SfNndvkW66GsVolhb9voB7rNlbbD63Xmp2LtftozodX16/WWh0a9lLjmjeyysYg37CqHGzvZgibADdUHJbkAnlhyyhKis7N+ujPY5uN1evarK+xWoBpnrpqtUqZEG0zeEe6yiEhxmrlxS+8li7++Yu5ehVqGqtVklgsFjWp1V5NarXXyQtHtXXfzzqXfEqX0i7K3y9IoaUqqEVkR35fQYlB2AS4qeK0JBfICVtGURLUr9ZKpfxDlHyp8He7KuUfohuqtTDQFeAcnrpqtUn1ylq+Y4+xek2rVzZWKy9BN9yk87/MMlev3s3GapVU4WWqqVuL/q5uA3Ap7kYHuLGsJbmDuo1V/Wqtc722frXWGtRtrB7rNpagCR7D0+/iAjjqpgY93aoO4CxZq1ZNKMpVqxVKl1Kd8HJGatWtWL5ID1P2DauqgFrNjdQKiGjB+TYAjGBlE+DmWJKL4owtoygperYaoPW7v1Vi6vkC1ygdGKqerQaYawpwEk9dtXpznQjtPXmm0HVuiqpV+GbyqXSLnko9uLXwdZr3MNANABA2AR6FJbkojtgyipLAy8tLo3p/olfm/J/SMlLzPd/PJ0Cj7psqLy8WpcP9eeqNThpUCVf9yuHaHX+yUDUaVDF7bpUjAqPaKDCytVL25XwwtUM1otoY7ApAScZvLAAAl2PLKEqCkKAwvfLAZyodGJqveaUDQ/XKA58pJCjMSZ0BZmWtWq0ZXq9A8121atVisejBds1VPaxsgeZXDyur/m2bu2S1rcViUflez8mvct0CzferXFflo59lpTAAY1jZBABwC2wZRUkQEhSmcQ/O09JNM7R219JcDw0v5R+imxr0VM9WA1jRBI/jqatW/X19NPjWtvpiw1btinN8hVODKuHq37a5/H1d9/bKyy9QFfuO0+kl/1JK7EaH5wVGtVH56Gfl5ccHOADMIWwCALgdtoyiOPPy8lKvNv9Qrzb/0O6jm7T6j3k6f/G00tIvyc/XX2WDyqtrs77cdQ4eL2vV6vZD67Vm52LtPprzFq/61VqrQ8NealzzRpevrvH39dGAm1ppV9xJrdt3SHuOn8rx2hsqVVD7yJpqUCXc5X1LVwKnCve8qJTYjUrcukypB7bkeG1ARAuVbt5DgVFt3KJ3AMULYRMAAICL1K/WSvUN3bkLcEeeumrVYrGoYdWKali1ok4lJivmSLzOp6ToUnqG/H19VDYwUE2rVy7Su845ymKxKKhOWwXVaav0s8d0cc9aZSSckjUtRRa/QPmEVFBQvZu56xwApyJsAgAAAOB0nrpqtULpUurcIMrVbRSIb1hVlbmxj6vbAFACcQAAAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGOPj6gZKmp07dyomJkZxcXHy9vZW1apV1apVK0VERLikn8TERK1bt05xcXE6fvy4vL29Vb58edWpU0ctWrRQqVKlXNIXAAAAAADwTIRNRWTBggUaO3asYmJirvv99u3ba9y4cerYsWOR9PPbb7/pjTfe0KpVq5Samnrda7y9vdWuXTuNGzdOt956a5H0BQAAAAAAPBvb6Jzs8uXLGjBggHr37p1j0CRJ69atU+fOnfXSSy85tZ/U1FQNHjxY7du31+LFi3MMmqQrva9du1a///67U3sCAAAAAADFByubnGz48OGaOXOmbRwUFKT+/furWbNmSktL04YNG/TVV18pPT1dmZmZGjt2rEJDQzV8+HDjvaSmpuquu+7SypUrbV8rXbq0br/9drVs2VLh4eFKT0/XsWPHtGXLFv38889KTk423gcAAAAAACi+CJucaNmyZfrggw9s4wYNGmjFihWqXr263XXbtm1T9+7dFRcXJ0kaMWKEunTposaNGxvt56GHHrIFTRaLRU899ZReeeUVhYSEXPf6S5cuacmSJQoODjbaBwAAAAAAKL7cbhvd1atuPFlmZqZGjRplGwcFBWnJkiXXBE2S1LRpU82fP19eXl62uaNHjzbaz7x58zR//nzbePLkyXr33XdzDJokyd/fX/fdd5/uuOMOo70AAAAAAIDiy+3Cpr/97W+KiIjQ2LFjdfToUVe3U2CrV6/W9u3bbeNhw4apdu3aOV7fvn179e7d2zZeunSpYmNjjfRy6dIlPfnkk7Zx37599dhjjxmpDQAAAAAAcDW3C5sk6fDhw3rllVcUERGhHj16aOHChbp8+bKr28qXb775xm48cODAPOc8+uijduOFCxca6WXBggU6fvy4pCvb59544w0jdQEAAAAAALJzy7Apy+XLl7VixQrde++9qlatmkaNGmVstY+zLVu2zPY4MjJSkZGRec7p0KGDAgICbOOlS5ca6eWTTz6xe45atWoZqQsAAAAAAJCd24VNK1eu1L333itfX19JktVqldVq1YkTJ/TWW2/phhtu0G233aY5c+YoLS3Nxd1e3/nz53X48GHbuF27dg7N8/PzU8uWLW3jmJiYQveSkpKitWvX2sa33XZboWsCAAAAAADkxO3Cpq5du2revHk6duyY3nnnHTVs2NDu+1arVb/88osefPBBVa5cWU899ZTd2UjuYPfu3XbjqKgoh+devQLq3Llztu1vBbVlyxZlZGTYxk2aNJEkJSYm6uOPP1bHjh1VtWpV+fv7q1KlSmrbtq1GjRqlXbt2Fep5AQAAAABAyeR2YVOWcuXKafjw4dq+fbvWrVunAQMGqFSpUpKuBE7SlTDmgw8+ULNmzdSuXTtNmzZNycnJrmxbkrR//367cY0aNRyem/3a7LXy648//rAbV6tWTT/++KMaNmyoIUOG6Oeff1ZcXJzS0tJ04sQJbdy4UW+++aYaN26sgQMHKiUlpVDPDwAAAAAASha3DZuulhUkxcfHa+rUqWrbtq0tcJKuhE+///67Bg0apMqVK2vQoEHauHGjy/pNSEiwG4eFhTk8NzQ01G6cmJhYqF5OnTplN/799991xx136MiRI5KuHBheoUIFVa5cWd7e3rbrMjMzNW3aNHXs2FFJSUmF6gEAAAAAAJQcPq5uID9KlSqlgQMHauDAgdq5c6f+85//6PPPP9eZM2ds4VNSUpKmTZumadOmqVGjRnr00Uf14IMPqmzZskXWZ/Zw5upDv/MSGBiYa638On/+vN14+PDhSk9Pl7+/v0aNGmUL6CTpwoULmj17tl544QWdPXtWkrRx40YNGjRIs2fPLlQfWU6ePHlNAJYXTzkUHgAAAAAAeFjYdLWGDRvq3//+t9566y19/fXXmjZtmn744QdlZmbagqft27frySef1HPPPad7771XgwYNUocOHZzeW2pqqt3Yz8/P4bn+/v5248JuY8seVqWnp8vX11fffvutOnXqZPe9MmXKaMiQIerYsaM6dOigM2fOSJLmzJmjYcOGOXzQeW4mTZqkV199tdB1AAAAAACAe/KIbXS58fX11f33369Vq1bphx9+UMWKFWWxWGx/pCvhz+zZs9WxY0c1bdpU8+fPd2pP2Vcy5eeueZcuXbIbZ1/pVNheJOmZZ565Jmi6Wv369fXuu+/afe39998vVB8AAAAAAKBk8PiwKSMjQwsWLNAdd9yhzp076+TJk7bvWa1W2yqnrMfbt29X3759deutt9rOLTItODjYbpx9pVNusq9kyl4rv0qXLm03tlgsGjZsWJ7z+vXrp4oVK9rGq1evLlQfAAAAAACgZPDYbXS7du3StGnT9Nlnn9m2e1mtVlksFlmtVvn6+urOO+/UI488ou3bt2v69Onau3ev7bo1a9aoQ4cO2rJlS74O8HZESEiI3fjcuXMOz81+xlL2sKiwvdSrV892RlNufHx8dPPNN+urr76SdOWg8SNHjqh69eqF6mfo0KHq3bt3vubExsbqrrvuKtTzAgAAAACAouFRYVNycrK+/PJLTZs2TRs2bJBkHzBJUu3atTVw4EANGDBA4eHhkqTu3bvr+eef13fffaexY8fq119/lSQdOXJEEyZM0IQJE4z2GRERYTc+fPiww3MPHTpkN65du3ahesk+v0aNGg7PrVmzpt349OnThQ6bwsPDbf9cAAAAAABA8eMR2+h+++03DRw4UJUrV9agQYO0YcMGuy1yPj4+uu+++/Tdd99p7969ev75568baHTt2lW//PKLnn76advXFi9ebLzfBg0a2I3zcze1ffv22R6HhoaqUqVKheqlYcOGduP83Bkv+7X52Q4IAAAAAABKJrdd2XTmzBnNmjVL06ZN0+7duyVdu4opMjLymlVMjnj99dc1efJkpaSkXLOSyISyZcuqRo0athVN69evd2heWlqaNm/ebBs3bty40L3ccMMNCgwMtJ0FdfbsWYfnZr+2XLlyhe4HAAAAAAAUb263smnlypXq06ePqlatqhEjRmj37t3XXcW0atWqXFcx5SYgIMC2RSz73d9M6d69u+3xvn37tH///jznrFmzxm71UM+ePQvdh6+vr7p162Ybx8TEKDMz06G5W7dutatTrVq1QvcDAAAAAACKN7cLm/72t7/pq6++UlpamiTZrWJ64403dOTIEc2bN09dunQp1PP4+/sXutfc3H333XbjTz75JM852a8xdSj2fffdZ3t84cIFrVq1Ks85Bw4c0O+//24bt2vXTkFBQUb6AQAAAAAAxZfbhU1XM7GKKSe9evXSww8/rIceeshIvey6dOmiRo0a2cYffPCBDhw4kOP169at0/z5823jHj16qE6dOte99uDBg7JYLLY/HTt2zLWX++67z+6w75EjR9rCvJw888wzdiugHn744VyvBwAAAAAAkNw0bIqIiDC6iul6Xn31Vc2YMUMzZswwXluSvLy8NH78eNs4OTlZ0dHROnLkyDXXxsTEqE+fPrZwx8vLS+PGjTPWi7+/v129bdu26Z577tG5c+euufbSpUt6/PHH9c0339i+VrduXaeFcgAAAAAAoHhxuwPCV61a5ZRwyRWio6M1dOhQTZo0SZK0c+dO1a9fX/3791ezZs2Unp6u3377TQsWLFB6erpt3oQJE9S0aVOjvfTv318//vijpk2bJklatmyZoqKi1KdPHzVp0kQ+Pj7au3ev5s2bZ3doenBwsL7++mv5+voa7QcAAAAAABRPbhc2FZegKcvEiROVmJiozz77TNKVFU5Tp0697rUWi0UjR47UiBEjnNLLxx9/rIyMDH366aeSrtxt7uOPP87x+ipVqmjhwoVq2LChU/oBAAAAAADFj1tuoytOvL29NWvWLM2dO9fuDKfs2rVrp++//95u651pPj4+mjlzphYtWqSWLVvmeF1ISIieffZZxcTEqHXr1k7rBwAAAAAAFD9ut7KpuOrTp4/69OmjHTt2KCYmRnFxcfL29laVKlXUunVr1a5d2+FatWrVst2lryB69eqlXr16ad++fdq8ebPi4uKUmpqq8uXLq169emrXrp18fHhpAAAAAACA/HO7RGHy5Ml64oknJEmdO3fWqlWr8l3j9ttv1+rVqyVJ06ZN0yOPPGKyxUJp1KhRriucilJkZKQiIyNd3QYAAAAAAChG3G4b3cyZM22rdkaPHl2gGqNHj5bVapXVatX06dNNtgcAAAAAAIBcuFXYdPbsWW3evFkWi0XVqlVTx44dC1SnY8eOqlGjhiTpt99+04ULFwx2CQAAAAAAgJy4Vdi0efNmZWZmSlKBg6YsnTp1kiRdvnxZmzdvLmxrAAAAAAAAcIBbhU2xsbG2x02bNi1UravPRbq6LgAAAAAAAJzHrcKmq7e7hYWFFarW1fPPnz9fqFoAAAAAAABwjFuFTX5+frbHFy9eLFStws4HAAAAAABA/rlV2FS+fHnb4/379xeq1tXzK1SoUKhaAAAAAAAAcIxbhU1RUVG2x99++22hai1btsz2OCIiolC1AAAAAAAA4Bi3Cpvatm2rkJAQWa1W7dmzR/PmzStQnblz52rPnj2SpKCgIN10000m2wQAAAAAAEAO3Cps8vb21r333itJslqteuyxx7Rt27Z81di6dasGDx4sSbJYLLr77rvl6+trvFcAAAAAAABcy63CJkl66aWX5OfnJ4vFogsXLuimm27S+++/r9TU1Fznpaam6r333tMtt9yihIQESZKvr69effXVomgbAAAAAAAAknxc3UB2NWvW1LvvvqsnnnhCFotFFy9e1NNPP61XX31Vd9xxh1q1aqXKlSsrODhYSUlJio+P16ZNm7RixQpduHBBVqtVFotFFotF7777Luc1AQAAAAAAFCG3C5skaejQoTpx4oRef/11WSwWWa1WnT9/XnPnztXcuXOvOycrZMry8ssva+jQoUXVMgAAAAAAAOSG2+iyvPrqq1q0aJGqVKly3e9brdbrfq1GjRr69ttv9dJLLzm7RQAAAAAAAGTjtmGTJPXs2VMHDhzQzJkz1aNHD5UpU0ZWq9UWNGU9Llu2rKKjo/XFF19o37596tatm4s7BwAAAAAAKJncchvd1Xx8fPTQQw/poYcektVqVXx8vM6cOaPExEQFBwerXLlyqlq1qqvbBAAAAAAAgDwgbLqaxWJRlSpVctxaBwAAAAAAANdy6210AAAAAAAA8CyETQAAAAAAADCGsAkAAAAAAADGeMyZTcnJyYqLi9P58+eVmppquyOdI2655RYndgYAAAAAAIAsbh027d+/X5MmTdLy5cu1Z8+efAVMWSwWizIyMpzQHQAAAAAAALJzy7DJarXqtdde07hx43T58mXb1wAAAAAAAODe3DJsevzxxzVlyhRZrVZZLBa7oMlisUi6fviU9b2cvg8AAAAAAADncrsDwhcvXqyPP/7YNi5btqxeeukl/fLLL/rrr79sIVKtWrW0f/9+bdmyRQsWLNCQIUNUqlQpWa1WeXl5afz48Tpw4ID279/vqr8KAAAAAABAieN2K5vGjRtne1yvXj19//33qlKlyjXX+fj4qFatWpKkZs2a6Z577tHYsWM1cOBALVy4UGPGjJHFYtHzzz9fVK0DAAAAAACUeG61sun48eP6/fffJV3ZEjd37tzrBk05CQsL01dffaV7771XVqtVL7zwgtasWeOsdgEAAAAAAJCNW4VN69evl3QlaOrUqZMaN26c47U5nclksVg0ZcoUlSlTRpmZmRo1apRTegUAAAAAAMC13Cpsio+Ptz2+5ZZbcr320qVLOX4vLCxMd955p6xWq9avX69Dhw4Z6xEAAAAAAAA5c6uw6fz587bHOW2fCwgIkNVqVXJycq61WrZsaXu8adMmI/0BAAAAAAAgd24VNgUEBNge57RNLiQkRNKVYCq31U1Z10n2K6YAAAAAAADgPG4VNpUvX972+MyZM9e9plq1arbHO3bsyLHW8ePHbY+TkpIMdAcAAAAAAIC8uFXYVLduXdvjnIKkqw8NX7lyZY61li9fbntcrlw5A90BAAAAAAAgL24VNjVp0kS+vr6SpHXr1l33mjvuuEPSlW1277///nW3yH322Wf65ZdfbOOrz28CAAAAAACA8/i4uoGrBQUFqU2bNlq7dq0OHDigLVu2qEWLFnbXREdHKywsTOfOndOpU6fUsmVLPfXUU2ratKlSU1O1dOlSzZw5UxaLRdKV1VLZawAAAAAAAMA53GplkyTdeeedtscfffTRNd8PCgrS+PHjZbVaZbFYdPz4cY0aNUrdu3fXPffco+nTp+vy5cu2A8bfeuutIusdAAAAAACgpHOrlU2S1LdvX+3cuVOS5O3trbS0NPn5+dldM2jQIMXGxurtt9/OsY7FYtG//vUvRUdHO7VfAAAAAAAA/I/bhU3VqlXTjBkz8rzurbfeUteuXfXuu+/qp59+0qVLlyRJpUqVUpcuXTRy5Ei1bdvW2e0CAAAAAADgKm4XNuVH165d1bVrV1mtVp05c0ZWq1XlypWTl5fb7Q4EAAAAAAAoETw6bMpisVhUvnx5V7cBAAAAAABQ4rlV2LRz50599dVXkq5sh3vmmWdc3BEAAAAAAADyw63CplWrVumVV16RxWLRI4884up2AAAAAAAAkE9udbhRenq67XGzZs1c1wgAAAAAAAAKxK3CpsqVK9selypVyoWdAAAAAAAAoCDcKmyqXbu27fGxY8dc2AkAAAAAAAAKwq3Cpvbt29tWNy1fvtzF3QAAAAAAACC/3CpsslgsGjp0qKxWqzZs2KBly5a5uiUAAAAAAADkg1uFTZI0cuRItWvXTlarVf369dN3333n6pYAAAAAAADgILcLm7y9vbVy5UrdfffdSkxM1B133KF77rlHixcv1unTp13dHgAAAAAAAHLh4+oGsrv6kHBJslqtWrRokRYtWiRJKl26tEJCQuTj41jrFotF+/btM94nAAAAAAAAruV2YdPBgwdlsVgkyfa/0pXQSZISEhKUkJCQZx2LxSKr1WpXAwAAAAAAAM7ldmGT9L9gydU1AAAAAAAAkD9uFza9/PLLrm4BAAAAAAAABUTYBAAAAAAAAGPc7m50AAAAAAAA8FyETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGON2d6Pr1KmT0XoWi0WrV682WhMAAAAAAADX53Zh008//SSLxWKkltVqNVYLAAAAAAAAeXO7sEm6EhLlV1aoVJC5AAAAAAAAMMPtwqaHH344X9dfvHhRJ06c0JYtW5SUlCRJ8vLy0r333qugoCBntAgAAAAAAIAcuF3YNGPGjALNy8jI0Lx58zRq1CgdOXJEe/fu1aJFi1S9enXDHQIAAAAAACAnxeZudD4+PurXr5/++OMPNW3aVNu2bdMdd9yhlJQUV7cGAAAAAABQYhSbsClLaGioFixYIF9fX/355596/vnnXd0SAAAAAABAiVHswiZJioyMVHR0tKxWq2bOnKnk5GRXtwQAAAAAAFAiFMuwSZLat28vSUpOTtaPP/7o4m4AAAAAAABKhmIbNoWGhtoeHz582IWdAAAAAAAAlBzFNmw6ceKE7XFiYqILOwEAAAAAACg5im3Y9M0339geV6hQwYWdAAAAAAAAlBzFMmx6/fXXtXHjRtu4TZs2LuwGAAAAAACg5PBxdQMmpKam6tixY/rtt9/0n//8R7/88ossFoskqUmTJmrUqJGLOwQAAAAAACgZ3C5s8vb2NlLHarXK19dXEydONFIPAAAAAAAAeXO7sMlqtcpischqteZ7btZqJqvVqpCQEE2fPl0dOnQw3SIAAAAAAABy4HZhk6QCBU1Z86pUqaIHHnhATz/9tCpXrmy4MwAAAAAAAOTG7cKmGTNm5Ot6i8WioKAglS1bVvXq1VO1atWc1BkAAAAAAADy4nZh08MPP+zqFgAAAAAAAFBAXq5uAAAAAAAAAMUHYRMAAAAAAACMIWwCAAAAAACAMW53ZlN6erri4+MlSV5eXgU68Pvo0aPKzMyUJFWpUkU+Pm731wQAAAAAACiW3G5l03vvvaeIiAhFRETo6aefLlCNp59+2lZj8uTJhjsEAAAAAABATtwubPrss89ktVolSc8//3yBajz//POyWq2yWq2aOXOmwe4AAAAAAACQG7cKm+Lj47Vjxw5ZLBZFRUWpZcuWBarTsmVL3XDDDZKkbdu26dSpUybbBAAAAAAAQA7cKmzaunWr7fGtt95aqFpZ861Wq7Zs2VKoWgAAAAAAAHCMW4VN+/fvtz1u2LBhoWrVr1//unUBAAAAAADgPG4VNiUkJNgely1btlC1rp5/4cKFQtUCAAAAAACAY9wqbAoKCrI9vjp4Koir5/v6+haqFgAAAAAAABzjVmFThQoVbI/37NlTqFp//fXXdesCAAAAAADAedwqbLr6nKVly5YpMzOzQHUuX76sJUuW2MZ16tQpdG8AAAAAAADIm1uFTS1atFD58uVltVp1+PBhffzxxwWq8/HHH+vw4cOSrpzd1LZtW5NtAgAAAAAAIAduFTZJ0oMPPihJslqteuaZZ7Ry5cp8zV+xYoWeeeYZWSwWWSwW9evXT15ebvfXBAAAAAAAKJbcLoUZPXq0goODZbFYdOnSJfXs2VPDhw/X0aNHc5137NgxPfXUU4qOjlZ6erqsVqtKlSqlF198sYg6BwAAAAAAgI+rG8iufPny+vTTT9W7d29JV85fmjhxoj788EO1bt1arVq1UuXKlRUcHKykpCTFx8dr06ZN2rRpky5fviyr1SpJ8vb21qxZsxQeHu7Kvw4AAAAAAECJ4nZhkyTdfffdmjJlip544gmlpaVJuhI6bdiwQRs2bLjuHKvVKovFIkny9/fX5MmTdddddxVVywAAAAAAAJAbbqPL8o9//ENr165Vq1atbKuVsv43u6u/f+ONN2rDhg165JFHiqpVAAAAAAAA/JdbrmzK0qJFC23YsEFr1qzRvHnztGbNGu3atUsZGRm2a3x8fNSwYUPdcsst6tu3r2688UYXdgwAAAAAAFCyuXXYlKVDhw7q0KGDbZyYmKjExEQFBwcrJCTEhZ0BAAAAAADgah4RNmVXunRplS5d2tVtAAAAAAAAIBu3PbMJAAAAAAAAnoewCQAAAAAAAMa43Ta6+Ph4fffdd5KkUqVK6d577813ja+++krJycmSpG7duqlixYpGewQAAAAAAMD1ud3KprfeeksDBgzQgAEDtGHDhgLV2LBhg63Ge++9Z7ZBAAAAAAAA5MjtwqZ58+bJarXKYrFo2LBhBaqRNc9qterLL7802R4AAAAAAABy4VZh0549exQfHy+LxaI2bdqoWrVqBapTrVo1tW/fXpJ0+PBh7du3z2SbAAAAAAAAyIFbhU3bt2+3Pc4KiwqqXbt2tscxMTGFqgUAAAAAAADHuFXYdPToUdvjiIiIQtW6ev6RI0cKVQsAAAAAAACOcauw6eLFi7bHwcHBhaoVFBRke5x1ZzoAAAAAAAA4l1uFTWXKlLE9Pn36dKFqnTlzxva4VKlShaoFAAAAAAAAx7hV2FShQgXb482bNxeq1pYtW65bFwAAAAAAAM7jVmFT69atJUlWq1UrVqzQhQsXClTn/Pnz+vbbb23j5s2bG+kPAAAAAAAAuXOrsCkiIkJRUVGSpAsXLmjkyJEFqjNy5EhbUFWjRg3Vq1fPWI8AAAAAAADImVuFTZL0z3/+0/Z46tSpGjNmjDIzMx2aa7VaNXr0aE2dOlWSZLFY7OoBAAAAAADAudwubBo8eLAiIyMlXQmP3nzzTbVu3VpffvmlUlJSrjsnJSVFc+bMUevWrTVhwgTb12vXrq0nnniiSPoGAAAAAACA5OPqBrLz9fXVkiVL1L59e9tWuK1bt6p///7y9vZWvXr1VLlyZQUHByspKUnx8fH6888/dfnyZVmtVlksFklSWFiYli5dKj8/P1f+dQAAAAAAAEoUtwubJKlevXr6/vvv1adPH+3fv18Wi0VWq1UZGRnasWOHdu7cabvWarXaHmddV6dOHc2bN0833HCDK9oHAAAAAAAosdxuG12WFi1aaOvWrXr22WcVEhJi9z2r1Wr7c7WyZctq1KhR2rJli5o2bVqU7QIAAAAAAEBuurIpS+nSpTVhwgS9+OKLWrlypdasWaNdu3bpzJkzSkxMVHBwsMqVK6dGjRrplltuUbdu3RQUFOTqtnO1c+dOxcTEKC4uTt7e3qpatapatWqliIgIV7cGAAAAAABQaG4dNmUJDg7Wvffeq3vvvTffc/fu3as6deo4oav8WbBggcaOHauYmJjrfr99+/YaN26cOnbsWLSN/dekSZP0+OOP233t5Zdf1iuvvOKSfgAAAAAAgGdy2210hZGSkqJZs2bp1ltvVf369V3ay+XLlzVgwAD17t07x6BJktatW6fOnTvrpZdeKsLurjhy5IhGjhxZ5M8LAAAAAACKH49Y2eSojRs3avr06fryyy+VmJhod3c6Vxk+fLhmzpxpGwcFBal///5q1qyZ0tLStGHDBn311VdKT09XZmamxo4dq9DQUA0fPrzIehw6dKgSExOL7PkAAAAAAEDx5fFh05kzZ/TZZ59p2rRp2rVrlyS5RcgkScuWLdMHH3xgGzdo0EArVqxQ9erV7a7btm2bunfvrri4OEnSiBEj1KVLFzVu3NjpPX755ZdaunSpJKl+/fravXu3058TAAAAAAAUXx65jc5qtWrFihXq06ePqlatqmeeeUY7d+60uzud1WpVQECA7r77bpf0mJmZqVGjRtnGQUFBWrJkyTVBkyQ1bdpU8+fPl5eXl23u6NGjnd7jmTNnNGzYMElSQECAJk6c6PTnBAAAAAAAxZtHhU0HDx7USy+9pJo1a6pHjx766quvlJaWZhcyeXl5qWvXrpoxY4aOHz+uBQsWuKTX1atXa/v27bbxsGHDVLt27Ryvb9++vXr37m0bL126VLGxsU7tcfjw4Tp16pQk6YUXXlBUVJRTnw8AAAAAABR/bh82paWlac6cOerSpYuioqI0btw4HT16VFar1RYyWSwWtWvXThMnTtSxY8e0cuVKPfzwwwoJCXFZ3998843deODAgXnOefTRR+3GCxcuNNmSnVWrVumzzz6TdGV733PPPee05wIAAAAAACWH257ZtHXrVk2bNk1z5szR+fPnJV17FpPFYpHValVkZKTWrVvnok6vb9myZbbHkZGRioyMzHNOhw4dFBAQoNTUVElXVjeNGDHCeG/Jycl67LHHJF35/3DKlCny9fU1/jwAAAAAAKDkcauVTefPn9dHH32kFi1aqFWrVpo8ebLOnTsnSbZVTN7e3urZs6fmz5/vNgeBZ3f+/HkdPnzYNm7Xrp1D8/z8/NSyZUvbOCYmxnhv0pUtcwcPHpR0ZcXVzTff7JTnAQAAAAAAJY9brGxavXq1pk2bpoULF+rSpUuS7FcxWa1WNW3aVA8//LD69++vChUquLLdPGW/o1t+zkKKjIzU2rVrJUnnzp3T8ePHValSJWO9bdiwwXYQeMWKFTVhwgRjtQEAAAAAAFwWNh09elQzZszQjBkzdOjQIUn/C5iyVjFVqFBB/fv318MPP6wmTZq4qtV8279/v924Ro0aDs/Nfu3+/fuNhU3p6ekaOHCgMjMzJUn//ve/FRoaaqQ2AAAAAACA5MKwqVatWnaHfGfx8/NTdHS0Hn74Yd1xxx3y9vZ2UYcFl5CQYDcOCwtzeG728CcxMdFIT5L05ptvaseOHZKkbt266YEHHjBW21EnT5603QHPUc6+Kx8AAAAAADDHZWFTZmambZucxWJRmzZt9PDDD6tv374qW7asq9oyIikpyW4cEBDg8NzAwMBcaxXU7t27NW7cONtzTJo0yUjd/Jo0aZJeffVVlzw3AAAAAABwPpef2WSxWBQREaEBAwbo/vvvV5kyZVzdUqFl3U0ui5+fn8Nz/f397cYpKSmF7sdqtWrgwIG287Beeukl1a5du9B1AQAAAAAAsnOLu9EdOHBAQ4YMUeXKlXX//fdr2bJltnOFPFH2lUxpaWkOz80KhLJkX+lUEJMmTdK6deskSY0bN9YzzzxT6JoAAAAAAADX47KVTRMmTNCMGTP0559/2r6WmpqqBQsWaMGCBQoPD1e/fv300EMPqWnTpq5qs0CCg4PtxtlXOuUm+0qm7LXy68iRIxo1apSkK6vIpk6dKl9f30LVLIyhQ4eqd+/e+ZoTGxuru+66yzkNAQAAAAAAo1wWNj377LN69tlntW7dOv3nP//R/PnzlZycbDsw/MSJE3rvvff03nvvqVGjRnrkkUfUr18/VaxY0VUtOywkJMRufO7cOYfnnj9/3m5cunTpQvUyZMgQ2yHjgwcPVrt27QpVr7DCw8MVHh7u0h4AAAAAAIDzuHwbXfv27TV9+nTFx8dr6tSp14QhVqtVO3bs0IgRI1S9enX16NFD8+bNu2a7mTuJiIiwGx8+fNjhuYcOHbIbF+ZspcWLF2vZsmWSpMqVK+uNN94ocC0AAAAAAABHuPyA8CzBwcEaOHCgBg4cqN27d+s///mPPv/8c506dUpWq1UWi0UZGRlasWKFVqxYYVs9lLUSyp00aNDAbhwbG+vw3H379tkeh4aGqlKlSgXuY//+/bbHycnJatmyZa7XZ2Rk2I0nTpyozz//3DZ+4YUX9MgjjxS4HwAAAAAAUPy5Tdh0tfr16+udd97RhAkTtGjRIk2fPl0rV660BUtWq1UXLlyQxWKR1WrViRMn9M4776hv376qWrWqi7uXypYtqxo1athWNK1fv96heWlpadq8ebNt3LhxY2M9JSQkKCEhIV9zzp07Z7cFMPsWPwAAAAAAgOxcvo0uNz4+Prr33nu1bNkyHTp0SK+99to1W9QsFouSkpL03HPPqWbNmrr11ls1depUnT171kVdX9G9e3fb43379tmtMsrJmjVr7A4T79mzp1N6AwAAAAAAcBa3DpuuVrVqVb3wwguKjY3V6tWr9cADD8jf319Wq9W24ikzM1O//vqrhgwZosqVK6tnz56aM2eOS/q9++677caffPJJnnOyX1PYO7A99dRTtv9/HPlz4MABu/kvv/yy3fefeuqpQvUDAAAAAACKP48Jm65222236YsvvlB8fLw++OADNW/e3O7sJqvVqvT0dH377bd68MEHXdJjly5d1KhRI9v4gw8+uCbMudq6des0f/5827hHjx6qU6fOda89ePCgLBaL7U/Hjh2N9Q0AAAAAAFAYHhk2ZSlTpowef/xxbd68WVu2bNHQoUNVpkwZV7clSfLy8tL48eNt4+TkZEVHR+vIkSPXXBsTE6M+ffooMzPTNnfcuHFF1isAAAAAAIApHh02Xa1Zs2b68MMPFR8fr88//1ydOnWSxWJxaU/R0dEaOnSobbxz507Vr19fjz32mCZPnqyJEyeqX79+atWqlY4dO2a7bsKECWratKkrWgYAAAAAACgUt7wbXWH4+/urX79+6tevnw4cOKAZM2a4tJ+JEycqMTFRn332maQrK5ymTp163WstFotGjhypESNGFGWLAAAAAAAAxhSblU3XExERoddee82lPXh7e2vWrFmaO3eu3RlO2bVr107ff/+93dY7AAAAAAAAT1PsVja5qz59+qhPnz7asWOHYmJiFBcXJ29vb1WpUkWtW7dW7dq1Ha5Vq1YtuwPRTXFWXQAAAAAAUHIQNhWxRo0a5brCCQAAAAAAwJMV6210AAAAAAAAKFqETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABhD2AQAAAAAAABjCJsAAAAAAABgDGETAAAAAAAAjCFsAgAAAAAAgDGETQAAAAAAADCGsAkAAAAAAADGEDYBAAAAAADAGMImAAAAAAAAGEPYBAAAAAAAAGMImwAAAAAAAGAMYRMAAAAAAACMIWwCAAAAAACAMYRNAAAAAAAAMIawCQAAAAAAAMYQNgEAAAAAAMAYwiYAAAAAAAAYQ9gEAAAAAAAAYwibAAAAAAAAYAxhEwAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AQAAAAAAwBjCJgAAAAAAABjj4+oGSpqdO3cqJiZGcXFx8vb2VtWqVdWqVStFREQUyfOnpaVp9+7d2rVrl44fP66LFy8qJCREFStWVKtWrVS7du0i6QMAAAAAABRPhE1FZMGCBRo7dqxiYmKu+/327dtr3Lhx6tixo/HnPnbsmBYsWKBvv/1Wv/76qy5evJjjtVFRURo6dKiGDh0qf39/470AAAAAAIDijW10Tnb58mUNGDBAvXv3zjFokqR169apc+fOeumll4w+/6pVq1S9enU99dRTWrVqVa5BkyTFxsbq6aefVsuWLbVr1y6jvQAAAAAAgOKPlU1ONnz4cM2cOdM2DgoKUv/+/dWsWTOlpaVpw4YN+uqrr5Senq7MzEyNHTtWoaGhGj58uJHnv3jxoqxWq23s5eWlpk2bqkOHDqpZs6ZCQ0N17tw5/fbbb1q0aJHS0tIkXdnu16lTJ/3666+Kiooy0gsAAAAAACj+CJucaNmyZfrggw9s4wYNGmjFihWqXr263XXbtm1T9+7dFRcXJ0kaMWKEunTposaNGxvrJSIiQo899pgeeughVa5c+brXHD58WH379tX69eslSSdOnNDf//53/fLLL8b6AAAAAAAAxRvb6JwkMzNTo0aNso2DgoK0ZMmSa4ImSWratKnmz58vLy8v29zRo0cb6SM8PFxTpkzRnj179Pzzz+cYNElSjRo1tHLlSt1www22r61Zs4awCQAAAAAAOIywyUlWr16t7du328bDhg3L9U5v7du3V+/evW3jpUuXKjY2ttB9tG/fXoMGDZKvr69D15cuXVovv/yy3deWLl1a6D4AAAAAAEDJQNjkJN98843deODAgXnOefTRR+3GCxcuNNmSw7p06WI33rdvn0v6AAAAAAAAnoewyUmWLVtmexwZGanIyMg853To0EEBAQG2satWFAUHB9uNk5OTXdIHAAAAAADwPIRNTnD+/HkdPnzYNm7Xrp1D8/z8/NSyZUvbOCYmxnhvjjhw4IDduFKlSi7pAwAAAAAAeB7CJifYvXu33TgqKsrhuVevgDp37pyOHz9urC9Hff3113bjG2+8sch7AAAAAAAAnomwyQn2799vN65Ro4bDc7Nfm72WsyUlJWnSpEm2sZ+fn+68884i7QEAAAAAAHguH1c3UBwlJCTYjcPCwhyeGxoaajdOTEw00pOjnnnmGcXHx9vGgwcPNrqN7uTJkzp16lS+5pi4Kx8AAAAAACgahE1OkJSUZDe++tDvvAQGBuZay5lmzZqlqVOn2sY1atTQ2LFjjT7HpEmT9OqrrxqtCQAAAAAA3Afb6JwgNTXVbuzn5+fwXH9/f7txSkqKkZ7y8vPPP+vRRx+1jX19ffXll18qJCSkSJ4fAAAAAAAUD4RNTpB9JVNaWprDcy9dumQ3zr7SyRk2b96sXr162fq0WCyaPn06B4MDAAAAAIB8YxudEwQHB9uNs690yk32lUzZa5m2fft2devWze6cqUmTJunBBx90yvMNHTpUvXv3ztec2NhY3XXXXU7pBwAAAAAAmEXY5ATZt56dO3fO4bnnz5+3G5cuXdpES9f1559/qkuXLjpz5ozta++9954GDx7stOcMDw9XeHi40+oDAAAAAADXYhudE0RERNiNDx8+7PDcQ4cO2Y1r165tpKfs9u7dq06dOunkyZO2r02YMEFPPvmkU54PAAAAAACUDIRNTtCgQQO7cWxsrMNz9+3bZ3scGhqqSpUqGesry/79+9WpUyfFx8fbvvbaa6/pueeeM/5cAAAAAACgZCFscoKyZcuqRo0atvH69esdmpeWlqbNmzfbxo0bNzbe26FDh3Tbbbfp6NGjtq+98MILevHFF40/FwAAAAAAKHkIm5yke/futsf79u3T/v3785yzZs0au8PEe/bsabSno0ePqlOnTnbb+p5//nmNHTvW6PMAAAAAAICSi7DJSe6++2678SeffJLnnOzXmLwDW3x8vDp16mQXej399NN68803jT0HAAAAAAAAYZOTdOnSRY0aNbKNP/jgAx04cCDH69etW6f58+fbxj169FCdOnWue+3BgwdlsVhsfzp27JhrL6dOnVLnzp21d+9e29eGDRumd955x8G/DQAAAAAAgGMIm5zEy8tL48ePt42Tk5MVHR2tI0eOXHNtTEyM+vTpo8zMTNvccePGGenj3Llz6tq1q3bv3m372uOPP67333/fSH0AAAAAAICr+bi6geIsOjpaQ4cO1aRJkyRJO3fuVP369dW/f381a9ZM6enp+u2337RgwQKlp6fb5k2YMEFNmzY10sOHH36obdu22X1t+fLlioqKcrhGtWrV9NNPPxnpBwAAAAAAFG+ETU42ceJEJSYm6rPPPpN0ZYXT1KlTr3utxWLRyJEjNWLECGPPf/ny5Wu+5shh5VfLyMgw1Q4AAAAAACjm2EbnZN7e3po1a5bmzp1rd4ZTdu3atdP3339vt/UOAAAAAADA07CyqYj06dNHffr00Y4dOxQTE6O4uDh5e3urSpUqat26tWrXru1wrVq1aslqtTp07SuvvKJXXnmlgF0DAAAAAADkD2FTEWvUqFGuK5zgPFarVZmZmQ4HdSZ4+xXZUxnn4x/g6hYKpJSvxdUtFJgnb1nlte4anvp657XuGrzWC+9ypnTpslVF95sEAACeibAJxVpmZqaSkpKUkJCgpKSkIg2aJKl+91JF+nwmWS8/5OoWCuQlvzBXt1Bge/fudXULBcZr3TU89fXOa901eK2bkZFp1Z4z6dp24pJ2nkpTRqarOwIAwP0QNqHYyszM1JEjR3Tx4kVXtwIAAIoJHy+LGlbwU8MKfjpwPl3TtyYojcAJAAA7hE0oltwlaAqt7LmfgMta3dUdFEiIxdfVLZRIvNZdg9d70eO17hru8lq3yqq0jEwlXcrQ+Yvpiijrq783D9F/tiawwgkAgKtwNzoUS0lJSS4PmgAAQPFikUX+Pt4qV8pfVUMD5WWRIsr6qmEFDz7MCwAAJ2BlE4qlhIQEu7HFYlF4eLiCg4Pl5VV0GevpI4lF9lymZWaccnULBXLKv5yrWyiwOlXKuLqFAuO17hqe+nrnte4avNYNsFplTU9V5sXzCvDxVtkgX51NTleTcD9tO5Hm6u4AAHAbhE0odqxWq5KSkuy+Fh4errCwoj9c1MvLu8if0xgv97jzT35ZPPj/cx8fz/1PMq911/DU1zuvdRfhtW6ExTtYkpSZfF7B/j46m5yueuVZ2QQAwNXYRodiJzMz85q7zgUHB7uoGwAAUNxYfAMkSX4+V36V9vGyyN/bc8M8AABMI2xCsZM9aJJUpFvnAABAMWe5EixZ9L+AyYdfNQAAsOHHIgAAAAAAAIwhbAIAAAAAAIAxhE0AAAAAAAAwhrAJAAAAAAAAxhA2AfAolaPqqnJUXa37bUORP/exI4fVtHqomlYP1bEjh4v8+fNjxowZuvHGGxUSEiKLxSKLxaL33nvP1W2hhHpx+FA1rR6qF4cPdXUrAAAAKAI+rm4AgGewWq1aunyFvl6yRNt37tKZM2fk5e2tCuXKKTy8gpo3aaK2rVupw43tVbp0sN3cqTNmKiEhQXd07aJGDRo4rcfKUXWv+ZrFYlGp4GBVqxmhdjffqr6PPKrKVas7rQd38M4772jEiBGSJB8fH4WHh1/5/6FUKRd3ZlbFWmUkSSOeHKlnh49ycTf5s+63Dbr3wf+zjadP/kh/69o1x+tb33qbjh47pmf++YRGPDnMWB9/7tyuH1cuU+mQMnpw4JA8r1/38w9aPH+2dvyxRadOnpA1M1PlKlRQuQoVVb9RE7Voc6PaduiosHLljfVoWkxMjL744gv9+OOPOnTokM6dO6fAwEBVrVpVrVu31j333KPu3bvL19fXbl7Hjh31888/q33bm/XN3GUOP9/d9/fQug2/XvP1wMAghVcIV7MmLfRA7/667dYuhf67AQAAuAvCJkDSR4N/cHULRvQe1copdS8kJGjA4KFav3Gj7Ws+Pj4qHRioY/HxOnTkiH7fvEVTZ8zUexPe1P333mM3/5OZn+rosWOqXq2aU8OmLIFBpRT032Al8/JlnTt7Rn/uiNGfO2I077MZemvSNHXodHu+6/r4+KhWZB3bY3f1r3/9S5I0bNgwvf3229e8aYb7eePtd3V7p07y9vYu0ufds3O7Pv73BFWpVj3XsCnt0iWNeWqwVi1daPual5eXSoeU0ckTxxV39Ii2b92keZ9N1+Dhz2vI0yPt5pevWFG1IuuofMWKzvqr5CkxMVGDBw/WnDlzZLVaJV0Jo8uUKaOUlBTt3r1bu3fv1qxZsxQZGakvvvhCbdu2Nfb8vr6+Klsm1DY+d/6sDh0+qEOHD2rR0q/Vv+9DeueNibJYLMaeEwAAwFXc990SALcxbMRzWr9xo7y9vfXoIw/r/x7oq1o1asjLy0sZGRn6KzZWP/6yRt8sWeLqViVJDz/2hN2b3eSkRH27cIH+Pe5lJScl6rmh/9DSNZtVrkJ4vupWrFxFi37amPeFLnTq1CmdOHFCkvToo48SNHmIvfv2ad7X3+iB3ve5upXrenfcS7ag6a77H1S/vw9SZN368vHxUWZmpg4f2Kf1a37UysXfXDcseXLky3py5MtF3PX/nDt3Th06dNDOnTtlsVjUt29fDRkyRO3atZOfn58kKS4uTsuXL9fEiRMVExOj9evXGw2bWrdoa7ci6vLly9qxK0YvjR2t3zau0xdfzlLL5q3V//6HjD0nAACAq3BmE4Bc7T94UKt+uLLy6/nhT+nlUSNVu1YteXld+c+Hj4+PGtSrp8cHParvlyxWrx7dXdnudZUKLq3eDw7QiJfHSZIuJidp0fzZLu7KOS5evGh7HBwcnMuVcBddb7tNkvT2+xOVeumSi7u5VnJSor6a/akk6b4HH9Grb3+gGxo0tq3u8/LyUq3IOnrgkUGa+fVyPTLY3DY/U/r376+dO3fKx8dHc+fO1Zw5c3TLLbfYgiZJqlKliv7xj3/ojz/+0KRJkxQQEODUnry9vdW0cXN9+slshYWGSZJmz/3Mqc8JAABQVAibAORq567dtsfdunTO8/rAq96gvf3+RFWOqqujx45Jkp56fqTtgO+sP9mdv3BBr705Qe1u66xaDRqp6Y036dEnhmnbjh2F/rv0uKu3LSTbuW2r7etXH15stVr19ZxZevieO3RL49pqWj1Ui+ZdCaYcOSA8MeGCPn7vLd3/t1vVvn4NtYmqrOgOLfX6qKd19NDBHHtrWj1UFotFP/30k06ePKmnn35adevWVVBQkEPban766SdZLBbVqlXL9rWIiAjb4eBXf71jx46yWCx65ZVXlJ6ernfeeUetWrVS2bJlbT1c7euvv1bPnj1VsWJF+fn5qWLFiurZs6e++eabHPsZ9swQVaxVRsOeubI168v5X6j73V0U1bi66japofv699L6DWtt12dkZOg/M6eoa89bFNmomqIaV1e/R+5TzI4/8vy7X8/d9/dQxVpl9K9/v6GMjAx9/J+P1Ln7zYpoUEUNWkbq4Uf7aeeu7bbrL6ak6N8fTVLHv/VQ7cZN1aBVGz027EkdPJT7QfC79+zRY8OeVJN27VWrQSO1va2Txrz6mk6fOaN1v23I8XV+teFPDFWpUqUUd/y4ps8qeNhw7MhhvfXKKN3d+Ua1u6Ga2tapojs7ttGEl0cq/tiRa65vWj1ULz3zuCQp7ugR22s768/kd9+UJB2I3au0/4Zgt92ed5gcEBh4zddyOyD86tdjRkaG/v3vf6t58+YKDg5WeHi47rrrLm3bts12/cWLF/X666+rUaNGKlWqlMqVK6f7779f+/btu24/y5cv1/LlyyVJL730knr37p1r/xaLRUOGDNGgQYPy/LuaULZMqFo0u7IFes/eP4vkOQEAAJyNbXQAHBZ//ITqRkU5fH2pUqVUoXx5nTl7VpmZmSodHJzraoEjR4/qnv7/Zwun/Hx9lZKSoqUrVmjV6tWa+sHEQvXvHxCgMqFhOnfmtJISE6/5vlVWjRj8iL7/drG8vLwUXDrEFk45InbPbg39v/t0Ij7uyvP5B8jH11eHD+7X4YP7tWj+bL0xcaq6dO+Vc43YWPXt21cnTpxQQECAw9vgskKgy5cv6/Tp05Kk8uXL284AqlChwjVzUlNT1bFjR61bt+7KGVylS9sFW2lpaXrooYc0d+5cSVdWsJQpU0anT5/WsmXLtGzZMj3wwAP69NNPc+1t2DNDNPer2fLx8VFAQKAuJCZozdqftX7DWs2Y8oVuvfk2PTSwr35a84P8/Pzk4+OrixeTtfqn77Ruw1otmvetmjZu7tD/D9mlZ6Sr78P3aM3an221z5w5rRXfLdOadT/r6zlLVK1ykO5/eIB27NqlAH9/yWLRufPntfjb5Vq3YaOWf/OVqlWpck3tb1et0uAnhys9PV3Sldf7yZOnNP2zz7Vs5SqNeuZph3osX66cBv99gN754EN98PEU9b+/j8qEhOTr77nsm3l65dlhtlDIz99fXhYvHdy3Vwf37dWiebP19scz1f7WTrY55SqE61JqipISE+Xl5aXQbId6BwVde6B81mvbGdLT03XHHXdo9erV8vPzk6+vr06dOqVFixZp9erV+vHHHxUREaGuXbtq69atCggIkMVi0dmzZzVv3jz99NNP+v3331WjRg27uh9++KEkqUyZMnr6acf+mUjK17/7hZV1htTly5eL7DkBAACciZVNAHLVrEljWwDx6htvat+BAw7PHTLwH4r5bZ2qVK4sSRr74guK+W2d3Z8sly9f1qP/HKajx46pbJkymjrxfe3bvk1//bFFPy3/Vs2bNdWTzz1fqL/LxYvJOn/2jCSpTNmy13x/9fKl+mnVt3r6hbFas+OA1uw4oLW7Dtm9Qc9JclKihv39AZ2Ij1N4pSr68NO5+u2vY1q3+7DmrfxFTVq0VtqlSxo1bJD2XLWiJrvhw4erbNmyWr16tZKTk5WQkKA9e/bk+fzt27fX8ePH9fvvv9u+9vvvv+v48ePXfD3LRx99pJiYGM2YMUMJCQk6e/asTp06pSZNmkiSRo8erblz58pisejFF1/UmTNndPbsWZ0+fVqjR4+WJM2ZM0cvvvhijn2t+G6ZFi/7Rv8a/55idxzVvh1HtXb1JjVt3EwZGRka/fKzemX8C9q2fas++Wim9u+M0/6dx7RqyU+qVTNCKSkX9cKrI3Osn5eZn/1HO3dt138mfWqrvWLRD6pZo5aSk5P0wqsjNWLMC7qQkKA5M6Zr3/Zt2hfzh+bNmqlyYWE6feaM3nj73WvqHjp8WE8886zS09PVuGFDrVj4tWK3bdX+HTGa++kM+fr66pXxbzjc5+B//F3lwsJ0/sIFffjxlHz9Hdf/8qNeeGqIMi9f1iNDhunbddu0cW+8fvvrmBb9tFG397xLyUmJenbII3YrnH7YskfPvXJl9VKlKlX1w5Y9dn8eHvxPSVLUDfUVEBgkSfr4329pxx9b8tWfoyZNmqQ//vhD8+fPV1JSkhITE7Vx40bVrl1bSUlJevLJJ/Xoo4/q3LlzWrlypZKTk5WUlKTvv/9eFSpU0MmTJ22vyywZGRn65ZdfJEldu3Z1yzsynr9wTlu3bZYk1axRy7XNAAAAGELYBCBX1atVU78+V7ad7N6zRx1uv0Nde92lUS+/ojnzF+jPv/6yfSpfGMtWrNS27Ve2yk394H1Fd/+b7UyYG+pEafb0aQq9TkCUH/NnTbf12qRF62u+fzE5Sc+8NE4PP/aEgktfWVkSVCpYFSpWyrP23FnTdOzwIfn4+mrSZ/PVodPttpURNzRorI+/+EpVqtdQ2qVL+uCt13Os4+Xlpe+//16dOnWyza9bN/dtWAWVlJSk2bNn65FHHlHgf7c+lStXTmFhYTp27Jjef/99SdLIkSP12muvqex///8PDQ3VuHHjbKtE3n33XZ04efy6z3Eh4YLefnOiHuo3QIEBV54jKrKOpn44Q5J05OhhTf90qj79ZI569bhbvr6+slgsatq4ud5+48rzb9z0m+LijxXo73gh4YJmTp2t6O532Wo3b9pS77x5ZZXc75s36Mdf1mjuzBnq2OFmeXl5ycvLSx3at9eYZ0dIurKCKWv1UpaJkz9WSkqKypcrp7mfzlDTRo0kXdmCdctNN2nOjGlKSUlxuM/g4GA99fiVLWb/mfWZjv/3kPe8ZGZmavwLzyozM1OjXv+Xho9+VVWr1/jf9snIOvrX5Bnq2PVvSkpM1GefTHK4pywBgYF69J9X/lmfPB6n/tGddddtbfXKs8M077Pp2hXzhzIyMvJdN7vz589r4cKFuu+++2z/rFq3bq1PPvlEkrRu3TqtWLFC3333nW6//XbbP6vOnTvrzTevhGZff/213T+rQ4cOKSkpSZLUvHnBVsc5y+XLl7Vt+1Y9/Gg/nT13VpLU977+Lu4KAADADMImAHl689VXNPyJxxUUFCSr1aodu3Zp5hez9fSo0bqte081addeL48br1P/3b5VEAuXXblLU+uWLdShfftrvh8UGKihgwbmu+7ly5f1/+3ddVhU2RsH8O/QXSKISNiBrdhY69qxa3e3rq7xs9Zau11b1+6OtVvswhYLE0QBg26Y+/tj5MrADAw4wwB+P88zjxPn3vvOzJlx7ss57/F98xqrF8/F8gWyAuGWVtZo2bZTqrYWllZo16Vnho8BAKeOyOoX/dq0JYqWKJXqcVMzc/T6Vjj56oWzCA8LVbifbt26oUCBApmKIaPc3NzQokULhY/t378fCQkJMDIywrhxikcWTZw4EYaGhoiPj8eR4/8pbFPA0QltWqWukePqUggFXQsBAKpVqYGq7tVTtalRtRYMDQwBAE+eeav0nFKq6l493X03b9wIBV1dUrWp61ELgGy64eu378T7BUHAsVOnAQA9OndSmAQtUqgQWjRtkqFYu3fqCGenAoiJicGCpctU2ubOzWvwffMK1jZ50LqT8lXMWrTtCAC4dvF8hmJK0vePURg7bS4srawBAG9evsDBXVsxc8IodGpWD3XLFcbU/w1Lsy5ZemrVqoVatWqlur9OnTowNJS9V23btkURBVN5GzVqBACIjo6Gj4+PeP+XL1/E6zY2NpmOTR1u372J0pWLihfn4nZo2KIubtySjfBs3qQl+vTImjpRRERERJrGZBMRpUtPTw9j/hyOe1cvY9mC+ejcvh3cSpaAwbd6Qp+/fMG/GzehbpNmuJeskG9GJI1qqlU9dWIgSa1qyh9LbvXiuWKR44qutmhRuxJWLZqDuNhYWOexxT/rt8NCQYLArVxF6CdbnUpV8XFx8HkqS4ZUrVVXabtqHrJVx6RSKZ4+fqiwTc2aNTN8/MxK61heXl4AAHd3d1goqR9kbW2NypVlhY0fPLynsE25MuWVFjjPa2sHAChftqLCx3V1dWFjkwcAEBIaojTWtFQoVyndfZcvW0ZJfN9rGIUmSw6+8/VDaFgYAKB6lSpKj12jatUMxWpgYIAxf/4JANi1bz9evn6d7jb3b98AAISHh6FB5ZKoX7G4wsvfY4YDAD6+T10oXFWde/XH6VveWLhmMzr06Au3chVh9G20WnhYGA7u2oo2v9bExbMnM7X/KkpeS11dXdh+ey/c3VOPSAQAe3t78XpwcHCmjq9p8fHx+PQ5SLwkjQaTSCSYM30B1q/aqnKNNiIiIqLsjgXCiUhlFubmaPtbK7T9rRUAICY2Fre8vLB+81acPn8eX4OD0XfIH7h67oys0HIGJI1AyJfspDElB4f0p7MBgLGJKUy+1WbRkejA2NQUBZxdUbVWbfzWoSusrBWPcLCxtVV4f3pCQ4LFwr52+RyUtrN3+F5k+uvnTwrb2NnZZSqGzEjrWEFBQQAAR0fHNPeRNArr8xfFz8fM1Fzptnq6et/amKXbJiHFNDZVqbJvZW2SpnHKjv99mtiXr1/F6/b2yl/DtPqyMq1btsCqdevg/fQZZi9chPUrlqfZ/lNgwLf44vHlU1C6+4+JUX1qnyJGxsZo0LSlWOQ+ISEBj+/fwf7tm3F4307EREdh7JC+OHr5DmztMvb8zc3T6Cvf3gtlbZK/V8mn0eXJk0e8/jXZ+6YNNarWwsHdshGc8fHxeO/vi607N2Hlv8swbfYUFC9aEjWqpR7ZRURERJQTMdlERJlmZGiI2jVronbNmhg+Ziz2HDiIDwEBuHDpEpr8+qvW4uoxYCgGjcx4UWldHV0NRJPBGHSzLoasPFZupWzU1o/sb/zoUejapx+OnzqNu/cfoGL5ckrbJ0plSc4yFSpj2+Ezao1FFXp6eihfuSrKV64KhwJOWPPPPERHReLk4QPo2ndQlseTkouLC8zMzBAREYF79xSPvtMGfX19FHQtjMnjp8PE2BTz/5mNfkN7wvPkdeS1Tb1yJBEREVFOw2l0RKQWXTt2EK+/eq36inVJkkYgpFUYOSBAtaLJWc3SylpM3AQGKF8aPvmy8TbZ/IQyadTT+/fv02yX9Lhtnuz9fNQpT7LaP4GBykcTqVrkO6Vf6tQRp+DNnL8gzba2eWWjh5KvMqctbZPVO3v7ykd5wyykp6eH2rVrAwDOnDmDyMhILUeU2vAho+DqUhCfP3/C3IXKFw8gIiIiykmYbCIitTA1MRGvG6Soe6SjIxv9kdaqdeXKyFbzunrjhtI2V65f/5EQNUbfwABFS7oBAG5duai03Y0rngBkK86VLF02K0LLtKRaTF5eXggNVVzMPCQkRKztVL6c4rpLuZGLsxMsv9WxunbzptJ2aT2WnqSV8K7dvIlzF5X3qfKVZUmpz0GB8H6Q8ZE7SSseqmNFyaSpqwBgkMFptJo0ZMgQAEBoaCgWLVqk8nZSqVRTIcnR19fHiKH/AwDs2LMVr16/zJLjEhEREWkSk01ElCZfPz+8epP+SKU9Bw6K18u4uck9Zm4mq4mTVFRZkVbNmgIAbnndwbUbqU/So2NisGrdepVi1obGLVsDAM4cPwyfZ09SPR4VGYFNq5cCAGrV/xXmFpZZGl9GtWnTBnp6eoiJicHcuXMVtpk1axZiY2Ohr6+P5k1aZnGE2iORSNC0YUMAwJaduxCiIBn3+u1bHDl+ItPHqFi+HJo2kh1j9oKFSpNB7jU84PxtVb/5f09AfFxcmvsNTVE829RMVgNJ2eqIABD89QuePLyfbsyH9+0Sr5csrXzqX1Zr2rQpGn57v6ZNm4Z9+/alu82///6LtWvXajo0UdvfO8DJ0RmJiYlYsGROlh2XiIiISFOYbCKiND33eYnajZqga99+2HPwIPySTauKj4/HI+8n+HPsOKzZsBEAUKFcWVStLL8CWPGixQAAx06eUnhiDgDNGjUSk1R9h/6BoydPiUW3X7x8iS69+8oVZs5u2nfrDUdnFyTEx2NI93a4cuGMODLC56k3BnVtA3/fdzAwNMTQ//2l5WjT5+joiOHDZSuYzZkzB1OmTEFISAgA2YimSZMmYf78+QCAkSNHwt5OteLtucUfAwfAyMgInz5/RseevfDIW5ZgFAQBV65fR6devWFsbPxDxxg/aiR0dXXh/fQZ/D8onp6pp6eHibMXQU9PD/du30Cvts1w88pFuSLZ79+9xZ6tG9C5WX3s3iKfsC1SvCQAICI8HKeOHIQin4MC0alZPfRu2wx7tm7A21c+YvIrMTERb1/5YP7UCVjw9wQAQP4CTvilaYsfeu7qtmPHDpQsWRIJCQlo3749unTpgsuXL8u9Th8/fsTmzZtRqVIlDBgwANHRioupxyfE48vXL2leIqMyNl1PT08PgwcMAwAcOrIfz32eZf7JEhEREWUDLBBORGnS09ODVCrFOc+LOOcpm85joK8PU1NThISGyo24KOPmhg0rV4hTc5J07dgBB48cwe27d1G6SjXY5skjLvF9++IF8Thrly1B6y7d8OHjR/Qb+gcMDQxgaGiIsPBwGOjr499lS9FzoPaLDitiamaOJet3YHC3dgj8+AFDureHoaER9A30EREeDkA2tWjWkjUoXqqMlqNVzaxZs+Dn54c9e/Zg2rRpmDFjBiwtLREaGiom0jp16oTp06cj+MOPrXKW0xR0dcGy+fMwaMRIPHj0GA1b/QYzU1MkSqWIjo6Gg709pk4Yjz/HjoNhimmlqipSqBA6tm2D7bv3pNmuaq06mL9qEyaOGIRH97zQv9Nv0NPXh5mZOaKiIhEXGyu2rdeoqdy2zgULoWqtOrh55SLGDO6Nv8cMh6WVFQCgS59B6Np3EPT09CCRSHDn5jXcuXkNgOzzampmjojwMDEpDAAFnF2xdONOmJiYIjvJkycPbty4gX79+mHv3r3YsWMHduzYAYlEAisrK0RHRyMmJkZsX7JkSXh4eCjc1+07N1GqYqE0j9ev1yDMmJKxEUqd23fD4mXzEfQpEPMXz8K6lVsytD0RERFRdsKRTUSUpnq1PXDt7BlMnzQRLZo0QdHChWFgYIDQsDAYGxujkKsrWjZtgtVLFuPkwf0Kl3uvXsUdW9f9i9o1a8DCwhyfPn/Ge39/vPf3l2vn4uyMs0f+w4DeveDsVACCIMDQ0BDNGzfG4b270ajBL1n1tDOlaIlSOHDuGgaNHIfibmWgq6eHuLg4OLkURLuuvXDg7HX82qyVtsNUmYGBAXbv3o19+/ahSZMmyJMnD8LDw5EnTx40adIEBw4cwI4dO8TE4c+meZPGOHlwP1o0aYI8NjaIi4tDXts86NuzB04f/g/m5rLpoxbf6jtlxuhhf8DIyCjddvUbN8ORy3cwcMRYlC5fCSYmpggPC4WBgQGKlyqN1p26Y/Habeg5cFiqbRes3oyufQfDpVARJMTH48N7P3x47ydOrStYpBhO3XyMSXMWo1nr9ihW0g3GJiaICA+DvoEh8js5o+6vTTBl/lIcPH8DhYuVyPTz1SQLCwvs3r0b9+7dw+jRo1G5cmXY2toiPDwc+vr6KFmyJHr06IGjR4/i0aNHqFSpUvo7VSMjIyMM7CurL3X0xGF4P3mUpccnIiIiUieJoI6qoEQa5O3tjdKlS4u3Hz9+DLcUNYGSS0hIgI+P/EpIRYsWhZ5e1g/kC3qnvEZRdidNyJ4rv6UnyDDnropWtoCVtkPINPb11GYvXISlq1ajVvVq2LtVM6NUcmp/Z1/Xjpz6vQ5kv74uSBORGPwRAOATFAEAmHbpKyLj5X9Wv53TLMtjU5cVA89rO4RMiwlWfTGA7GZZwew5gjs97Ovawb6uHTmlv2f0PFrdOLKJiIhIzT5/+Yode/YCAOrVrq3laIiIiIiIshaTTURERJmwbvMWLFu9Bm/evkNCQgIAIDY2Duc8PfF75874/OUL8tjYoGPbNlqOlIiIiIgoa7FAOBERUSa88/PDuk2bMWvBQujq6sLC3BzhERFi4snC3Bz/Ll0CG2trLUdKRERERJS1mGwiIiLKhPa//w5dHR3cuH0bAYFBCA4OhpGhIZyLFEZdDw/07dEdDvnyaTtMIiIiIqIsx2QTERFRJpRxK4UybqW0HQYRERERUbbDmk1ERERERERERKQ2TDYREREREREREZHaMNlERERERERERERqw2QTERERERERERGpDZNNRERERERERESkNkw2ERERERERERGR2jDZREREREREREREasNkExERERERERERqQ2TTUREREREREREpDZMNhERERERERERkdow2URERERERERERGrDZBMREREREREREakNk01ERNnUpk2bIJFI4OrqqpXjT506FRKJBHXr1tXK8XOq9x8+4M+x41DJow6cS7rBoUgxFK9QSdth0U/K1+8d7F0tYe9qCb/377UdDhEREf0k9LQdAFF2sLBDc22HoBbd5u3QyH4XLFmKhcuWAwA+vnyhkWNQxmzatAm9evVKdb++vj5sbGxQtmxZtG/fHj169IC+vr4WIlSP3zs0w7WbV1Cjai0c3H1M2+GkKyw8HK3ad8SHgAAAgIW5OawsLWFhbq7lyNRr1aI5WL14LgDggV+wlqPJuLp16+LixYsAgAoVKuDOnTuQSCQK2yb/rAmCoNY41qxfibCwUDRp2Ayl3cqm2fbzl8/YunMjznuexctXLxAWHgYLcwvktbWDs7MrqlauhmpVasC9UlW1xqhOsbFxOHD4MM5fvISH3o/x5Wsw4uPiYGVlhWJFCqNGtWpo07IFnJ2c5La7duMm2nTtBgBYt+cI3KvXUul4t69fQd/2LVLdr6urCzNzC7gWLoIadRugQ/c+sLbJ8+NPkIiIiERMNhER5XC2trbQ1dUFAERERCAwMBBnzpzBmTNnsGbNGpw+fRrW1taZ2m/x4sXh7Oys7pBzrYNHjuJDQACsLC1xeM8uFC1cWNshUTru3buHXbt2oVOnTll+7LUbVsHP3xdOBZzTTDZduuqJ/kN6Ijjke2LPxMQU8QkJeO7zDM99nuHMuZMAgMC3oXLb6uvro0ihogAAPT3t/ew7c/4CxkyahIDAIPE+QwMDGBsb49Pnzwj69AlXrt/AwqXL0LVDB8yZNlWtx7ewtIK+gQEAIC4uFqEhwXhw5zYe3LmNXZvWYtXWfShZppxaj0lERPQz4zQ6IqIc7vbt2wgICEBAQAAiIiLw+vVrdO7cGQDg5eWF/v37Z2q/Q4cOxbNnz7BlyxZ1hpurPXv+HABQs1o1JppykEmTJiE+Pl7bYSj03t8PPft3QXBIMJwKOOOfeSvw4sE7vHnyAS8f+cHnoS92bzmA3t37wcrSKtX2Dvny4+p5L1w97wWHfPmy/gkA2LJzF3oOHISAwCDkd3DA7KlT4HXpIt4+eYxnd73w7sljHNy5Hb26doGeri4OHjmi9hgWrd2K83ef4/zd57jy+C2ueL/F6MkzoW9ggOAvnzF6YM9s2weIiIhyIiabiIhymYIFC2Lbtm3w8PAAAOzfvx8B36Z1kWZFx8QAAExNTbQcCanil19+gZGREV69eoU1a9ZoOxyFtuzYiMjICBgYGODQ7uPo1L4rLJMllSwsLFG39i+YPW0B7t98pr1Albh15w7++nsapFIpqrm748Lxo+jZtQsc8zuIbfT19VHN3R2zpk7BlbOnUaWy5mucmVtYolu/wej3x2gAwHvft7h97bLGj0tERPSzYLKJiDRKKpVi/3+H0aVPX5SpWh3OJd3g5l4VHXr0wsEjR5XWQAn69Anrt2xBzwGD4NGoMYqVr4iCbmVQvX4DjBo/Ac9f+Cg95qQRg1HOyRqTRgyGIAg4sHMLerRujNplCqGckzX+2yOrbdWnXXOUc7LGqkVzIAgC9u/YjC4tGqBGSWdUL+GEbq0a4uiB3ek+R59nTzBt7J9o4VEJVYvmR7XiBdD215pYNnc6gr9+SXPbh3dv488+XVCnbGEYGxujePHi+OuvvxAREZHucdMikUjQtWtXALI6M15eXnKPSSQSeHp6IigoCCNHjkSxYsVgYmIiV7dGlQLh9+7dQ/fu3VGpZmk4F7NDsbLOaNb6V6xZvxKxsbEKt9m1dzvsXS1RuWYZAMCVa5fQo19nlHEvBodC1hg2apDKz/POPS8MGt4XlWuVgXMxO7iWdEClmqXxW/umWLR0Hj589Fe4XVBQIP6eNRG1f62KQmXKoVCZcqjTuCmmz52HT58/q3z8JK07d4VDkWLYvf8AAGDPgYNwKFJMvCTdf+3GTfE+AHjk/QSDR45CxZoecCpRCq07d5WP89MnTJszF3UaN1U5Tn8/X5RzskY5J2v4+/niw3tf/D1mOBpVLQ33IvnQrGYFLJ83A1FRkeI2Ps+eYPyw/mhYxQ3uRfKhhUcl/LtkQaZGety+fkU8PgC8ePoYY4f0QYNKJVGliAN+q1cVCxYsQEJCgrjN1atX8dtvv8HBwQFGRkYoXbo0VqxYkWaNpPj4eCxatAjly5eHqakpbGxsULduXezbtw+ArC6TRCLB1KlTle6jQIEC+OOPPwAA06dPz/TnTiqVYt+hPejcsy3cKhdBgaK2KFWxENp3+w0H/tuX6nnMXzxbVrDb3xcAMPx/g8Ui3kmXJN5PHgEA3EqWQQFH+VpGKRkbGae6L60C4Sn745NnzzDozxEoX6MWCrqVgUejxli1br3ce3Xrzh30HDgI5arXhGup0qjbpBk2bt2m9L36e9YcJCQkwDZPHqxbsSzd+mUF8ufH5jWr02yjTjXr/iJef/Ui+yXriIiIcirWbCIijQkOCUHvQUNw4/Zt8T4Lc3N8DQ7GpatXcenqVfx39Bj+XbYEBt9qaSSZOX8B9hw4CEBWZ8TczAzRMTF46+uLt76+2P/fYSxftBDNGzdSenwBAkYP7Imzxw9DR0cHZuYW0NFJnWNPTEzEiL5dceH0cejp6cHI2BiRERF4ePc2Ht69Dd83rzF41HiFx9i4agmWzpH91R4AjIxNkJAQD59nT+Dz7An+27MDyzbvRsnSqeuxHNy1DdPGDhe3tbS0xNu3bzFr1iwcOHAg09PfkhQoUEC8HhYWlurxly9fomPHjggMDISRkVGGC4kvXrwYo0aNEk8yLcwtERUdBa+7t+B19xZ27d2OXVv2w95O+dSdfzeswuTp4yEIAizMLcXaU6rYvW8Hhv9vsHh8QwND6Onp4b2/H977++H6ravI7+CIju26yG137cYV9OzfGaFhsto2JiayUUgvXr7Ei5cvsWPPXmxaswpVK1dWORYrK0vktbVFeHg4YmJjYWRoCPNkJ9VGRoaptjl68hQGjxiJ+Ph4mJuZQS/Fc7928xZ6DxqM0G/vnaI4F2/YiYpVqiuN6+njB5j6vz8QHhoKM3NzJCYk4L3vW6xdthB3bl7Dv7v+w/VL5/G/Qb0REx0FcwsLxMfFwffta6xYMBMvnz/BvJUbVH4dUrpy4QxG9uuO2NgYmFtYIC4uFm9evsD//vc/3LlzBzt37sS6deswcOBASKVSWFhYIDY2Ft7e3hg6dCj8/PwwZ86cVPuNjIxE06ZNcenSJQCygs+Ghoa4dOkSLl68iPHjFX9eFRk/fjzWrl2LoKAgLFq0CJMnT87QcwwO+Ype/bvi+q2r4n0W5pb48vULLl6+gIuXL+DQkf1Yt3Kz+D1namqKvLZ2+PL1M6RSKczNLWBkaJTmcQKDAiAIgtJC5j/q3MWL6Dt4KGJiY2Fhbo7YuDi8fPUa0+bMxcPHj7Hqn8XYvnsPxk6eIovZzAyxcXF47uODCX9Pw4ePH/HXmP/J7fP+w4e4++ABAKB3927IY2OjUiyKvqc1JXmSTJqYmGXHJSIiyu04somINCIxMRF9Bg/Fjdu3UbpkSWz5dw1ePXqA5/fu4NXD+1gyfy5s8+TBqXPnMGPeglTbu7q4YPK4sbhw/CjePH6IJ1638O7JY3geP4bWLVsiNi4Ow8eMRUBgoNIYzp04Cs/TxzFy4nRcfvwGlx+/wdUn71CjTn25drs3r4PXjSuYvmglrj7xxdUnvjh96zHqNGgMAFi7dAHevXmVav8Hdm3FP7OmwsjYBH+MmYhzd57h5gt/3HzxATuPXUCVmrXxKSgAw3t3QlSk/IiJp48eYMb4EZBKpahcvRYOXbiJkJAQREREYOfOnQgICMC0adMy89KL3r59K163UXCSN2LECFhZWeHcuXOIjIxEWFgYnn+rOZSeo0ePYuTIkRAEAa1atcKtyw/g88gXr70/YPmiNTAzM8eTZ4/RZ1B3JCo5gfv0OQhTZ/6FDm064+41b/g88sW7Z4EYOex/CtsnFxUdhQlTx0AQBLT9vQNuXrwH3xdBePnID6+ffMDpI54YMmAYbG3zym3n/+G9mGgqXrQEjuw7hVcP7+PVw/s4uHM7ChcqiJDQUPQaOBgfMzD1cMPKFXh44xpaNmsKAGjZrCke3rgmXlo1a5Zqmz/HjkPtmjVw6dQJvLh/F2+8H2HBrBnf4vwoJpqKFSmC/3bvVBjnn326IPDjB6VxTf3fHyhVpjwOnLuOq098ce2pH8ZOmwtdXV3cvXUda/6ZhwnD+qNOg0Y4cf0Brni/w7Wnvuj3xygAwKkjB3HjsqfKr0NK4/7oh7oNm+DkjYe44v0OV5+8Q58hIwAAu3btwpw5czB48GAMHjwYAQEBCAkJwdevX9GzZ08AwPz58/HiReoVMEeNGoVLly5BR0cHc+fOFbcLCgrCsGHDMHv2bDz4luRIj7W1NcaNGwcAWLBgAT59+qTy80tMTETvAd1w/dZVlC5VBlvX78abpx9ln4UnH7Bs4WrY2ubFqbPHMX3OFHG7wf2H4bGXDxwdZAnhGZPn4LGXj9wlSYVysillHz76Y+rMiYhMNiJNnYaMGIVGDX7B7UueeH7vDl7cu4M/Bg4AABw6egzLVq/B+Kl/o2eXznh44xqe37uDp3duo0Ob1gCAlevW49WbN3L7vHztuni96a+/aiTuH3X14jnxuqOLq/YCISIiymWYbCIijThw+Aiu37qFIoULYf+Obfi1fj2YGMumeJiYmKD9779j2/q1kEgk2Lx9Oz5/kZ9uNmLIYAzq2wclihUTV1DS0dFB8WJFsWLRAjSoVxdRUVHYuW+/0hiiIiMwavJM9BgwFGbmFrJjm5ohr738SJuw0BAsWrsNLdt1gtG3GO0dHLFg9SbktXeAVCrF6SMH5baJjAjHohmTAAALVm9C3z9GwdbOHoBslEWpsuWxatt+lCpTHoEfP+DAzq1y2y+fPwMJCQlwKVQEKzbvQcFv01j09fXRsWNH7Nq1CyEhIaq+3KkkJCTg33//BSB73dzd3VO10dHRwdmzZ1G/fn1xJEGxYsVU2v+YMWMAAB4eHti/fz9cnFwBAAYGBmjXuiNW/rMWAHD7zk0cP6W42G9MbAwa/9oUSxashGN+2Um3rq4uXF0KpXv8Z8+fIiIiHCYmplgyf6XcNqYmpihXpgImj5+OBvUaym23ZMVChIaFwsrSCvu2H0aVytXEx6q5u2PP5s0wNzNDcEgIlq3WbA2fYkUKY/Oa1XKFxAu5ugIAlq5ejdCwMFhZWmLv1s2oUul7DZvkcYaGBGP9isVKj2Fn74Dlm3ajcLESAAAjY2N07tUfTX5rC0CWSHUrVwlzV6xH/gKyVQdNTM0wdMxEccTUycMHMv0c3cpWxNwV6+HwbfqXqZk5ho2bLNYTGz9+PHr06IGlS5fCzs4OgCz5s27dOhQsWBBSqRR79uyR26evry/WrpX1r7///htjxoyBmZkZANkKikuWLEGPHj0y9PkZNmwYHB0dER4ejhkzZqi83YH/9uLazSsoWrgYDu46hoa/NIaJsWwEmqmJKdq36YQdG/dCIpFg07Z1+PRZ9URWkl7d+yGfvay+0ep1y1G6clF06tEGcxfNxInTxzK1T0XKlSmDVf8sRoH8+QEAZmZmmDB6FKq6y0b4zVqwEO1+/w0zJk+CbZ48AAArS0ssnDUTzk4FIJVKcfj4Cbl9PveRJc0MDQxQtEj2KpgfHhaKbetWYd2yhQCAPHnt4FEveybEiIiIciImm4hII3buldVN6dG5s9IaHeVKl0bxokURFx+PqzduZGj/Db7VEbrldUdpGwtLK7Tr0jPdfZV3r4oqNTxS3W9gaCiOgnrx9IncY2ePH0F4aChKlC4rV/MjOT09PTRu1QYAcC3ZX8/DQkNx7eJ5AEDPgX+ICa7kGjVqhOrVlU+PUiYiIgI3btxA06ZNxZEdPXr0QJ5vJ4fJdevWTW6qnaoePnyIp0+fAgAmTpyocOpbowZNxBEZBw/vU7qvYYNHZvj4AGBpIatpEx8fh6/BX1XaRhAEHD4mSxp279Ibdt+Sg8nld8iH7p07AQAOHTuWqdhUNbhvX4WvnSAIOPLtpL1bp46wy5s3VZvkcZ5KIxnUtd9gGBimnsKXfHRf7yF/Kpya9b3ve6fzTJTrPXi4wn03avR9+quiKW+6urr45RfZ5+rhw4dyj+3fvx9SqRQmJiYYMWKEwuNOmjQpQ3EaGxuLtZ1Wr14tNyowLTt2y5LIPbr2gYWFpcI25cpUQPFiJREXF4er1y9lKC4AyGOTB4f3nUQdj3oAgKioSJy/eBaLls5Dz/6dUbpyETRsUQe79m4Xp+RmxtAB/RS+V3U9vn83Dvs20ik5XV1d1Pr2XfX0mfzIyOBvCT8LC8VTmLPSyH7dUL9icdSvWBy1Sruilpsr5v89AfFxcTA1M8e8FRtgaJT2VEYiIiJSHWs2EZHaJSYm4u79+wCAhUuXYekq5cVeQ0JldXPe+6eeCuT99Cm27tyNW3fuwO/9e0RGRaUqQpvWVCe3chWhn6IWlCJlyiuvzWP3bRRUWGiw3P33vW4CAN74vED9isWVbh8bEy2L0/97Yd6njx+IJ4VVatRWum39+vVx/fp1pY8nKViwoNLHGjRogGXLlil8rGbNmunuW5GkYuN6enqoU6eO0nZ1POrh3oM7ePDovsLHjY2MUbZ0+UzF4OpSEEULF4PPqxdo+tsv6NG1N+rV/gUlS7gprfv0zu8tgkNk72PtWnWV7rt2zRpY8e9aBAeHwNfPD85OaRdlziz3ShUV3u/r5yeepNeuWUPp9klxhgR/xXvfdyjg7JKqTZlyio+Rx9ZOvF66XAXFbfLK2oSHhiiNIT2lyys+vr29LNFnY2ODQoUUj2RLahMcLP/Zu3v3LgCgcuXKMDU1Vbht4cKF4eTkBD8/P5Vj7dWrFxYuXIhnz55h0qRJ2Lp1a5rtExMTceeerB7dgn9mY8mKhUrbhnz7/njvr3o8ybk4uWLP1kN48fI5Tp05Dq+7t/H4yUNxfw8e3cfw/w3GwcP7sHntThhlImlSoWzqunIAkPdbotraygouzs6K29jaAoBYBy07ClPSj4u7lcGKzXtSjXglIiKiH8NkExGpXXBIKGLj4gB8TyalJzo6Wu72hi1bMWnGTDEpI5FIYGFuLhbYjYmJQXhEBKJSbJeczbcToPSYfpuCo4jutyl8CSlW5foU+BEAEBsbg9hPMekeIyY6Srz+Ndm0F7t8DoqaA4DKo45sbW3FBIu+vj5sbGxQtmxZtG3bFi1btlRaUDhp2lJGBQUFicc1VDBqJkn+fLLpOJ+VTPOxtrbJ9GgHXV1drFm2AT0HdIGv3zvMmDsVM+ZOhbGxCdwrVUGzRi3Qvm1ncUqTLI7vq7c52OdXum+HfN9POj9/+aqxZJOtgtFmScdMks8+9eirJMnj/Prlk8Jkk4mZ4lGFSf0akE1tU9hG91vfT8j4inTp7Ttpaqx5GiuTJbVJuSJeUk2l/PmVv4cA4OjomKFkk66uLmbOnIk2bdpgx44d+N///oeyShIwABAcEozYONmKiyEqJuRSfs9lVLEixVGsyPfkdlBQIE6eOYalKxfDz98XnpfPY87C6Zj618wM79tMyfdg0vugLLEHQCxuHx+fIHe/tZUVANkCBVKpVKujm9btOQL36rUAAKHBwXhw9xYWz5qK596PMHPCKCz8d0uGFiggIiKitDHZRERqJ5V+Lwi9ff061K+jfPSOIi9evsTkmbMglUrRokkTDO7XB6VKlJBbsW7Hnr0YNeGvNJdG19XR3IlDYqIsCdaoxe8/tFqXOty+fRuu32r9ZIS2T6x+9P1xK1UGV8954cz5k7hw8Rxu372F5y+e4tIVT1y64omlqxZj24Y9KFXCTU0Rq5e2X/+cThOrsrVu3RpVq1bFzZs3MW7cOBw/flxp2+Qrl+3ctB/16zZQezzpsbOzR/cuvdG4YXPUa1IDnz9/ws492zB5/HStT1sDgOJFiwIAYuPi4PPyFYoXK6rliGQsra1R+5dGcCtXEe0a1sKF08fx75L5GDRynLZDIyIiyjW0/0uEiHIdaysr8a/h7z8oXylLmaMnTyExMRFFCxfG6iWLUb5sWblEEwAEJRulog2236YYJZ8epyqbZCukBQV8VNrO398/44FlgaQRUZ8/f0ZsbKzSdh8CZO99yhXh1MnAwADNGrfEgtlLcPHUdTy5+xrzZy6GtZU1/D+8x7BRA8W2tslGun0IUP7aJp+aaZtHtaXa1Sn5MdOaJpr8MZs8mnuNs5u832pYfUjnuyWzn5+5c+cCAE6cOIGLFy8qbWdtbfP9e87fN1PHUhe7vHZo/KtsJcSQ0BB8/qLd78ckHjW+1507fuaMFiNRLI9tXgwbOxkAsGHlP/D30+77SERElJsw2UREaqevry/W/zhz/nyGt//wUZaAcStZQulf5y9fvZb5ANWgvHtVAMCTR/fxKVB5QkCRkqXLic/r1vXLStudz8RrlxUqV5bVuEpISEjzZPzSFU8AQPmyimsCaYKNtQ26d+mNieP+BgA88n4oFhB3cXKFtZU1AODyVeVxJ/Uta2srjU2hS4uzk5M4/Sj50vEpJcVpZW2jcApdblWxoqwOlJeXFyIjIxW2ef36dYam0CVXp04dNGnSBAAwduxYpe309fXFIvinzp3M1LEkOrLRWWmN0FSVqcn3aXCGKtSqywrly5ZFhXKy/ws2bt2GL19VK+b/I4XOM6pF245wcimIuNhYrFw4K8uOS0RElNsx2UREGtG1Y3sAwDnPizjn6Zlm2+AUS5QnrV739PkLhSdh5y5exLWbN9USZ2b92uw3mFtaIiE+HgumpT2dTyqVIixZ7SoLS0tUry1bWWrLmuWIjUld8+ns2bO4dk27CTVlypYti1KlSgEAZsyYgcRk04mSnL1wGnfvywqJ/96yrdpjSGtEFQAYGX1f4U/n2wm9RCJBq+atAQBbd2xEUFBgqu0CAgOxddduAMDvzZurK9wMkUgkaNlUNkpl267dCPqUuuZV8jiTVjz8WbRu3Ro6OjqIjIzEkiVLFLaZOTPjNYuSmz17NnR0dHDz5k0cOKB8tb9unXoCAM5dOI2zF06nuc/gkNSJFnMzCwBpF9a+cesaopLVfFMkMjICx08eAQA4O7nA0tIqzfZZafK4sdDV1cWnz5/Rd8gfCAsPT7P9h48B6DVwcBZFJ5vO2mvwcADAiUP78Obliyw7NhERUW7GZBMRZciXr1/TvISGhQEA2rRqhdo1a0AQBPQeNASLV6xEQOD3k/uoqChcvX4D46dMRbV6v8gdo15t2VLbz318MH7K32IyKioqClt27kK/ocNgbW2VJc9XGQtLS4yZMhsAcPLwAQzt0R4P73mJf5GXSqV47fMcm9csR+tfquNSipEPQ0b/BV1dXbx5+QJDe3bA21c+AGSjhfbs2YP27dvD6tvoluwoaarR5cuX0bZtW7zzewtAVsx536E9GDisDwDAvVJVNGmo/qTNoSP70bxNQ2zZvgFvfd+I9ycmJuLCxbOYOXcqAKByxSqwsrQWHx8+ZBQsLSwRHBKMtl1b4fad70nLW3fuoH33nggNC4O1lRWGDuiv9rhVNWzQQFhaWCA4JATtu/fE7W8rsKWM09LKGr0H/6m1OLXBxcUFffrI+tfkyZOxYMECREREAAC+fPmCkSNHYsOGDT/0+SlXrhw6d+4MADhy5IjSdm1/74DatepCEAT0GtAFi5bNR0Dg96mxkVGRuHLtEsZNGoUqHuVTbV+ieEkAwNET/4kr1qW0duMqVKrhhvFT/oeLVy4gPDxMfCw8PAz/HT2AZm0awu/bVL5B/f7I8PPVpGru7pg+8S9IJBLcuH0b9Zu1wKZt2/Hh4/cRofHx8bh99y4mzZiJmr82xI3bt5XuLyIsDMFfv6R5yehIsZZtO8EuX34kJiZi1aI5mX6uRERE9B0LhBNRhpSuUi3Nx91KlsDZI4ehq6uLdcuXY8jIUThz4QLmLf4H8xb/A3MzM+jo6CAsPFw8IdDTk/8q8qhRA781b4ZDR49h844d2LxjBywtLBARGYnExESULV0aHVr/jr+mTdfY81RFy3adEBMTjXlTx+PKhbO4cuEsDAwNYWJiioiIcLkV7FIWM3YrVwETZi7AjPEjcevqJbSqWwWWlpaIiYlBbGwsSpQogf79+2PkyJFZ/bRU0rx5cyxatAijRo3CoUOHcOjQIVhaWCI6Jhpx31YiLFnCDetWbtZIIWxBEHD7zk0xWWRoYAhTU1OEhIaICb989g74Z94Kue3yOzhi07870KNfZzx/8RTN2zSEiYlsxbqoKNnoEUsLC2xYtUJutbeslt8hHzasWoleAwfhuY8PWrbvqDDOf9Ztg71D2quy5UaLFi3C06dPceXKFfzvf//DuHHjYGFhgZCQEAiCgIkTJ+LSpUu4dOkSjIyMMnWMadOmYc+ePWJ/VkRXVxcbVm3FoD/74cy5k5i7cAbmLpwBc3ML6EgkCAsPU/o9B8hGRh34by9u37mJUhULwzZPXhjoy6bAeV199G07fXwN/ooNm//Fhs3/AgDMzMwhCAIiIyPEfeno6GBw/2Ho3b1fpp6vJvXq1hUO+fJh3JSp8P/wAeOn/o3xU/+GkaEhjIyMEBom/zp169hR6b7+7Nsl3eNdfvwWFpaWKsenb2CAHgOGYv7fE3D66CH0+2MUipbMngsLEBER5RQc2UREGmNuboYta9dg2/q1aNWsKRzz50dcXByio6PhYG+POrVqYcLoUbhyOnW9kxWLFmLaxL9QqkRxGBoYIDExESWLFcOE0aNwePeuNJfhzkrtu/XGf5630WPAUBQvVRoGBgYIDwuFiYkp3MpWQKde/bFmx0E0aZV6KlnbLj2x+eBJ1GnQGJZW1oiNjYWLiwvGjx+PW7duwdraWsERs48RI0bAy8sLXbt2hWP+AoiOiYaRoTEqVXDHtEmzceq/C8hn76CRYzf6tQmWL1qDju26wq1kGZhbWCAsPAxmpuaoUK4Sxo6aiEunb6BokWKptq1RrRaunLuFQf2GoliR4pBKpRAEAUULF8agvn1w6dQJVHN310jcGVGjahVcOnUCA/v0RtHChRXGWbFqDW2HqRVmZmY4d+4c5s+fj7LfFhAQBAF16tTBgQMHMH36dIR8GxGZ2RFOBQsWxMCBA9NtZ25ugW3rd2PHxn1o1bw1Cjg6IS42FtEx0XDIlx91PerjrzFTcPW8V6ptq1etie0b9qJ2rbqwtLDEp89B8PP3FUcpAcCKxf9i/44jGDZ4JDxq1kF+B0fEx8UhNjYGVpZWKF+uIgb0GYKzxy5j0rdaZdlR418b4MaFc1gwcwaaNmoIpwIFoKOri6ioKNjmyQOPGtUxbuQI3Dh/DtMmTsjy+Np06QFrmzwQBAErObqJiIjoh0kEdVSlJNIgb29vlC5dWrz9+PFjuLkp/4tjQkICfHx85O4rWrSowr8qa1rQu7D0G2VT0oTU9WxygiDDnLsqV9kCVtoOIdPY17Ujp/Z3Tff1iIgI5MmTB3Fxcbh06RI8PDzUtm/2de3Ibn1dkCYiMVg2ZdInSDbCbNqlr4iMl/9Z/XZOsyyPTV1WDMyei1SoIiZ4kbZDyLRlBQdpO4RMYV/XDvZ17cgp/T2j59HqxpFNRERElKssWrQIcXFxsLGxgXs2GKVGRERE9LNhsomIiIhylPDwcHTs2BEnT54Up8sBwLt37/C///0PU6dOBQD8+eefma7ZRERERESZxwLhRERElKMkJiZi9+7d2L17NwDA3NwcgCwJlaRNmzYYP368VuIjIiIi+tkx2UREREQ5ipmZGZYvX44zZ87g8ePH+PTpk2zhAQcHVK5cGd27d0ebNm1SrQJJRERERFmDySYiIiLKUfT09DBkyBAMGTJE26EQERERkQKs2URERERERERERGrDZBMREREREREREakNk01ERERERERERKQ2TDYREREREREREZHaMNlERERERERERERqw2QTERERERERERGpDZNNRERERERERESkNkw2ERERERERERGR2jDZREREREREREREasNkExERERERERERqQ2TTUREREREREREpDZMNhERZVObNm2CRCKBq6urVo4/depUSCQS1K1bVyvHzyl27duP5m3bo2i5CnAoUgwORYrh342btB0W/aSGjRoEe1dLDBs1SNuhEBER0U+MySYiSteCJUvFk2jKHpISUSkvBgYGyJcvHxo2bIh169YhPj5e26H+kN87NIO9qyV+79AsU9ulvLiWdECV2uXQf2gvXLh49ofjW71uPUaMG4879+8jJjYWtnnyIK+tLUyMjX9439lJOSdrlHOyxqpFc7QdSoZ5enrKfUYOHTqUZntXV1dIJBJMnTpVrXE89n6I+YtnY836lSq197x0DgOH9UHVOuXhWtIBLsXtUblmGTT57ReMnTgSB/7bh89fPqs1RnV78uwZZsybjyat26BM1epwLumGYuUronajJhj2vzE4eeaswu+o1p27wqFIMbTu3DVDx+vTrrnYV5NfqhZzRLOaFTBmcG9c9TynrqdHREREadDTdgBE2YHruGPaDkEtbg3y0HYIpAW2trbQ1dUFAERERCAwMBBnzpzBmTNnsGbNGpw+fRrW1taZ2m/x4sXh7Oys7pCzjL6+Pqwsvz/34JCveOf7Fu983+K/owfQpWN3zJ/+FyQSSab2v3LdegBAnx7dMWXcWOjr66slbtKcCRMmoEWLFuJnJqs8fvIIC5bMgZOjMwb0Gay0XWxsLIaO7I/Dxw6J9+no6MDSwhIBQR/h5++Lu/e9sGnbeowePg7/GzFebns7O3sUKVQUdnb2mnoq6YqIiMCYyVNw6MhRCIIAAJBIJLAwN0dMTAx8Xr2Cz6tX2HvwEFydnbFi0UJULF9ObcfX09eHpdX3z31o8Fe8932L975vcerIQbTu1B2T5/6T6c89ERERpY8jm4iIcrjbt28jICAAAQEBiIiIwOvXr9G5c2cAgJeXF/r375+p/Q4dOhTPnj3Dli1b1BlulnKvWBWPvXzEi+/zIJw+4olqVWoAALbv2oKde/dlat+fv3zFp8+ykSVdO7RnoimHePr0KTZv3qztMJT6e/YkMdHUqX1XnD9+BX4vPuHZ/bfwfR6Eq+e8MOvv+ajqXl1hsmTi2Km4et4LE8dOzdrAvwkJDUXzdh1w8PARAMBvzZvhwI7teOv9CM/ueuHtk8e4d/UyFs6aiVIliuOtry+87t1TawzlK1XB+bvPxcutlwHYeewCKlapDgA4sHMLDu7eptZjEhERkTwmm4iIcpmCBQti27Zt8PCQjXTbv38/AgICtBxV9qCrq4tyZSpg89odsLG2AYBMJ5uiY6LF66YmJmqJjzSrefPmAIApU6YgJiZGy9GkFhERjm07NgEAunfuhX/mrYBbqTLQ05MNRNfR0UGRwkXRp0d/HN57EkMGDtditIoNGTkKz318oKenhzVL/sGqfxajehV3GBgYiG3y2dujc/t2OHvkMOb8PRWGhoYajUlXVxelypbHkvU7YPXtc39o11aNHpOIiOhnx2QTEWmUVCrF/v8Oo0ufvmLNDjf3qujQoxcOJptikVLQp09Yv2ULeg4YBI9GjVGsfEUUdCuD6vUbYNT4CXj+wkfpMSeNGIxyTtaYNGIwBEHAgZ1b0KN1Y9QuUwjlnKzx354dAL7X91i1aA4EQcD+HZvRpUUD1CjpjOolnNCtVUMcPbA73efo8+wJpo39Ey08KqFq0fyoVrwA2v5aE8vmTkfw1y9pbvvw7m382acL6pQtDGNjYxQvXhx//fUXIiIi0j1uWiQSCbp2ldU7EQQBXl5eco9JJBJ4enoiKCgII0eORLFixWBiYiI3UkKVAuH37t1D9+7dUalmaTgXs0Oxss5o1vpXrFm/ErGxsQq32bV3O+xdLVG5ZhkAwJVrl9CjX2eUcS8Gh0LWWVLY2MrSGhXLVwYAPPdR3pcUuXbjJhyKFEOVOvXE+6rUrS/WNXNPdn9S7ZkFS5YiPj4eq9etR6PfWqN4hUpwKFIM127clNv3sVOn0K1ff/GzUqZqdXTr1x/HT59WGk/y/g4A/+3ZgW6tGqJmKWfUKu2K/p1+w50bV8X2CQkJ2LHxX3RsWhc1SjqjZilnDOneDk8fPcjQ65Ak+ecoISEBW9euRPvGtVGteAHULV8Uf/bpgudPHonto6OjMGPGDJQuXRqmpqbIkycPOnTogFevXqV5nEePHqFDhw7Ily8fjIyMUKhQIfzxxx8ICgqSq8uUlkmTJsHMzAzv37/HsmXLMvV8AcDX7x0m/j0OtX+tioKl8sO1RD7UrF8Zf00di/f+fqna27taYvj/ZO+Pn79vqlpi8xfPBgD4vHqB2DjZ56bxr+nXKTM2Sl0bLK0C4cn7Y0JCAtZs2IhfW7RC4bLlUbpKNfQcOAjeT5+K7aOio7F4xUrUbdIMhcqUQ6nKVTBg2HC8feerMJ5zFy/i/MVLAIARQ4egRdMmacYvkUjQo0tndOvYId3nqg4WVlYoU6ESAODVi2dZckwiIqKfFWs2EZHGBIeEoPegIbhx+7Z4n4W5Ob4GB+PS1au4dPUq/jt6DP8uWyL3V28AmDl/AfYcOAgA0NPTg7mZGaJjYvDW1xdvfX2x/7/DWL5oIZo3bqT0+AIEjB7YE2ePH4aOjg7MzC2go5M6x56YmIgRfbviwunj0NPTg5GxMSIjIvDw7m08vHsbvm9eY/Co8QqOAGxctQRL50yDVCoFABgZmyAhIR4+z57A59kT/LdnB5Zt3o2Spcum2vbgrm2YNna4uK2lpSXevn2LWbNm4cCBA5me/pakQIEC4vWwsLBUj798+RIdO3ZEYGAgjIyMMjwNbPHixRg1apSYMLQwt0RUdBS87t6C191b2LV3O3Zt2Q97u3xK9/HvhlWYPH08BEGAhbllltbRSYo78dvrryp9A33ktbVFYmIivgYHAwBsrK3F2PPYpK6PFRsbizZduuH23bvQ09ODmampXGIkLi4Ow/43Bv8dOw5ANoIl6bNy9oInzl7wxO8tmmPJvLlpvk+TRgzG4X07oaenB0MjY0SEhuLmlYu4c+MqFq3diuoe9TCsd2dcv3Qe+gYG0NPTR3RUJK5cOAuvG9ewcd8xlCpbPkOvR5KE+HgM7tYWN69cFPcd/OUzLpw+jptXL2Hd7sNwdHbBgM6/49njhzAyMoJEIsHXr1+xZ88eeHp64vbt2wprhB08eBAdOnQQi0mbmZnh48ePWL58Ofbv349Zs2apFKOdnR1GjRqFv//+G7Nnz0a/fv1gZWWVoee579AejBwzVEwKGRoYQkdHBy9f++Dlax/s2rcd61duRt3av4jb5LW1Q0xsDMLDw6Cjo4M8NrZy+zQ1NU11nA8B/hmKKyPiExLQuXcfXL52HQb6+tDT18eXr19x6uw5XLl+A/u2bYFzgQLo0KMXHj95AiNDQ0AiQXBICA4fP4FrN2/hxMH9KJA/v9x+N26VTU2zMDfHwN69VI5H0feypoif+8SMfe6JiIgoYziyiYg0IjExEX0GD8WN27dRumRJbPl3DV49eoDn9+7g1cP7WDJ/Lmzz5MGpc+cwY96CVNu7urhg8rixuHD8KN48fognXrfw7sljeB4/htYtWyI2Lg7Dx4xFQGCg0hjOnTgKz9PHMXLidFx+/AaXH7/B1SfvUKNOfbl2uzevg9eNK5i+aCWuPvHF1Se+OH3rMeo0aAwAWLt0Ad69ST3q4sCurfhn1lQYGZvgjzETce7OM9x84Y+bLz5g57ELqFKzNj4FBWB4706IipQfqfT00QPMGD8CUqkUlavXwqELNxESEoKIiAjs3LkTAQEBmDZtWmZeetHbt2/F6zY2NqkeHzFiBKysrHDu3DlERkYiLCwMz58/V2nfR48exciRIyEIAlq1aoVblx/A55EvXnt/wPJFa2BmZo4nzx6jz6DuSExMVLiPT5+DMHXmX+jQpjPuXvOGzyNfvHsWiJHD/pep55sRIaHBuPfgDgDAxckpQ9u6V6yIhzeu4eTB/eJ9Jw/ux8Mb177dfyDVNhu378CT58/xz9w5eHH/Lp7euY3Ht26gZIniAIDZCxfhv2PHIZFIMGLoEDzxuoWnd27D+/ZNDBs0EABw8MhRzFv8j9K4Lpw5jtNHD2HSnMW4+sQX15764j/PWyhVpjwSEhIwZ/JYLJwxCU8e3sP8VRtx/dl7XH/mh53HLsDJpSBioqMwd+q4DL0Wye3euh7PvR9hwepN4r63HzmHAs6uiIqMwLyp4/D3mOEICw3BqVOnEBkZiYiICJw9exZ58+ZFUFAQJkyYkGq/r1+/RteuXREfH4+KFSvCy8sL4eHhiIqKwpkzZ2BgYICRI0eqHOeoUaOQN29eBAcHY86cjK2ud+bMGfwxcgASpYkYOmA4bl9+iHfPA/Hm6UdcPeeFls1+Q0REOPoO6Sk3wumxlw9mTJYdy9GhgFwdscdePhjcfxgAoETxUjA2lk3JXLhkrthH1W3z9h14/PQp1i5bipcP7+Plg3s4cWAfXJycEBkZicnTZ2L0XxMRGhaGnRs34NWjB3j18D72bNmEPDY2+PzlC2YvWCS3z4SEBNy4LRtBWbtmTZhkw6mlYSEheHz/LgCggLOLlqMhIiLK3ZhsIiKNOHD4CK7fuoUihQth/45t+LV+PXE5eBMTE7T//XdsW78WEokEm7dvx+cv8tPNRgwZjEF9+6BEsWJy9UqKFyuKFYsWoEG9uoiKisLOfftTHloUFRmBUZNnoseAoTAzt5Ad29QMee3lR9qEhYZg0dptaNmuE4y+xWjv4IgFqzchr70DpFIpTh85KLdNZEQ4Fs2YBABYsHoT+v4xCrbfVn9Kqg+yatt+lCpTHoEfP+DATvn6IMvnz0BCQgJcChXBis17ULBIMQCy1dM6duyIXbt2ISQkRNWXO5WEhAT8+++/AGSvm7u7e6o2Ojo6OHv2LOrXry+OLChWrJhK+x8zZgwAwMPDA/v374eLkysAwMDAAO1ad8TKf9YCAG7fuYnjp44o3EdMbAwa/9oUSxashGN+2SgsXV1duLoUUv2JZlBiYiIePLqHHv0642vwVwBAhzatNXa8JJGRkVi5aCE6tGkNYyMjALLRUNZWVvgYEIB1m2VF2IcO6I8xfw6HpYWsv1pZWmL8qJEY8G2UyJqNmxAYFKTwGOGhoZg87x+07dJT7MeuhYti3soNAIAPfr7YtWkt/lm/HQ2b/wZ9fX1IJBKUKlsek+b+AwC4f/smAj9mbkRNeGgoFq/bhl+btRL3Xbp8RUyet0S2b69buOZ5Dmu2H0TDhg2ho6MDHR0d/PLLL2LS58CBA+LopSSzZs1CVFQU7OzscObMGVSqJJsGJZFI0KBBA5w6dQpRUVEqx2lubo6JEycCAJYuXYoPHz6otJ1UKsWQIUMglUoxe9oCTBo/Dc5OLuL0vSKFi2Ltis1o1KApwsPDsHrdCpVjSmJsZIw/h44CAHwM+IDGreqj1i/uGDF2KDZvW48Hj+4hISEhw/tNKTQsDBtXrUTzJo3F96p82bJYMGsGAOD23bu4cOkydm/aiLoetcT3yqNGDfz1v9EAgOOnT8u9V+/9PyAyMhIAULpUyR+OUZ0SExPx5OF9DO/TGSHfPvet2nfRclRERES5G5NNRKQRSUWXe3TuDAtzc4VtypUujeJFiyIuPh5Xb9zI0P4bfKsjdMtL+V/+LSyt0K5Lz3T3Vd69KqrU8Eh1v4GhoTgK6sXTJ3KPnT1+BOGhoShRuixq1v0l1baAbPpf41ZtAADXLp4T7w8LDcW1i+cBAD0H/iEmBpJr1KgRqlevnm7sKUVERODGjRto2rQpHjyQ1eDp0aMH8uTJk6ptt27d5Kbaqerhw4d4+q2uy8SJExVOfWvUoAkqlJMlBQ4eVl6Ae9hg1UekZMbtuzdRunJR8eJc3A4NW9TFjVvXAADNm7RE725dNRoDABQvWhQNf6mv8LFjp04jISEBRoaG+GPAAIVt/hwyGIYGBoiPj8fRkycVtnFwLICmv7VLdb+Ta0E4u8oSeBWrVBdX5EqucrWaMPhWpPnFU2+VnlNKFdyrpbvvBs1awrlg6mRio0ay6bDR0dHwSVZDSxAE7N8vSygPGjRI4Qi94sWLo3379hmKdeDAgShYsCCio6MxdepUlba5dOkSfHx8kMcmD7p27KG0Xfs2HQEAnpfOKW2Tlj+HjMbMqfNgbSWbjunz6gV27N6KMRNHomGLuihZoRBGjB2Kt75vMrV/AKhSuRKqVq6c6v7qVarA8NuU5uaNG6Gga+rRP3U9agEAYmJi8PrtO/H+4JBg8XpGpyaq2/07t1C/YnHxUqVIPnRqVg93b10HADRo2hIde/bTaoxERES5HWs2EZHaJSYm4u79+wCAhUuXYemq1UrbhoSGApD9VTwl76dPsXXnbty6cwd+798jMioqVUHxj2mssuZWriL0U9SCUqRM+dQnXUnsvo2CCgsNlrv/vpessPMbnxeoX7G40u1jv61Y9tH/vXjf08cPxDpNVWrUVrpt/fr1cf369XSil60+p0yDBg2UFkKuWbNmuvtWJKnYuJ6eHurUqaO0XR2Perj34A4ePLqv8HFjI2OULV0+UzGoKj4+Hp8+px4JJJFIMHvafPTq1g/SBOVTMdXFvVJFpY89eCQrnl2ubBmYm5spbGNlaYmyZUrj9p27ePDoscI2pcpWUFog2yZvXvi+fQ23corj0NXVhZV1HgQFfEBYaEgaz0S50uUrpbtvZce3t7cXrwcHf/+svX79Whzhl1Zfq1u3LrZuVX11MQMDA0yfPh1du3bFhg0bMGrUKBQvrvxzDABXr8qKrIeFh6FsFeVt4+PjAEBhoXBV9e05AF06dse5C6dx9fpl3H1wB8+fP0V0TDTCwkOxY/dWHDy8H/8u34iGvzTO8P4rlE1dQw6QvVc21tb4GBiI8mXLKGyT1/Z7vanQsNAMHzsrJMTH48snxZ/78dPnoUOPvlqIioiI6OfCZBMRqV1wSChi42QnXEnJpPRER0fL3d6wZSsmzZgpJmUkEgkszM3FQuIxMTEIj4hAVIrtkrOxtVX6WHKmZopP8AFA99sUvoQUU3s+BX4EAMTGxiD2U/pLqMdEf5/m8/XzJ/G6XT4HpduoOurI1tZWHF2kr68PGxsblC1bFm3btkXLli2VJiDs7OxU2n9KQd+mcdna2qa5ZHn+fLLiwZ+TPd/krK1tNF4YuEbVWji4+xgAWeLpvb8vtu7chJX/LsO02VNQvGhJVKtcVKMxAICtgpFlST5/kU3rcUiWcFEkf75839orXuHQ1FR5P9bTlfXjtPq6np6sDyXEZ26alir7VhZj0lRZAHJTsz59+t538qcoRp2co6OjynEm6dy5M+bPn48HDx5gwoQJ4ggqZZKm2ylLYKYUHaP8u0kVxkbGaN6kFZo3aQVANjX23oM72LpjE3bv34Ho6CgM+KM3bnreg51d2n0nJTMFBcmTJH3nmanwXiXvK0kjsQD80BRgdahcrSbW7z0KQPZ+fXzvh/07NmHzmuVYPGsqChcricrVM5dsJyIiItUw2UREaieVfi8IvX39OtSvo3z0jiIvXr7E5JmzIJVK0aJJEwzu1welSpSQW7Fux569GDXhr1QjnZLT1dHcymZJKxk1avG7WBNHW27fvg1XV9cMb5eVK78pPL4G3x9F9PX1UdC1MCaPnw4TY1PM/2c2+g3tiQvHDqeZDFIH3SxcbSu3UpY0/ZH9zZ49G02bNsWBAwdw8+ZNVK1aVWn7pEL3FctXxolDmZsi9yP09PTgXqkq3CtVRQFHJyxcOhdRUZE4eGQ/BvQZnOXxpFTAMT9MTU0RGRmJx0+eajsckb6+PpwLFsKIv6bB2MQUqxbNwf8G98K+M1eRxzavtsMjIiLKtfjrl4jUztrKSvzr93sVi+8md/TkKSQmJqJo4cJYvWQxypctK5doAoCgz5/VEmtm2eaVjQpKPj1OVTbJTnCCAj4qbefvr7mlz39E0oioz58/IzY2Vmm7DwGy9942G57QDR8yCq4uBfH58yfMTWOFt6xgm0dWh+hDGlNCkz+u6cRYdpI37/e+k1Yh78x+Vpo0aYK63+q/jRuX9kp8+b6NLPuR6XHq0r1LL/H6q9c+abTMOnp6eqjmLpuSfOnq1QwVbc8qfYaOhJNLQXz9/AkrFszUdjhERES5GpNNRKR2+vr6Yk2QM+fPZ3j7Dx9lCRi3kiWUTrO6fPVa5gNUg/LushEQTx7dx6fAtJMEKZUsXU58XreuX1ba7nwmXrusUPlbYeGEhARcvHhRabtLVzwBAOXLVsiKsDJEX18fI4b+D4CsmP2rN5kvtvyjypWR1cZ5+OgxwsLDFbYJDQvDw2+1msqXUVxLJzcqVKiQWGza09NTabu0HktP0kp4np6eOHHihNJ2STXOgj4F4v7Duxk+TtJnXoDy0ZiqMjX5Pg3OwED5VNas1qurbIW3sPBwrN6wUeXtkqZLa5q+vj76DZOtpndo1za8ff0yS45LRET0M2KyiYg0omtH2epQ5zwv4lw6J4LBKep7JK1e9/T5C4XT5M5dvIhrN2+qJc7M+rXZbzC3tERCfDwWTEt7Op9UKkVYstpVFpaWqF67HgBgy5rliI1JXfPp7NmzuHZNuwk1ZcqWLYtSpUoBAGbMmCFOL0ru7IXTuHtfVkj895ZtszQ+VbX9vQOcHJ2RmJiIhcuWay2OZo0aQk9PDzGxsVi+5l+FbZauWo3YuDjo6+ujWeNGWRyh9kgkErRu3RoAsHr1arni4Ul8fHywZ8+eTB+jatWq4jHGjx+v9LNcr149FClSBAAwefoExH2rS6dMcMhXudtmZrLvtbSKan/5+gUPHt1LN+bd+3eK18uWLpdu+6zyS926qFNLtlrd4uUrcPSE4pUTk9u6axe27c78+5dRzVq3R/4CTkhMTMSaxXOz7LhEREQ/GyabiChDvnz9muYlNCwMANCmVSvUrlkDgiCg96AhWLxiJQICv6/6FRUVhavXb2D8lKmoVu8XuWPUq+0BAHju44PxU/4Wk1FRUVHYsnMX+g0dBmtrqyx5vspYWFpizJTZAICThw9gaI/2eHjPS/wLvVQqxWuf59i8Zjla/1Idl87Jn3QNGf0XdHV18eblCwzt2QFvX8mmwiQkJGDPnj1o37691pcPT8vcubKTtMuXL6Nt27Z45/cWgKwY775DezBwWB8AgHulqmjSsPkPHy8+IR5fvn5J8xIZFZmhferp6WHwgGEAgP+OHsNzH+2McnDIlw99e3QHACxf8y/m/7NE/ByFhoVh7uJ/sHLtOgDAgF49YZ/Jwu451fjx42FsbIzAwEA0bNgQ9+7JkjGCIOD8+fNo1KgRTExMfugYs2bNgq6uLh48eABfX1+FbfT09LB69Wro6enh5u3raNW+CS5d9ZQraP7W9w02b1uPRi3rYuPW9XLblyxeEgAQHh6G/44eUHiMoE+BaNiiLn5r3xSbt63Hy1c+YvIrMTERL1/5YNK08Zg8fTwAwMnRGc2atPyh565uKxcvRNHChZGQkID+w4Zj8MhRuHH7ttzrFBgUhD0HDqBhq98xZuJkxChIuAOy78Ok/1uCv35ReInKxOe+x4A/AMi+u1+9eJb5J0tERERKsUA4EWVI6SrV0nzcrWQJnD1yGLq6uli3fDmGjByFMxcuYN7ifzBv8T8wNzODjo4OwsLDxZOo5KsbAYBHjRr4rXkzHDp6DJt37MDmHTtgaWGBiMhIJCYmomzp0ujQ+nf8NW26xp6nKlq264SYmGjMmzoeVy6cxZULZ2FgaAgTE1NERITLrWCXsrixW7kKmDBzAWaMH4lbVy+hVd0qsLS0RExMDGJjY1GiRAn0798fI0eOzOqnpZLmzZtj0aJFGDVqFA4dOoRDhw7B0sIS0THR4oiPkiXcsG7lZrUUIr995yZKVSyUZpt+vQZhxpQ5Gdpv5/bdsHjZXAR9+oQFS5Zi7fKlPxJmpo0fNRIfPn7E4eMnsGj5CvyzchUszM0RFh4uJjB/b9EcY0b8qZX4tKlIkSLYsmULOnXqBC8vL1SsWBHm5uZITExEVFQUHB0dsWjRIvTq1SvN1RHTUrx4cfTu3Rtr165Ns90vv/yCtSs2449RA3H3vhfadWkFfX19mJuZIzIyErFx32uYNW7YTG7bgq6F4VGzDi5fvYj+Q3th5LhhsLaUreDWr/cgDOgzGHq6epBIJLh+6yqu37oKQPb9aG5mjrDwMLlRhC7Orti6frfclLrswMbaGsf27cXov/7CkRMncfDwERw8fAQSiQSWFhaIiYlBTLJab0ULF0bVb7WeUrp99266/+d06TMQY6bOzlCMv3fshrXLFuJzUCBWLZqDBas3ZWh7IiIiSh9HNhGRxpibm2HL2jXYtn4tWjVrCsf8+REXF4fo6Gg42NujTq1amDB6FK6cTj3VYsWihZg28S+UKlEchgYGSExMRMlixTBh9Cgc3r0Lpmks3Z2V2nfrjf88b6PHgKEoXqo0DAwMEB4WChMTU7iVrYBOvfpjzY6DaNIq9VSytl16YvPBk6jToDEsrawRGxsLFxcXjB8/Hrdu3YK1tbWCI2YfI0aMgJeXF7p27QrH/AUQHRMNI0NjVKrgjmmTZuPUfxeQz95B22GmycjICAN6y4otHzt1Ct5PtbOKloGBAdYsXYK1y5ehfp3asLayQkRkJKytrFC/Tm2sX7kcKxcvgr6+vlbi07a2bdvCy8sL7dq1Q968eREbGwt7e3sMHz4c9+7dg6WlJQD80GjAqVOnwtjYON12TRs1xw3Pexg9fBwqlKsEUxNThIaFwsDQEG4ly6BLx+7YuGY7hvQfnmrb9Su3YECfIShcqAgS4uPh5+8LP39fhH2bWle0SDHcu/4E82f9g7a/d0CpEqVhYmyKsPAwGBgYwqmAMxo1aIpFc5fh8plbKF60RKafryaZm5thzdIlOHP4EAb17YNyZUrDxtoaEZGR0NPTQ9HChdG+9e/YunYNLhw/inKlS2dpfIZGRujWT7aC39njh/H8yaMsPT4REdHPQCKkVWiEKBvw9vZG6WQ/RB8/fgw3Nzel7RMSEuDjI786T9GiRVONnskKQe/CsvyY6iJNCEy/UTYUZJj9Vj5TVdkCVtoOIdPY17Ujp/Z3dff1v/76C7NmzUL9+vVx7tw5te47JfZ17chufV2QJiIxWLaYhU9QBABg2qWviIyX/1n9dk6zVNvmFCsGZs9FKlQRE7xI2yFk2rKCg7QdQqawr2sH+7p25JT+ntHzaHXjyCYiIiLKsT59+oR162Q1rRo3bqzlaIiIiIgIYLKJiIiIsrmlS5dizpw5ePnyJRISEgAAsbGxOH78OGrXro2goCDkzZsXvXv31nKkRERERASwQDgRERFlc69fv8aSJUswfvx46OrqwtLSEmFhYWLiydLSEnv27EGePHm0HCkRERERAUw2ERERUTbXo0cP6Orq4tKlS/D398eXL19gbGyMggULolGjRhg+fDgcHR21HSYRERERfcNkExEREWVrFSpUQIUKFbQdBhERERGpiDWbiIiIiIiIiIhIbZhsIiIiIiIiIiIitWGyiYiIiIiIiIiI1IbJJiIiIiIiIiIiUhsmmyjXkUgkqe6TSqVaiISIiIhyJUGQ/QNBvCuBPzWIiIhETDZRrqOjo5Mq4RQREaGlaIiIiCi3EeJjAABx3zJMCVIBsYlCWpsQERH9VPS0HQCRukkkEpiZmSE8PFy8LygoCABgZmYGHZ2sy7FKpYlZdix1k0pz5o9mIQe/5gkJCdoOIdPY17Ujp/Z39nXtYF9XA0GAEB8DaVQIACAiVtaXn32O02JQRERE2Q+TTVnM29sbDx8+xIcPH6CrqwtHR0dUrlwZBQsWzNI4pFIprl27hlevXuHjx4+wtLSEo6MjPDw8YG1tnaWxaIKFhYVcskkQBAQGBiIwMDBL44iPyyY/jjNDiNd2BJmSGJVzf/D7RAZpO4RMY1/Xjpza39nXtYR9Xa1iEhIREiV7TR8GZb/4iIiItInJpiyyb98+TJ8+HQ8fPlT4eI0aNTBz5kzUrVtXo3EkJCRg7ty5WLlyJT58+JDqcQMDA7Ro0QILFiyAq6urRmPRJDMzM5iYmCAqKkrboRAREVEuIUBAXIIUEbEJCImKh1QA3oTEw/sTk01ERETJMdmkYYmJiejbty82bdqUZrtr167hl19+wV9//YVp06ZpJJbAwEA0b94cXl5eStvExcVh//79OHPmDLZs2YJWrVppJBZN09HRgZOTE/z8/LSacAr+GKm1Y/8oITFrR4GpS6CBnbZDyLSyBSy1HUKmsa9rR07t7+zr2sG+rn5vQuKx4V4Yi4MTERGlwGSTho0YMUIu0WRiYoIuXbqgfPnyiIuLw82bN7F//37Ex8dDKpVi+vTpsLa2xogRI9QaR3R0NFq1aiWXaHJ0dETXrl1RuHBhfPnyBSdOnMClS5cAAGFhYejYsSPOnz+P6tWrqzWWrJKUcIqIiEBYWBgiIiIgCDm3XgURERFpX4JUwLPPcXgYFAfvT3FMNBERESnAZJMGHTt2DMuWLRNvlypVCidPnoSTk5NcuwcPHqBp06bitLbRo0ejQYMGKFOmjNpimTx5Mm7evCnebtu2LbZt2wZDQ0PxvnHjxmHHjh3o2bMn4uPjERMTgw4dOuDFixcwMjJSWyxZSUdHBxYWFrCwsIAgCJBKpVmacLq46lKWHUvdYkO2aDuETPnXpbe2Q8i0B1MqazuETGNf146c2t/Z17WDff3HJUjBVeeIiIhUwGSThkilUowfP168bWJigiNHjqRKNAFAuXLlsHfvXnh4eEAqlUIqlWLChAk4cuSIWmJ5//49li9fLt4uW7YsduzYAX19/VRtO3fuDF9fXzF2Pz8/rFixAqNGjVJLLNokkUigq6ubpcdMzMElHBJiY7QdQqZExufckwA9vZz7lcy+rh05tb+zr2sH+zoRERFllaxbA/4nc+7cOTx69Ei8PWzYMBQqVEhp+xo1aqBdu3bi7aNHj+Lly5dqiWXVqlWIifn+A3PevHkKE01JRo8eDUdHR/H2kiVL1BIHEREREREREeV+TDZpyMGDB+Vu9+3bN91t+vXrJ3f70KFDao/FxcUFDRs2TLO9np4eevXqJd728/NLs6g4EREREREREVESJps05NixY+L1woULo3Dhwulu4+HhIVcb6ejRoz8cx5s3b/D06VPxdoMGDSCRSNLd7tdff5W7rY5YiIiIiIiIiCj3Y7JJA0JCQuDr6yverlatmkrbGRgYoFKlSuLthw8f/nAsDx48kLutaixVqlSRq6mhjliIiIiIiIiIKPdjskkDko8kAoAiRYqovG3yEVDBwcEICAjQSixGRkbInz+/ePvJkyc/FAcRERERERER/RyYbNKA169fy912dnZWeduUbVPuS1ux/GgcRERERERERPRzYLJJA8LCwuRu29jYqLyttbW13O3w8PBsEUt8fDxiY2N/KBYiIiIiIiIiyv300m9CGRURESF3O3nR7/QYGxunuS9tx2JoaPhD8QQFBeHTp08Z2iblFL6XL1/+UAxZ6ePXt9oOIdNiw34s0aktcZ/eaTuETPP29tZ2CJnGvq4dObW/s69rB/t61mNf1w729azHvq4d7OvakVP6e8rz5qwePMJkkwbExMTI3TYwMFB525TJnOjo6FwTCwCsXLkSf//99w/t47fffvvhOCg3u6TtADKt9AZtR0A5T87s7+zrlHHs6/SzYF+nn0XO7OtAzu3vfn5+qFixYpYdj9PoNCDl6KG4uDiVt02ZbUw5uignx0JEREREREREuR+TTRpgZmYmdzvl6KK0pBw9lHJfOTkWIiIiIiIiIsr9OI1OAywsLORuBwcHq7xtSEiI3G1zc3O1x2JlZZXhWPT19X+4XhMADB48GO3atcvQNmFhYfDy8oKFhQWsrKzg5OSkllgo6718+VJuGuShQ4dQpEgR7QVEpCHs6/SzYF+nnwX7Ov0s2Ndzj9jYWPj5+Ym369Spk6XHZ7JJAwoWLCh329fXV+Vt372TL5RWqFAhtceS8j5VYvnROJLY2dnBzs4uw9tVr15dLcen7KVIkSJwc3PTdhhEGse+Tj8L9nX6WbCv08+CfT1ny8oaTSlxGp0GlCpVSu52RlZPe/XqlXjd2toa+fLl00osMTEx+PDhg9L9EBEREREREREpwmSTBlhZWcHZ2Vm8ff36dZW2i4uLw507d8TbZcqU+eFYypUrJ3db1Vhu3bqFhIQEtcZCRERERERERLkfk00a0rRpU/H6q1ev8Pr163S3uXz5slwB7+bNm/9wHAULFkSJEiXE22fPnoUgCOlud+bMGbnb6oiFiIiIiIiIiHI/Jps05Pfff5e7vXbt2nS3SdkmeWE2dcXy7t07nD59Os32CQkJ2Lhxo3i7QIECqFy5slpiISIiIiIiIqLcjckmDWnQoAFKly4t3l62bBnevHmjtP21a9ewd+9e8XazZs1QtGhRhW3fvn0LiUQiXurWrZtmLIMGDZJbvW3MmDGIj49X2n7BggXw9/cXbw8fPhwSiSTNYxARERERERERAUw2aYyOjg5mzZol3o6MjESLFi3klh5M8vDhQ7Rv3x5SqVTcdubMmWqLxcnJCUOGDJE7XpcuXRAbG5uq7c6dOzFlyhTxtqOjI4YOHaq2WIiIiIiIiIgod9PTdgC5WYsWLTB48GCsXLkSAODt7Y2SJUuiS5cuKF++POLj43Hjxg3s27dPbqTR3LlzUxX2/lHTp0/HpUuX4OXlBQDYu3cvrl27hm7duqFQoUIIDg7G8ePHcfHiRXEbQ0ND7N69G0ZGRmqNhYiIiIiIiIhyLyabNGzp0qUIDw/H1q1bAchGOP37778K20okEowbNw6jR49WexwmJiY4cuQImjVrhrt37wIA/P39MWfOHIXtzc3NsXnzZtSsWVPtsRARERERERFR7sVpdBqmq6uLLVu2YPfu3XI1nFKqVq0azp49Kzf1Tt3y5cuHGzduYNq0aciXL5/CNgYGBmjdujUePHiQqsg5EREREREREVF6OLIpi7Rv3x7t27fH48eP8fDhQ3z48AG6urrInz8/3N3dUahQIZX35erqCkEQMhWHvr4+Jk2ahAkTJuDatWt4+fIlAgMDYW5ujgIFCsDDwwM2NjaZ2jcREREREREREZNNWax06dJpjnDKKrq6uvDw8ICHh4e2QyEiIiIiIiKiXITJJiLKMnnz5pVb7TBv3rxajIZIc9jX6WfBvk4/C/Z1+lmwr5O6SITMzsciIiIiIiIiIiJKgQXCiYiIiIiIiIhIbZhsIiIiIiIiIiIitWGyiYiIiIiIiIiI1IbJJiIiIiIiIiIiUhsmm4iIiIiIiIiISG2YbCIiIiIiIiIiIrVhsomIiIiIiIiIiNSGySYiIiIiIiIiIlIbJpuIiOinJpFIIJFIsGnTJm2HQqQR7OP0s+nZsyckEgnq1q2r7VCINIp9nbIzJpuIiIiIiCjbmzp1KiQSCVxdXbUdCpFGsa9TbsBkExERERERERERqQ2TTUREREREREREpDZMNhERERERERERkdow2USUi23atEksDJvWxcDAAHnz5kWFChXQs2dP7N+/H7GxsdoOX63evn2LqVOnipeQkBBth0TpSFn08t69e+jUqRPy588PQ0NDuLi4YNCgQfj48WOa+3n8+DG6dOkCBwcHGBkZwdXVFYMGDcK7d++y4FkQZUzKfn/lyhW0a9cOBQoUgL6+vsIisOzjlNt5enpCIpHg77//BgC8e/cu1W+ZtAokZ/b/D6Ksxr5OuYmetgMgIu2Lj4/H58+f8fnzZ9y/fx+bN29GgQIFsGzZMvz222/aDk8t3r59K/7HDchO6KysrLQXUC4kCAJevXqFx48fw8/PD2FhYTAxMYGNjQ3KlSuHMmXKQFdXN1P73rlzJ3r27Im4uDjxPl9fX6xevRpHjx7F9evXUaBAgVTb7d+/H506dUJ8fLx437t377B69Wrs3r0bp06dylQ86enZsyc2b94MAKhTpw48PT01chzSvoiICHh7e+Pdu3f4+PEjIiMjoaOjAysrK7i6uqJSpUrImzdvpva9fPlyDB8+HFKpVGkbbfRx9u/cQ5Pf29lFZv//+FGCIMDLywu3b99GaGgobG1tUbNmTZQqVSrD+/L398fatWsBAK6urujZs6dK202dOlX87ePi4oK3b9+qpS0p5+3tjYcPH+LDhw/Q1dWFo6MjKleujIIFC2r82Ozr7OvZjkBEudbGjRsFAOLFzs5OKFy4cKqLg4ODoK+vL9cWgCCRSIQ1a9Zo+2moxYULF+Se25s3b7QdUq4QFhYmbN++XejQoYOQN2/eVH0o+cXa2loYOXKk8OHDB5X23aNHDwGA4OjoKBgaGgr169cXzp8/L3z69El4+/atMG3aNEEikQgAhA4dOqTa3tvbWzAwMBAACA4ODsKWLVuEDx8+CP7+/sLGjRsFe3t7oWDBgmJ8GzduVNvrkhQ7AKFOnTpq229OdOHCBWHKlCnClClThMWLF2s7HLXw9vYWevbsKRQtWlTsg2ldateuLRw4cEClfSf1HXt7e0FXV1eoXbu2cPbsWSEoKEh48+aNcOrUKbk4tNHH2b+/y4n9W5Pf24IgpPt5UHaZP3++0n0mJCQI4eHhwvjx4wUAgrOzsxAeHi53iYqKEtv/6P8fP+rOnTtC+fLlFT7PX375JcO/QVq3bi1uf/ToUZW3mzJliridi4uL2trmJJroj4rs3btXKFu2rNL91ahRQ7hw4UK6+2FfZ1/PTZhsIsrFUiab0jrRiIuLEy5fviy0bNlSbhtDQ0PhxYsXWRe0hjDZpH5hYWGCkZFRhn/A2djYqHTinfyEtlmzZkJCQkKqNn/++acAQNDX1xdCQ0PlHmvWrJkAQDA3NxdevnyZatunT58KxsbGTDZpWG78Ubd169ZMnby0aNFCiIiISHPfKftOXFyc0rba6uPs39/ltP6t6e9tQdDsyX3S653ea/2j/3/8iNu3bwvm5uZpPlcHBwfh7du3Ku3vxIkT4na//fZbhmLhCbjmk00JCQlCz549Vdqnjo6OMGnSJJX2y77Ovp4bcBodEQEA9PX1UatWLdSqVQu9evXCpk2bAACxsbFYu3Yt5s2bp90AKdtJTExETEyM3H2FChVCnTp1ULx4cdja2iImJgaPHj3C/v378fnzZwDA169f0a5dO+zduxe///67SsdavHixwqkcPXr0wD///IP4+Hjcv38ftWvXBgAEBgbixIkTAIBhw4ahcOHCqbYtUaIEhgwZggULFmToeRMlZ29vj2rVqqF48eJwcnKCmZkZYmNj4efnh0uXLuHKlSsQBAEAcOTIETRv3hznzp2Djk76ZTPnz58PfX19hY+xj1NmZOX3NgDY2dnB3NxcpbbW1taqP5EMyOj/Hz8iISEBXbp0QXh4OADAwcEB/fv3h7OzM54+fYo1a9YgPDwcHz9+RO/evXHu3Lk09xcTE4OhQ4cCAExNTbFkyZIfjvFnpon+OGLECPE3MwCYmJigS5cuKF++POLi4nDz5k3s378f8fHxkEqlmD59OqytrTFixIjMPIU0sa9TdsNkExGlMmPGDGzevFk8Qbp27VqGto+NjcXVq1fx9u1bBAUFwdjYGA4ODqhduzby5cuXqZj8/f3h5eUFX19fhIWFQVdXF+bm5ihQoABKlCiBYsWKQSKRZGrf9GMsLCzQu3dv9OrVC2XLllXYZtGiRfjzzz/FefiJiYno06cPPDw8YGtrm+b+CxUqhKJFiyp8rFixYuL1wMBA8fr169fFOjdpnRi1bt2aJ+KUYS4uLpg3bx5atmyJ4sWLp9n29u3b6NChA968eQNAVvx19erVGDx4cJrb2drawt3dXenj7OP0IzT9vZ1k7ty5Ktdc0YTM/P/xIw4dOoQXL14AAPLnz4+7d+/C3t5efLxXr16oVKkSYmJicP78eXh5eaFy5cpK9zd79my8evUKADB58mQ4OztnKJ6kRVFIRt398dixY1i2bJl4u1SpUjh58iScnJzk2j148ABNmzbFhw8fAACjR49GgwYNUKZMGbXFwr7Ovp4dMdlERKk4Ojoib968CAoKAgDx3/S8efMGkyZNwsGDBxEVFZXqcYlEgtq1a2P+/PlpnkQl5+npicmTJ+Py5ctptrO2tkbTpk0xe/Zsuf/k69ati4sXL6Zqn1ahxqQkG6VNT08P48ePx+jRo2FjY5NmWxMTE/z777+IjIzEjh07AADBwcFYuXIlJk+enOa2+fPnT3O/SZL3ueTFHkuUKKF0+5IlS6Z5bCJFPDw84OHhoVJbd3d3nDp1CmXKlBFX+Vy7dm26yab0ismyj1NmZNX3dnaRmf8/fsTx48fF62PHjpU7+QZkyYj+/ftj6dKlAIATJ04oPQF/+fIl5s6dCwBwc3PTyEgYyjypVIrx48eLt01MTHDkyJFUiSYAKFeuHPbu3QsPDw9IpVJIpVJMmDABR44cUVs87OuUHTHZREQKJSYmitfNzMzSbb9mzRoMGzZMbgWMlARBwMWLF1G1alUsXLgw3f9M5syZI/cfeVqCg4Oxfft29OzZU+F/9KR+ZmZmmDVrVoa2mT9/Pnbu3Ckm9I4ePZruSYuqKyElTxJGREQAkCU4TU1NlW6jSt9Wt8jISHh6esLPzw+hoaHIly8fKleuDDc3tx/et7e3Nx48eICgoCDExsbC3t4epUuXRqVKlTI18i80NBR37tzB8+fPERoaCqlUChMTEzg4OKBIkSIoU6YMDAwMfjju3K5o0aJo2rQpDh48CED2V+64uLg0X7vkJweKZNc+zv6dvWXV93Z2kZn/P37E48ePxeuNGjVS2KZx48biCXjy9ikNHTpUTFCvXLlS6ZTa7ELdn8/s7ty5c3j06JF4e9iwYShUqJDS9jVq1EC7du2we/duALLP0cuXL1GkSBG1xMO+nnV+tr7+I5hsIqJUfHx88OXLF/G2siH2SebOnYtx48aJtyUSCerVq4d69erBwcEBUVFR8PLywv79+xEZGQlBEDBy5EgYGhoq/ev+qVOn5BJNBgYGaNq0Kdzd3WFvbw+JRIKQkBC8ePECt2/fxt27dxXux9HREYULF0Z0dLQ4fBmQTYPR0+NXYFbLnz8/SpYsiSdPngCAOGRa3ZJOsAVBQGRkpNKT8aQT9qwQGRmJsWPHYvPmzQqPW7FiRSxbtgw1atTI0H5jY2OxfPlyLF26FL6+vgrbODo6Yvz48Rg4cKBKP0hfv36Nv/76CwcPHhR/ACpiaGiIOnXq4K+//kpVA0LRD653794p/SFWp04deHp6phtbTpV8up0gCPj8+XOaf4lOT3br4+zfubd/Z9X3dm4QHBwsXlc2DcjFxUVh++T27t2LU6dOAQC6d++e6Ro7ml7iXROfz5wi6Y8HSfr27ZvuNv369ROTTYBsKtro0aPVHltWYF9PLbf29R/BMy0ikpOQkJBqxFH37t2Vtr9w4QImTJgg3i5WrBh27dqFChUqpGo7c+ZMtGnTBrdu3QLwfc568rnkSWbPni1eL1y4ME6dOqWwAG6S9+/fY/Xq1bCwsJC7f/v27QBk0/Hq1asn3u/p6QlXV1el+yPNST7SIjIyUiPHSP7ePnv2DJUqVVLY7unTpxo5fkoBAQFo0KABvL29lba5e/cuPDw8sHTpUgwZMkSl/fr4+KBZs2bw8fFJs52/vz+GDh2KPXv24OjRo2kWSD1//jxatGih0lD72NhYnD59Gu7u7mopOJqbhYWFidd1dHRgZWX1Q/vLTn2c/Tv3y4rv7dzAyMhIvB4WFgZjY+NUbUJDQxW2TxIeHi7+DrOyssL8+fM1EOmP08TnMyc5duyYeL1w4cJp/kZN4uHhASMjI7FI/9GjR3Nssol9PbXc2td/BJNNRISYmBj4+/vj6tWr+Oeff3Dv3j3xsX79+qF+/foKt5NKpejXr59YpNbFxQVXr15VWji0QIECOH36NMqVK4d3794hOjoa06dPx9atW+XaxcXF4cqVK+LthQsXpvufeIECBTBjxgyVni9pV/K/NmW2YHx6qlevDh0dHUilUhw8eFDpifiBAwc0cvzkpFIpOnfuLJ6I165dG02aNEHevHkREBCAo0eP4saNG2LbP/74A3ny5EHHjh3T3K+3tzfq1q0rrhYFyAqEtmjRAsWKFYOBgQFevXqF/fv3iz+QLl26hMaNG+PixYsKR/YFBQWhdevWcifiNWrUQL169eDs7AwDAwOEh4fj3bt3uHfvHq5cuaJ06mzSZ/br16/iXzT19PTk/tKZnKOjY5rPNydLTEzE6dOnxdsVK1ZMd5pcerJLH2f//jn6d1Z8b6siaXpN8qn+2Un+/PnF6ULPnz9PVccm6f7k7VOaMmUK/P39AQCzZs2CnZ2dhqLNPE18PnOSkJAQudEt1apVU2k7AwMDVKpUCVevXgUAPHz4UGlb9vXs4Wfv6z9MIKJca+PGjQKATF3y5csnLFq0SEhMTFS6//3798ttc+LECZXi2rVrl7iNoaGh8PnzZ7nH/f395fb75MmTH3odBEEQLly4ILfPN2/e/PA+KeMuX74s9z507NhRadsePXoIAIQ6deqkuc+kfW3cuFHu/mbNmgkABHNzc+Hly5eptnv69KlgYmKidPsfkRQ7AEFHR0cAIBgbGwsHDhxQ2H7btm2Cvr6+uI2NjY0QFBSkdP9RUVFCqVKlxPb6+vrC0qVLhYSEhFRt4+PjhcmTJ8u97tOmTVO43ylTpohtjIyM0v1Mh4aGCmvWrBHWr1+vtE3yfbq4uKS5v9xq5MiRcq//rl27lLZVtd8Lgvb6OPu34n3m1v6dke9tQRDk2jZo0EDw8PAQ8ubNK+jr6wvW1tZC0aJFhfbt2wurVq0SQkNDMxTLqlWrxN8O8fHxStv96P8fmZW8P7Rt21ZhmwoVKohtNm3aJPfYw4cPBT09PQGA4O7unuZvsIzGk17/VLWtpj6fmqKJ/njt2jW5/U6ZMkXleLp37y637cePHxW2Y1/PfDw/a1/PjphsIsrFMptsKl68uLBx40YhNjY2zf23adNG3KZUqVIqxxUfHy+Ym5uL26Y8QQkODpaLZ926dZl6/skx2ZQ9tGjRQu59UHZyKgg//gPK29tbMDAwEAAI+fPnF7Zu3Sp8/PhR+PDhg7Bp0ybB3t5eKFiwoMaTTaokGARBENauXSvXfsSIEUrb/v3333Jt9+zZk25Mf/75p9je1NRUCAkJSdXGw8NDbPPnn3+m/0RV8DOcjKcUExMjvH79Wti+fbtQs2ZNufdqwIABaW6bkWSTtvo4+/d3P0P/zsj3tiAIqfpGWhdLS0th1qxZKp9o3rp1S9x2/Pjxgr+/vxAXFyfEx8fLnQBq6wTcx8dHkEgk4n5nzpwpREdHC4IgCCEhIcKAAQPExywsLISwsDBxW6lUKn5f6OjoCF5eXj8cjyZOwDX1+dQUTfTHbdu2yW2XVkI6pYkTJ8pte/XqVYXt2Nczhn09e2KyiSgXS5lssrOzEwoXLpzq4urqKlhZWaX6T9fJyUk4e/as0v3b29uLbf/3v/9lKLY6deqI244dOzbV48lPkCwsLIQ9e/b80F89mGzSvh07dsi9B+XLl0/zPVXHD6i9e/fKjahIfrGyspL7MafJZFP9+vVV2q5KlSriNnny5BFiYmJStYmOjhbs7OzEdh06dFBp35GRkYKNjY243bJly1K1KVq0qPj4ypUrVdpven6Gk/H58+enexJjZ2en0muakWSTIGinj7N/f5fb+3dGv7cFIfXJvampqeDk5CTky5dPaV/99ddfhaioKJViqlGjhsJ9JP/MaOsEXBAE4Y8//pCLy9jYWHB2dk713JcuXSq33fr168XHhgwZopZY1H0CrsnPp6Zooj+uXLlSrv3BgwdVjmfhwoVy2548eVJpW/Z11bGvZ086IKKfxty5c/Hy5ctUlzdv3iA4OBj+/v5Yvny5OO/az88PjRs3xpEjR1LtKyAgAIGBgeLtjC5rnXxu9/v371M9PnDgQPF6WFgY2rdvDycnJwwcOBC7d+9WuA1lX97e3ujfv794W09PD2vXroWOjmb/G2rbti3u3r2LTp06IV++fDAwMICzszP69u2LO3fuwN3dXaPHTzJgwACV2vXr10+8/uXLF1y7di1Vm7NnzyIoKEi8PWrUKJX2bWJigvbt24u3z5w5o7BNEkXHpsypWbMmTp8+jUGDBql939mhj7N/506Z/d42MDBA+/btsXPnTvj6+iIiIgK+vr74+PEjIiIicPnyZXTt2lVu5b4zZ86ga9euKi3Lfvz4cfzvf/9DqVKlfrj2mSYsWLAAbdu2FW9HR0fD19cX8fHx4n2jR4/GH3/8Id7++vUrxo4dC0D2+2jmzJmp9vv582d4enri6NGj8PLyQkJCggafhWKa/Hxqiib6Y8oVNxUVv1YmZSHttFYMZV9nX8/xtJ3tIiLNSTmySdW/Znz48EFwcXERt1NUX+Px48fp/iVf1UvTpk1TxZCQkJBq6H7KS5EiRYQhQ4YI169fT/c5cWST9qTsTwCEBQsWaDssjUo58iM4OFil7fz8/OS2mzt3bqo2Y8aMER+3s7MTpFKpynEl/06wt7dP9XivXr3kjj9t2jQhIiJC5f0rkttHfgiCIKxbt05utKidnZ2gq6sr91pKJBKhTZs2QkBAgLbD/WHs39/l1v79I9/badXjSu7EiRNyNcUA1aap5BR79+4VGjVqJNja2gr6+vqCg4OD0KZNG8HT0zNV2379+omvwbZt2+Qee/XqldCqVatU3ylWVlbCjBkz0qzno+7RHpr8fGqKJvrjtGnT5NqdO3dO5XiSj+oBIGzdulXlbbMr9nV52urr2RFHNhFRKg4ODpgzZ454++vXr1i1apVcm5CQELUdT9ES1Lq6ujh06BBWrFgBZ2dnhdu9fPkSK1asQPXq1VG3bl25VS8oe/j69SsaNWqEd+/eiff1799f5b8Q5QZOTk4qL3NfoEABubbPnj1L1ebBgwfi9VKlSsn9NTY9yUcUBgYGpvprYf/+/eX2N3nyZOTLlw/t27fHmjVr8OTJE5VGHvxs+vTpIzdaNDAwEGFhYThz5gxatWoFABAEAfv370e1atXg5+en5YjVh/079/nR7+28efOq1K5x48bYsGGD3H3Tpk1TPdBsrm3btjh58iQ+ffqEuLg4fPjwAfv27UOdOnXk2t24cQPr1q0DANSrVw9dunQRH3v8+DGqVauG//77L9WqZCEhIZg4cSLatGmTZSuWafLzqSma6I8pRzIpW7VSkdjYWLnbKUc65UTs6/K01dezIyabiEih5s2bQ1dXV7x97NgxucdTDud1cHBA4cKFM3VRtBwqAOjo6GDw4MF48+YNPD09MXHiRNStW1fhf8wXL15ElSpV0lxGlrJWWFgYGjdujEePHon3denSJVXiMrfL6FK+yX8YJy2pntyXL1/E656enpBIJCpfmjZtKrevlPuvVq0aZs+eLXdfREQE9u7di4EDB8LNzQ329vbo1KkTDh06JDdUnuSZmJigQYMGOHToEDZs2CBOPXr79q3cD+ycjv07d8nq7+0OHTqgSpUq4u3Hjx/j7du3GjlWdpSYmIhBgwZBEATo6+tjxYoV4mNxcXHo0KEDPn36BADo27cvXr9+jejoaHh6eqJ48eIAgMOHD2PBggVZEq8mP5/Zgar90czMTO52TEyMyseIjo5Oc1+5Ffv6z4nJJiJSyMzMDHny5BFvpxw1ZGtrK3d78eLFCutBqXLZvn17mrHo6OigTp06mD59Oi5cuICQkBCcP38eQ4YMgYWFhdguLCwMffr0UcOzpx8VERGBJk2a4Pbt2+J9bdu2xebNmzVepym7yehfLU1NTcXrimo5aHpU4dixY3H69Gm5H9zJffr0Cbt27cLvv/+OEiVK4Pjx42qLJ7fq1asXhg8fLt6+fPkyzp07p8WI1If9O/fQ1vd269at5W5fv35dY8fKbpYvX4779+8DkNWEKVmypPjY3r178eTJEwBAkyZNsHbtWhQsWBBGRkaoU6cOTp06BX19fQCympwpkxiaoOnPZ3agSn9M/tsTyFgyIeVraG5urnpwORj7+s9JT9sBEFH2lXw6Qcov9vz588PCwgJhYWEAFBf51hQDAwPUq1cP9erVw+TJk1G7dm0xGebl5YXnz5+LfwWhrBcVFYVmzZrJFeBt2bIlduzYITda7meR0R9FkZGR4nVFf/FMPqrQ1NQU+fLly3RsenqKfwb8+uuv+PXXX+Ht7Y2TJ0/i0qVLuHbtGj5//izX7vXr12jevDnWrVuH3r17ZzqOn8GwYcOwePFi8fbRo0fxyy+/aDEi9WD/zh20+b2d8v/r5EV5c7OPHz9i8uTJAAAXFxdMmjRJ7vH9+/eL18eMGZNqexcXF3Tq1AlbtmxBcHAwzp07h+bNm2s05qz4fGqbKv2xYMGCcrd9fX1V3n/y6akAUKhQoQxElzOxr2fPvp4Vft5nTkRpCg8PlxtCmnLOu66uLjw8PMTpdRcuXNBKHR47OzvMmTMHv//+u3jfkydPUv1YSPqLSBKpVJol8f1soqOj0aJFC1y6dEm8r0mTJti7d2+q9+BnkdETp6Rh5ABgbW2d6vHkowo9PDxw4sSJzAeXDjc3N7i5uWHUqFEQBAGPHj3Cf//9hw0bNohTCwRBwLBhw9C8efMMT6n6mbi6usLS0hKhoaEAZDXncgP275xP29/bKUfH/SyjAEaOHCn+wW7p0qWpyhPcuXMHACCRSFC9enWF+6hRowa2bNkittf0CXhWfj61RZX+WKpUKbnbGfk+f/XqlXjd2tr6h5IYOQX7+s/r55rLQEQq+++//+QSMuXKlUvVpmPHjuL1kydPaq1Ad8rEkqI6Gyn/gp50wkfqExsbi99++w3nz58X7/v1119x4MABGBgYaDEy7fLz81N5OLa/v79cW0Uj9EqUKCFez8oRhRKJBGXLlsWkSZPw/PlzdOjQQXwsMjISBw8ezLJYcipDQ0PxelYVOdU09u+cLTt8bwcGBsrdTjlNPzc6d+4cdu3aBQBo0aIFWrZsmapNUmLW1tZW7rsjOScnJ/F6VowI09bnMyup0h+trKzkFq9RdepnXFycmFgBgDJlymQyypyDff3nxmQTEaXi7++PCRMmyN3Xpk2bVO06duwoDiVOTExE586dFdbgSIuioopfv35FeHi4yvtIvmIEIBtBkJKLi4vc7cePH6u8f0pfXFwc2rRpg9OnT4v31atXD//991+qVVt+Rslfl7ScPHlS7ra7u3uqNvXq1ROve3t7a2XKiYGBAVatWiW3OktSvYWUko+M+JlHFIaHh8tN00q+Wk1Ox/4tk9P6d3b53r5y5Yrc7ZRTlHKbuLg4DBkyBIBsqs7SpUsVtktKSKc1VTX5qJusSGBnh8+npqnaH5MXgX716hVev36d7r4vX74s97tX06NztI19nZhsIiLRhw8fsHz5clSsWFFuae7SpUuje/fuqdrr6elh3bp1Yj2Hu3fvomrVqnI1H5R5+PAhxo0bh8KFCyt8zNnZGePGjYO3t3ea+3n06BFGjx4t3nZ0dETlypVTtbOyspL7K8W8efNU+mFA6UtISEDHjh3lViz08PDAkSNHcsWSvuqwdu3aDLfLkycPatasmapNo0aNxOXjBUFQ+uNN06ytreWm1ypbuSv5qMKfeUThwYMH5ZIRir6ncir2b5mc1L+zy/d2UkH2JMbGxqhVq1aWHV8b5s2bJ44EnzhxosI/kAEQF2mJiIjA169fFbZJXiso+aIumpJdPp+akpH+mLx8A6Da92DKNr/99lvGg8xB2NcJAhHlWhs3bhQAiBc7OzuhcOHCqS6urq6ClZWVXNukS4ECBYRXr16leZxly5YJEolEbrvy5csLI0aMEJYtWyZs2rRJWLFihfD3338L7dq1E5ydncV2hoaGqfZ34cIFuX0VK1ZM6N69uzB37lxh7dq1wvr164WZM2cKzZo1E3R1deXa7t69W2mc8+bNS/X8nJychLJlywrlypUTL6S6hIQEoUOHDnKvac2aNYXw8HBth6ZVPXr0SNXX9u7dm+Y2GzZskGs/YsQIpW0nTZoktjMwMBAuXLiQ4Rijo6NT3ffmzRuVt3///r2go6MjxjF37lyF7Q4dOiT3vHx9fTMca3YSHR0txMfHZ2gbf39/wdHRUXwN9PT0hPfv32soQs1j//4uJ/ZvTX1vx8XFZeizER8fLzRp0kQujp49e/5QDNnd69evBWNjYwGAUKJECSEuLk5p20aNGomvy6pVqxS2qVq1apq/f6ZMmSI+7uLikmZsqrbV1OdT3TTdHxMTE4XSpUuLbU1NTYXXr18rbX/16lW575RmzZpl6PnkNOzrMlnR17MzJpuIcrGUyaaMXCQSidChQwchICBApWMdOHBAsLCwyPBxTExMUu0rZbJJlYuurq6wdOnSNGOMi4tL9UNC0YVUI5VKhe7du8u9dtWqVRPCwsK0HZrWJT8ZT/pxaWJiIhw6dEhh+x07dggGBgbiNjY2NkJQUJDS/UdERMj9yDUyMhIWL14sxMTEpBnXp0+fhHXr1gkVK1YUdu7cmepxPT09oUuXLsL58+eFxMREpfv58uWLULduXbnvi2fPnils6+/vL/cDu2PHjkJISEiacWZn9+7dEwoXLiysXr1a+PLlS7rtjx8/Lri4uMh9TkaNGpUFkWoO+/d3Oa1/a/J7+82bN+Jn4+vXr2m2ffHihVC7du1UvwfevXv3w3FkZ82bNxef7/nz59Nsu2zZMrGtq6ur8PnzZ7nH9+7dK/cZSfm4IGjmBFxTn091y4r+ePjwYblt3NzcFCacHzx4IPcHBx0dHeH+/fs/9PyyO/b1rOvr2ZlEEJKtbU5EucqmTZvQq1evdNvp6OjAzMwMNjY2cHNzQ/Xq1dGpU6cML8f65csXLFy4EBs3bkRAQIDSdvr6+qhSpQpatmyJLl26wNHRUe7x0NBQbN68GcePH8fVq1fTrANlYGCAZs2aYerUqShbtmy6MQqCgAMHDmDPnj24d+8eAgICEBERgeRfhfxaVM3ly5dRu3Ztufvy58+f4SkYFy9eTNUHcrqePXti8+bNAGRTU/T09HDhwgUAQJ06ddCkSRPkzZsXgYGBOHr0qNzUU4lEgh07dsgV4Ffk5cuXqF27Nj5+/CjeZ2tri0aNGqF8+fKwsbGBVCpFSEgIfHx8cP/+fdy5c0esdbBz585Ux0heo8be3h41atRA+fLlYWdnB2NjY3z9+hX379/HoUOHxJVlAGDQoEFYuXKl0libNWuG48ePi7f19PTg6uoKU1NT8b7KlStj3bp1aT7n7OD+/fuoUKECgO/fZeXLl0ehQoVgaWkJiUSCkJAQPHv2DOfOnUs1XbdevXo4evRoqtV4chL2b3k5qX9r8nv77du3Yn0bfX19VK9eHeXLl0fBggVhYWGBhIQEfPz4EVeuXMH58+flppXq6enh0KFDaNasWSafWfZ36NAhcepVly5dsG3btjTbh4WFoVixYmLBaicnJwwYMAD58uXDzZs3sWHDBrG///HHHwqn+UydOhV///03AFntyqRVFhXJSFtNfD7VLav645AhQ+S+H0xNTdGlSxeUL18e8fHxuHHjBvbt2yc3FXf+/PlyJSByG/b1rO3r2ZpWU11ElGs9evRI2L59u/DPP/8I06dPFxYtWiRs2bJFuHHjhhAREaHyfhISEoSHDx8K+/btE5YsWSLMnDlTmD17trBq1Srh3Llz2fovyLldZkagKbpkZGpLTpF85EedOnWEjx8/Cm5ubum+Fjo6OsKyZctUPo6/v7/c0PKMXPbs2ZNqf5nZT5cuXdIcHi8IgvDu3TuhUKFCae6nTp06GX2ZteLevXuZep0kEonQr18/ITIyUttP4Yexf8vLSf1bk9/bb968ydS+8ufPL5w+fTrrX4wsFBkZKZYQsLS0VHnU+KlTp+RGBSq6lCtXTunvKk2M9kii7s+numVVf0xISBC6deum8v8D48eP1+Cz1j729azv69kZk01ERJQpTDYpl/JkXBBkw7GHDBkimJmZKXwdKlSoIFy5ciXDx5JKpcLu3bsFd3f3VLXTUl4KFSokDBo0SLh8+bLCfW3fvl3o1KmTYG9vn+77Vq1aNeHAgQMqxxkeHi4sW7ZMaNy4seDo6CjWckj5OmV3YWFhwoIFC4QGDRoofS+TX8zMzIQePXoIN2/e1HboasP+nVpO6d+a/N4ODQ0VBg8eLLi5uclNLVR2KVy4sDB37lwhODg4y1+HrDZ27FjxeWck4SoIsvesaNGiCl/DDh06pDlFTJMn4IKg3s+numV1f9y9e7fclCtF3ynnzp1T75PMhtjXs76vZ2ecRkdERJSFIiIi4OnpCT8/P4SGhiJfvnxwd3eHm5vbD+/78+fPuHr1KgICAvD161fo6urC0tISBQsWhJubW4amK7558wZPnz7Fu3fvEBoaCqlUCnNzc7i4uKBy5crInz//D8eb00mlUjx79gwvXrzA+/fvER4eDkEQYGFhgTx58qBMmTIoOazNjAAAAl9JREFUWbKkuGLnz4D9mwAgMjISjx49wtu3bxEQEIDIyEjx/cqXLx+qVKmS66ZPK5OQkIB58+YhLi4ORkZGGDNmDHR0MrYgeGJiIq5du4b79+8jIiIC9vb2qF+/vtLVvbRBnZ9PdcvK/vj48WM8fPgQHz58gK6uLvLnzw93d/cMl6bIidjXtd/Xsxsmm4iIiIiIiIiISG0ylmokIiIiIiIiIiJKA5NNRERERERERESkNkw2ERERERERERGR2jDZREREREREREREasNkExERERERERERqQ2TTUREREREREREpDZMNhERERERERERkdow2URERERERERERGrDZBMREREREREREakNk01ERERERERERKQ2TDYREREREREREZHaMNlERERERERERERqw2QTERERERERERGpDZNNRERERERERESkNkw2ERERERERERGR2jDZREREREREREREasNkExERERERERERqQ2TTUREREREREREpDZMNhERERERERERkdow2URERERERERERGrDZBMREREREREREakNk01ERERERERERKQ2TDYREREREREREZHaMNlERERERERERERqw2QTERERERERERGpDZNNRERERERERESkNkw2ERERERERERGR2jDZREREREREREREasNkExERERERERERqQ2TTUREREREREREpDZMNhERERERERERkdow2URERERERERERGrDZBMREREREREREakNk01ERERERERERKQ2TDYREREREREREZHaMNlERERERERERERqw2QTERERERERERGpzf8Brs1S4f/TYRIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(4, 3), dpi=300)\n",
    "ax.bar(grouped_results[grouped_results.prior_type=='nonlearned'].rank_value-0.25, grouped_results[grouped_results.prior_type=='nonlearned'].test_acc1_mean, color='#9467bd', label='StdPrior fromImgNetSimCLR', linewidth=0, width=0.25)\n",
    "ax.bar(grouped_results[grouped_results.prior_type=='adapted'].rank_value, grouped_results[grouped_results.prior_type=='adapted'].test_acc1_mean, color='#8c564b', label='LearnedPriorIso fromImgNetSimCLR', linewidth=0, width=0.25)\n",
    "ax.bar(grouped_results[grouped_results.prior_type=='LearnedPriorLR'].rank_value+0.25, grouped_results[grouped_results.prior_type=='LearnedPriorLR'].test_acc1_mean, color='#1f77b4', label='LearnedPriorLR fromImgNetSimCLR', linewidth=0, width=0.25)\n",
    "ax.scatter(results[results.prior_type=='nonlearned'].rank_value-0.25, results[results.prior_type=='nonlearned'].test_acc1.values, color='black', s=15)\n",
    "ax.scatter(results[results.prior_type=='adapted'].rank_value, results[results.prior_type=='adapted'].test_acc1.values, color='black', s=15)\n",
    "ax.scatter(results[results.prior_type=='LearnedPriorLR'].rank_value+0.25, results[results.prior_type=='LearnedPriorLR'].test_acc1.values, color='black', s=15)\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.set_xticks(list(range(1,6)))\n",
    "ax.set_xticklabels([\n",
    "    'Best', \n",
    "    r'$2^{\\mathrm{nd}}\\ \\mathrm{best}$', \n",
    "    r'$3^{\\mathrm{rd}}\\ \\mathrm{best}$', \n",
    "    r'$25^{\\mathrm{th}}\\ \\mathrm{\\%ile}$', \n",
    "    r'$50^{\\mathrm{th}}\\ \\mathrm{\\%ile}$', \n",
    "])\n",
    "ax.legend(loc='lower left', fontsize=6)\n",
    "ax.set_ylabel('Accuracy')\n",
    "fig.tight_layout()\n",
    "plt.savefig('hyperparameter_sensitivity.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl-transfer-learning",
   "language": "python",
   "name": "bdl-transfer-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
