{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(path):\n",
    "    df = pd.read_csv(path, index_col='Unnamed: 0')\n",
    "    return df\n",
    "\n",
    "def get_best_epoch(df, window_size):\n",
    "    val_nll = df.val_nll.values\n",
    "    windowed_nll = [sum(val_nll[index-window_size:index])/window_size \\\n",
    "                      for index in range(window_size, len(val_nll))]\n",
    "    return df.iloc[window_size+np.argmin(windowed_nll)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning'\n",
    "experiments_path = os.path.join(repo_path, 'experiments/HAM10000/8:1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [1001, 2001, 3001]\n",
    "#random_states = [4001, 5001, 6001]\n",
    "prior_scales = np.logspace(0, 9, num=10)\n",
    "lr_0s = np.logspace(-1, -4, num=4)\n",
    "weight_decays = np.append(np.logspace(-2, -6, num=5), 0)\n",
    "window_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_auroc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_nll\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      2\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_prior\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_auroc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_nll\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_prior\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_auroc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_nll\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_prior\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (random_state,) \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(random_states):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Get best model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     best_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "columns = ['random_state', 'method', 'test_auroc', 'test_loss', 'test_nll', \n",
    "           'test_prior', 'train_auroc', 'train_loss', 'train_nll', 'train_prior', \n",
    "           'val_auroc', 'val_loss', 'val_nll', 'val_prior']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for (random_state,) in itertools.product(random_states):\n",
    "    # Get best model\n",
    "    best_row = None\n",
    "    for lr_0, weight_decay in itertools.product(lr_0s, weight_decays):\n",
    "        df_path =  '{}/nonlearned_lr_0={}_n=1000_random_state={}_weight_decay={}.csv'\\\n",
    "        .format(experiments_path, lr_0, random_state, weight_decay)\n",
    "        row = get_best_epoch(get_df(df_path), window_size=window_size)\n",
    "        if best_row is None: best_row = row\n",
    "        if row['val_nll'] < best_row['val_nll']: best_row = row\n",
    "    # Append best_model to df\n",
    "    row = [random_state, 'nonlearned', best_row.test_auroc, best_row.test_loss, \n",
    "           best_row.test_nll, best_row.test_prior, best_row.train_auroc, \n",
    "           best_row.train_loss, best_row.train_nll, best_row.train_prior, \n",
    "           best_row.val_auroc, best_row.val_loss, best_row.val_nll, \n",
    "           best_row.val_prior]\n",
    "    df.loc[df.shape[0]] = row\n",
    "    # Get best model\n",
    "    best_row = None\n",
    "    for lr_0, prior_scale, weight_decay in itertools.product(lr_0s, prior_scales, weight_decays):\n",
    "        df_path =  '{}/learned_lr_0={}_n=1000_prior_scale={}_random_state={}_weight_decay={}.csv'\\\n",
    "        .format(experiments_path, lr_0, prior_scale, random_state, weight_decay)\n",
    "        row = get_best_epoch(get_df(df_path), window_size=window_size)\n",
    "        if best_row is None: best_row = row\n",
    "        if row['val_nll'] < best_row['val_nll']: best_row = row\n",
    "    # Append best_model to df\n",
    "    row = [random_state, 'learned', best_row.test_auroc, best_row.test_loss, \n",
    "           best_row.test_nll, best_row.test_prior, best_row.train_auroc, \n",
    "           best_row.train_loss, best_row.train_nll, best_row.train_prior, \n",
    "           best_row.val_auroc, best_row.val_loss, best_row.val_nll, \n",
    "           best_row.val_prior]\n",
    "    df.loc[df.shape[0]] = row\n",
    "# TODO: If more seeds are added average over seeds\n",
    "df = df.groupby('method').agg(lambda x: list(x))\n",
    "columns = ['test_auroc', 'train_auroc', 'val_auroc']\n",
    "for column in columns:\n",
    "    df['{}_std'.format(column)] = df[column].apply(lambda item: np.std(item))\n",
    "    df[column] = df[column].apply(lambda item: np.mean(item))\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_state</th>\n",
       "      <th>method</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>train_auroc_std</th>\n",
       "      <th>val_auroc</th>\n",
       "      <th>val_auroc_std</th>\n",
       "      <th>test_auroc</th>\n",
       "      <th>test_auroc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1001, 2001, 3001]</td>\n",
       "      <td>learned</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.038258</td>\n",
       "      <td>0.846525</td>\n",
       "      <td>0.022369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1001, 2001, 3001]</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>0.980668</td>\n",
       "      <td>0.026712</td>\n",
       "      <td>0.856886</td>\n",
       "      <td>0.036020</td>\n",
       "      <td>0.849510</td>\n",
       "      <td>0.003192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         random_state      method  train_auroc  train_auroc_std  val_auroc  \\\n",
       "0  [1001, 2001, 3001]     learned     1.000000         0.000000   0.885000   \n",
       "1  [1001, 2001, 3001]  nonlearned     0.980668         0.026712   0.856886   \n",
       "\n",
       "   val_auroc_std  test_auroc  test_auroc_std  \n",
       "0       0.038258    0.846525        0.022369  \n",
       "1       0.036020    0.849510        0.003192  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['random_state', 'method', 'train_auroc', 'train_auroc_std', 'val_auroc', \n",
    "    'val_auroc_std', 'test_auroc', 'test_auroc_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl_2022f_env",
   "language": "python",
   "name": "bdl_2022f_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
