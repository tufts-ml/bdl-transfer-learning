{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(path):\n",
    "    df = pd.read_csv(path, index_col='Unnamed: 0')\n",
    "    return df\n",
    "\n",
    "def get_val_nll(df):\n",
    "    return df.val_or_test_nll.values[-1]\n",
    "\n",
    "def get_val_loss(df):\n",
    "    return df.val_or_test_loss.values[-1]\n",
    "\n",
    "def get_val_acc(df):\n",
    "    return df.val_or_test_acc.values[-1]\n",
    "\n",
    "def get_last_epoch(df):\n",
    "    return df.iloc[-1]\n",
    "\n",
    "def get_nonlearned_hyperparameters(experiments_path, lr_0s, ns, random_states, weight_decays):\n",
    "    columns = ['lr_0', 'n', 'random_state', 'val_acc', 'val_loss', 'val_nll', 'weight_decay']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for n, random_state in itertools.product(ns, random_states):\n",
    "        best_val_loss = np.inf\n",
    "        best_val_nll = np.inf\n",
    "        best_hyperparameters = None\n",
    "        for lr_0, weight_decay in itertools.product(lr_0s, weight_decays):\n",
    "            model_name = 'nonlearned_lr_0={}_n={}_random_state={}_weight_decay={}'\\\n",
    "            .format(lr_0, n, random_state, weight_decay)\n",
    "            path =  '{}/{}.csv'.format(experiments_path, model_name)\n",
    "            val_loss = get_val_loss(get_df(path))\n",
    "            val_nll = get_val_nll(get_df(path))\n",
    "            val_acc = get_val_acc(get_df(path))\n",
    "            #if val_loss < best_val_loss: best_val_loss = val_loss; best_hyperparameters = [lr_0, n, random_state, val_acc, val_loss, val_nll, weight_decay]\n",
    "            if val_nll < best_val_nll: best_val_nll = val_nll; best_hyperparameters = [lr_0, n, random_state, val_acc, val_loss, val_nll, weight_decay]\n",
    "        df.loc[df.shape[0]] = best_hyperparameters\n",
    "    return df\n",
    "\n",
    "def get_adapted_hyperparameters(experiments_path, lr_0s, ns, random_states, weight_decays):\n",
    "    columns = ['lr_0', 'n', 'random_state', 'val_acc', 'val_loss', 'val_nll', 'weight_decay']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for n, random_state in itertools.product(ns, random_states):\n",
    "        best_val_loss = np.inf\n",
    "        best_val_nll = np.inf\n",
    "        best_hyperparameters = None\n",
    "        for lr_0, weight_decay in itertools.product(lr_0s, weight_decays):\n",
    "            model_name = 'adapted_lr_0={}_n={}_random_state={}_weight_decay={}'\\\n",
    "            .format(lr_0, n, random_state, weight_decay)\n",
    "            path =  '{}/{}.csv'.format(experiments_path, model_name)\n",
    "            val_loss = get_val_loss(get_df(path))\n",
    "            val_nll = get_val_nll(get_df(path))\n",
    "            val_acc = get_val_acc(get_df(path))\n",
    "            #if val_loss < best_val_loss: best_val_loss = val_loss; best_hyperparameters = [lr_0, n, random_state, val_acc, val_loss, val_nll, weight_decay]\n",
    "            if val_nll < best_val_nll: best_val_nll = val_nll; best_hyperparameters = [lr_0, n, random_state, val_acc, val_loss, val_nll, weight_decay]\n",
    "        df.loc[df.shape[0]] = best_hyperparameters\n",
    "    return df\n",
    "\n",
    "def get_learned_hyperparameters(experiments_path, lr_0s, ns, prior_scales, random_states, weight_decays):\n",
    "    columns = ['lr_0', 'n', 'prior_scale', 'random_state', 'val_acc', 'val_loss', 'val_nll', 'weight_decay']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for n, prior_scale, random_state in itertools.product(ns, prior_scales, random_states):\n",
    "        best_val_loss = np.inf\n",
    "        best_val_nll = np.inf\n",
    "        best_hyperparameters = None\n",
    "        for lr_0, weight_decay in itertools.product(lr_0s, weight_decays):\n",
    "            model_name = 'learned_lr_0={}_n={}_prior_scale={}_random_state={}_weight_decay={}'\\\n",
    "            .format(lr_0, n, prior_scale, random_state, weight_decay)\n",
    "            path =  '{}/{}.csv'.format(experiments_path, model_name)\n",
    "            val_loss = get_val_loss(get_df(path))\n",
    "            val_acc = get_val_acc(get_df(path))\n",
    "            val_nll = get_val_nll(get_df(path))\n",
    "            #if val_loss < best_val_loss: best_val_loss = val_loss; best_hyperparameters = [lr_0, n, prior_scale, random_state, val_acc, val_loss, val_nll, weight_decay]\n",
    "            if val_nll < best_val_nll: best_val_nll = val_nll; best_hyperparameters = [lr_0, n, prior_scale, random_state, val_acc, val_loss, val_nll, weight_decay]\n",
    "        df.loc[df.shape[0]] = best_hyperparameters\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparameters(experiments_path, lr_0s, ns, prior_scales, prior_type, random_states, weight_decays):\n",
    "    columns = ['lr_0', 'n', 'prior_scale', 'prior_type', 'random_state', 'val_acc', 'weight_decay']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for n, prior_scale, random_state in itertools.product(ns, prior_scales, random_states):\n",
    "        best_val_nll = np.inf\n",
    "        best_hyperparameters = None\n",
    "        for lr_0, weight_decay in itertools.product(lr_0s, weight_decays):\n",
    "            if prior_scale:\n",
    "                model_name = '{}_lr_0={}_n={}_prior_scale={}_random_state={}_weight_decay={}'\\\n",
    "                .format(prior_type, lr_0, n, prior_scale, random_state, weight_decay)\n",
    "            else:\n",
    "                model_name = '{}_lr_0={}_n={}_random_state={}_weight_decay={}'\\\n",
    "                .format(prior_type, lr_0, n, random_state, weight_decay)\n",
    "            path =  '{}/{}.csv'.format(experiments_path, model_name)\n",
    "            val_nll = get_val_nll(get_df(path))\n",
    "            val_acc = get_val_acc(get_df(path))\n",
    "            if val_nll < best_val_nll: best_val_nll = val_nll; best_hyperparameters = [lr_0, n, prior_scale, prior_type, random_state, val_acc, weight_decay]\n",
    "        df.loc[df.shape[0]] = best_hyperparameters\n",
    "    return df\n",
    "\n",
    "def get_best_hyperparameters(experiments_path, lr_0s, ns, prior_scales, prior_type, random_states, weight_decays,add_name=''):\n",
    "    columns = ['lr_0', 'n', 'prior_scale', 'prior_type', 'random_state', 'val_acc', 'weight_decay']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for n, random_state in itertools.product(ns, random_states):\n",
    "        best_val_nll = np.inf\n",
    "        best_hyperparameters = None\n",
    "        for lr_0, prior_scale, weight_decay in itertools.product(lr_0s, prior_scales, weight_decays):\n",
    "            if prior_scale:\n",
    "                model_name = '{}_lr_0={}_n={}_prior_scale={}_random_state={}_weight_decay={}'\\\n",
    "                .format(prior_type, lr_0, n, prior_scale, random_state, weight_decay) + add_name\n",
    "            else:\n",
    "                model_name = '{}_lr_0={}_n={}_random_state={}_weight_decay={}'\\\n",
    "                .format(prior_type, lr_0, n, random_state, weight_decay) + add_name\n",
    "            path =  '{}/{}.csv'.format(experiments_path, model_name)\n",
    "            val_nll = get_val_nll(get_df(path))\n",
    "            val_acc = get_val_acc(get_df(path))\n",
    "            if val_nll < best_val_nll: best_val_nll = val_nll; best_hyperparameters = [lr_0, n, prior_scale, prior_type, random_state, val_acc, weight_decay]\n",
    "        df.loc[df.shape[0]] = best_hyperparameters\n",
    "    return df\n",
    "\n",
    "def get_results(df, experiments_path,add_name=''):\n",
    "    columns = ['n', 'prior_scale', 'prior_type', 'random_state', 'test_acc', 'test_loss', 'test_nll', \n",
    "           'test_prior', 'train_acc', 'train_loss', 'train_nll', 'train_prior']\n",
    "    results = pd.DataFrame(columns=columns)\n",
    "    for row_index, row in df.iterrows():\n",
    "        if row.prior_scale:\n",
    "            model_name = '{}_lr_0={}_n={}_prior_scale={}_random_state={}_weight_decay={}'\\\n",
    "            .format(row.prior_type, row.lr_0, row.n, row.prior_scale, row.random_state, row.weight_decay) + add_name\n",
    "        else:\n",
    "            model_name = '{}_lr_0={}_n={}_random_state={}_weight_decay={}'\\\n",
    "            .format(row.prior_type, row.lr_0, row.n, row.random_state, row.weight_decay) + add_name\n",
    "        path =  '{}/{}.csv'.format(experiments_path, model_name)\n",
    "        last_epoch = get_last_epoch(get_df(path))\n",
    "        results_row = [int(row.n), row.prior_scale, row.prior_type, int(row.random_state), \n",
    "                       last_epoch.val_or_test_acc, last_epoch.val_or_test_loss, \n",
    "                       last_epoch.val_or_test_nll, last_epoch.val_or_test_prior, \n",
    "                       last_epoch.train_acc, last_epoch.train_loss, \n",
    "                       last_epoch.train_nll, last_epoch.train_prior]\n",
    "        results.loc[results.shape[0]] = results_row\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlearned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '../oxpets_dataset'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/tuned_OXPETS'\n",
    "lr_0s = np.logspace(-1, -4, num=4)\n",
    "ns = [3441, 370, 37]\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "random_states = [1001, 2001, 3001]\n",
    "prior_type = 'nonlearned'\n",
    "wandb_project = 'tuned_OXPETS'\n",
    "weight_decays = np.append(np.logspace(-2, -6, num=5), 0)\n",
    "count = -1\n",
    "for lr_0, n, random_state, weight_decay in itertools.product(lr_0s, ns, random_states, weight_decays):\n",
    "    count += 1\n",
    "    model_name = '{}_lr_0={}_n={}_random_state={}_weight_decay={}'\\\n",
    "    .format(prior_type, lr_0, n, random_state, weight_decay)\n",
    "#     print('    \"python ../src/OXPETS_main.py --dataset_path=\\'{}\\' --experiments_path=\\'{}\\' --lr_0={} --model_name=\\'{}\\' --n={} --prior_path=\\'{}\\' --prior_type=\\'{}\\' --random_state={} --tune --wandb --wandb_project=\\'{}\\' --weight_decay={}\"'\\\n",
    "#           .format(dataset_path, experiments_path, lr_0, model_name, n, prior_path, prior_type, random_state, wandb_project, weight_decay))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>prior_scale</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>random_state</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.897898</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.897898</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.911411</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lr_0     n prior_scale  prior_type random_state   val_acc  weight_decay\n",
       "0  0.0100  3441        None  nonlearned         1001  0.897898      0.001000\n",
       "1  0.0100  3441        None  nonlearned         2001  0.897898      0.001000\n",
       "2  0.0100  3441        None  nonlearned         3001  0.911411      0.000001\n",
       "3  0.0100   370        None  nonlearned         1001  0.689189      0.000010\n",
       "4  0.0010   370        None  nonlearned         2001  0.635135      0.000001\n",
       "5  0.0001   370        None  nonlearned         3001  0.554054      0.000000\n",
       "6  0.0010    37        None  nonlearned         1001  0.135135      0.010000\n",
       "7  0.0010    37        None  nonlearned         2001  0.135135      0.010000\n",
       "8  0.0010    37        None  nonlearned         3001  0.162162      0.010000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Find the best hypers for nonlearned\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/tuned_OXPETS'\n",
    "lr_0s = np.logspace(-1, -4, num=4)\n",
    "prior_scales = [None]\n",
    "prior_type = 'nonlearned'\n",
    "ns = [3441, 370, 37]\n",
    "random_states = [1001, 2001, 3001]\n",
    "weight_decays = np.append(np.logspace(-2, -6, num=5), 0)\n",
    "nonlearned_hyperparameters = get_best_hyperparameters(experiments_path, lr_0s, ns, prior_scales, prior_type, random_states, weight_decays)\n",
    "nonlearned_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "####### Make new run commands with the best hypers\n",
    "dataset_path = '../oxpets_dataset'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS'\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "prior_type = 'nonlearned'\n",
    "wandb_project = 'retrained_OXPETS'\n",
    "\n",
    "count = -1\n",
    "for row_index, row in nonlearned_hyperparameters.iterrows():\n",
    "    count += 1\n",
    "    model_name = '{}_lr_0={}_n={}_random_state={}_weight_decay={}'\\\n",
    "    .format(prior_type, row.lr_0, int(row.n), int(row.random_state), row.weight_decay)\n",
    "#     print('    \"python ../src/OXPETS_main.py --dataset_path=\\'{}\\' --experiments_path=\\'{}\\' --lr_0={} --model_name=\\'{}\\' --n={} --prior_path=\\'{}\\' --prior_type=\\'{}\\' --random_state={} --wandb --wandb_project=\\'{}\\' --weight_decay={}\"'\\\n",
    "#           .format(dataset_path, experiments_path, row.lr_0, model_name, int(row.n), prior_path, prior_type, int(row.random_state), wandb_project, row.weight_decay))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>prior_scale</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>random_state</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_prior</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_nll</th>\n",
       "      <th>train_prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.864874</td>\n",
       "      <td>0.555606</td>\n",
       "      <td>0.555606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.866187</td>\n",
       "      <td>0.547540</td>\n",
       "      <td>0.547540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.859838</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.575321</td>\n",
       "      <td>1.720191</td>\n",
       "      <td>1.720191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.537177</td>\n",
       "      <td>1.828269</td>\n",
       "      <td>1.828269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.532070</td>\n",
       "      <td>1.782722</td>\n",
       "      <td>1.782722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.156752</td>\n",
       "      <td>0.156752</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.172697</td>\n",
       "      <td>3.327513</td>\n",
       "      <td>3.327513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.145260</td>\n",
       "      <td>3.398588</td>\n",
       "      <td>3.398588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>nonlearned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.200102</td>\n",
       "      <td>3.250308</td>\n",
       "      <td>3.250308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n prior_scale  prior_type random_state  test_acc  test_loss  test_nll  \\\n",
       "0  3441        None  nonlearned         1001  0.864874   0.555606  0.555606   \n",
       "1  3441        None  nonlearned         2001  0.866187   0.547540  0.547540   \n",
       "2  3441        None  nonlearned         3001  0.859838   0.655502  0.655502   \n",
       "3   370        None  nonlearned         1001  0.575321   1.720191  1.720191   \n",
       "4   370        None  nonlearned         2001  0.537177   1.828269  1.828269   \n",
       "5   370        None  nonlearned         3001  0.532070   1.782722  1.782722   \n",
       "6    37        None  nonlearned         1001  0.172697   3.327513  3.327513   \n",
       "7    37        None  nonlearned         2001  0.145260   3.398588  3.398588   \n",
       "8    37        None  nonlearned         3001  0.200102   3.250308  3.250308   \n",
       "\n",
       "   test_prior  train_acc  train_loss  train_nll  train_prior  \n",
       "0         0.0   1.000000    0.000219   0.000219          0.0  \n",
       "1         0.0   1.000000    0.000212   0.000212          0.0  \n",
       "2         0.0   1.000000    0.000021   0.000021          0.0  \n",
       "3         0.0   1.000000    0.000037   0.000037          0.0  \n",
       "4         0.0   1.000000    0.000633   0.000633          0.0  \n",
       "5         0.0   0.991892    0.156752   0.156752          0.0  \n",
       "6         0.0   1.000000    0.003454   0.003454          0.0  \n",
       "7         0.0   1.000000    0.003515   0.003515          0.0  \n",
       "8         0.0   1.000000    0.003434   0.003434          0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### nonlearned results\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS'\n",
    "results = get_results(nonlearned_hyperparameters, experiments_path)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_prior</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_nll</th>\n",
       "      <th>train_prior</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.172686</td>\n",
       "      <td>3.325470</td>\n",
       "      <td>3.325470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.548189</td>\n",
       "      <td>1.777061</td>\n",
       "      <td>1.777061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.052474</td>\n",
       "      <td>0.052474</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>0.863633</td>\n",
       "      <td>0.586216</td>\n",
       "      <td>0.586216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_acc  test_loss  test_nll  test_prior  train_acc  train_loss  \\\n",
       "n                                                                        \n",
       "37    0.172686   3.325470  3.325470         0.0   1.000000    0.003468   \n",
       "370   0.548189   1.777061  1.777061         0.0   0.997297    0.052474   \n",
       "3441  0.863633   0.586216  0.586216         0.0   1.000000    0.000151   \n",
       "\n",
       "      train_nll  train_prior  \n",
       "n                             \n",
       "37     0.003468          0.0  \n",
       "370    0.052474          0.0  \n",
       "3441   0.000151          0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby(['n']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '../oxpets_dataset'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/tuned_OXPETS'\n",
    "lr_0s = np.logspace(-1, -4, num=4)\n",
    "ns = [3441, 370, 37]\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "random_states = [1001, 2001, 3001]\n",
    "prior_type = 'adapted'\n",
    "wandb_project = 'tuned_OXPETS'\n",
    "weight_decays = np.append(np.logspace(-2, -6, num=5), 0)\n",
    "count = -1\n",
    "for lr_0, n, random_state, weight_decay in itertools.product(lr_0s, ns, random_states, weight_decays):\n",
    "    count += 1\n",
    "    model_name = '{}_lr_0={}_n={}_random_state={}_weight_decay={}'\\\n",
    "    .format(prior_type, lr_0, n, random_state, weight_decay)\n",
    "#     print('    \"python ../src/OXPETS_main.py --dataset_path=\\'{}\\' --experiments_path=\\'{}\\' --lr_0={} --model_name=\\'{}\\' --n={} --prior_path=\\'{}\\' --prior_type=\\'{}\\' --random_state={} --tune --wandb --wandb_project=\\'{}\\' --weight_decay={}\"'\\\n",
    "#           .format(dataset_path, experiments_path, lr_0, model_name, n, prior_path, prior_type, random_state, wandb_project, weight_decay))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>prior_scale</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>random_state</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.896396</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.899399</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.920420</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lr_0     n prior_scale prior_type random_state   val_acc  weight_decay\n",
       "0  0.0100  3441        None    adapted         1001  0.896396      0.001000\n",
       "1  0.0100  3441        None    adapted         2001  0.899399      0.001000\n",
       "2  0.0100  3441        None    adapted         3001  0.920420      0.001000\n",
       "3  0.0100   370        None    adapted         1001  0.702703      0.000010\n",
       "4  0.1000   370        None    adapted         2001  0.540541      0.010000\n",
       "5  0.1000   370        None    adapted         3001  0.675676      0.010000\n",
       "6  0.0001    37        None    adapted         1001  0.135135      0.000010\n",
       "7  0.0001    37        None    adapted         2001  0.135135      0.000001\n",
       "8  0.0001    37        None    adapted         3001  0.162162      0.000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Find the best hypers for nonlearned\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/tuned_OXPETS'\n",
    "lr_0s = np.logspace(-1, -4, num=4)\n",
    "prior_scales = [None]\n",
    "prior_type = 'adapted'\n",
    "ns = [3441, 370, 37]\n",
    "random_states = [1001, 2001, 3001]\n",
    "weight_decays = np.append(np.logspace(-2, -6, num=5), 0)\n",
    "adapted_hyperparameters = get_best_hyperparameters(experiments_path, lr_0s, ns, prior_scales, prior_type, random_states, weight_decays)\n",
    "adapted_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "####### Make new run commands with the best hypers\n",
    "dataset_path = '../oxpets_dataset'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS'\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "prior_type = 'adapted'\n",
    "wandb_project = 'retrained_OXPETS'\n",
    "\n",
    "\n",
    "count = -1\n",
    "for row_index, row in adapted_hyperparameters.iterrows():\n",
    "    count += 1\n",
    "    model_name = '{}_lr_0={}_n={}_random_state={}_weight_decay={}'\\\n",
    "    .format(prior_type, row.lr_0, int(row.n), int(row.random_state), row.weight_decay)\n",
    "#     print('    \"python ../src/OXPETS_main.py --dataset_path=\\'{}\\' --experiments_path=\\'{}\\' --lr_0={} --model_name=\\'{}\\' --n={} --prior_path=\\'{}\\' --prior_type=\\'{}\\' --random_state={} --wandb --wandb_project=\\'{}\\' --weight_decay={}\"'\\\n",
    "#           .format(dataset_path, experiments_path, row.lr_0, model_name, int(row.n), prior_path, prior_type, int(row.random_state), wandb_project, row.weight_decay))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>prior_scale</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>random_state</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_prior</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_nll</th>\n",
       "      <th>train_prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.872254</td>\n",
       "      <td>0.566250</td>\n",
       "      <td>0.534827</td>\n",
       "      <td>0.031423</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031560</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.031423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.863352</td>\n",
       "      <td>0.583711</td>\n",
       "      <td>0.554833</td>\n",
       "      <td>0.028878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029020</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.028878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.864451</td>\n",
       "      <td>0.596398</td>\n",
       "      <td>0.568093</td>\n",
       "      <td>0.028305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.028305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.573260</td>\n",
       "      <td>1.722578</td>\n",
       "      <td>1.722463</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.554725</td>\n",
       "      <td>1.679727</td>\n",
       "      <td>1.673891</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.005836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.567416</td>\n",
       "      <td>1.806014</td>\n",
       "      <td>1.800529</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006123</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.005485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.181212</td>\n",
       "      <td>3.276047</td>\n",
       "      <td>3.276021</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014836</td>\n",
       "      <td>0.014810</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.151471</td>\n",
       "      <td>3.341888</td>\n",
       "      <td>3.341885</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014935</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.207152</td>\n",
       "      <td>3.184841</td>\n",
       "      <td>3.184838</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.015298</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n prior_scale prior_type random_state  test_acc  test_loss  test_nll  \\\n",
       "0  3441        None    adapted         1001  0.872254   0.566250  0.534827   \n",
       "1  3441        None    adapted         2001  0.863352   0.583711  0.554833   \n",
       "2  3441        None    adapted         3001  0.864451   0.596398  0.568093   \n",
       "3   370        None    adapted         1001  0.573260   1.722578  1.722463   \n",
       "4   370        None    adapted         2001  0.554725   1.679727  1.673891   \n",
       "5   370        None    adapted         3001  0.567416   1.806014  1.800529   \n",
       "6    37        None    adapted         1001  0.181212   3.276047  3.276021   \n",
       "7    37        None    adapted         2001  0.151471   3.341888  3.341885   \n",
       "8    37        None    adapted         3001  0.207152   3.184841  3.184838   \n",
       "\n",
       "   test_prior  train_acc  train_loss  train_nll  train_prior  \n",
       "0    0.031423        1.0    0.031560   0.000138     0.031423  \n",
       "1    0.028878        1.0    0.029020   0.000142     0.028878  \n",
       "2    0.028305        1.0    0.028443   0.000138     0.028305  \n",
       "3    0.000115        1.0    0.000151   0.000036     0.000115  \n",
       "4    0.005836        1.0    0.006635   0.000798     0.005836  \n",
       "5    0.005485        1.0    0.006123   0.000638     0.005485  \n",
       "6    0.000026        1.0    0.014836   0.014810     0.000026  \n",
       "7    0.000003        1.0    0.014935   0.014932     0.000003  \n",
       "8    0.000003        1.0    0.015300   0.015298     0.000003  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### nonlearned results\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS'\n",
    "results = get_results(adapted_hyperparameters, experiments_path)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_prior</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_nll</th>\n",
       "      <th>train_prior</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.179945</td>\n",
       "      <td>3.267592</td>\n",
       "      <td>3.267581</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015024</td>\n",
       "      <td>0.015013</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.565134</td>\n",
       "      <td>1.736106</td>\n",
       "      <td>1.732294</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.003812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>0.866686</td>\n",
       "      <td>0.582119</td>\n",
       "      <td>0.552584</td>\n",
       "      <td>0.029535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029674</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.029535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_acc  test_loss  test_nll  test_prior  train_acc  train_loss  \\\n",
       "n                                                                        \n",
       "37    0.179945   3.267592  3.267581    0.000010        1.0    0.015024   \n",
       "370   0.565134   1.736106  1.732294    0.003812        1.0    0.004303   \n",
       "3441  0.866686   0.582119  0.552584    0.029535        1.0    0.029674   \n",
       "\n",
       "      train_nll  train_prior  \n",
       "n                             \n",
       "37     0.015013     0.000010  \n",
       "370    0.000491     0.003812  \n",
       "3441   0.000139     0.029535  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby(['n']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapted corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../oxpets_dataset'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/tuned_OXPETS'\n",
    "lr_0s = np.logspace(-1, -4, num=4)\n",
    "ns = [3441, 370, 37]\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "random_states = [1001, 2001, 3001]\n",
    "prior_type = 'adapted'\n",
    "wandb_project = 'tuned_OXPETS'\n",
    "weight_decays = np.append(np.logspace(-2, -6, num=5), 0)\n",
    "count = -1\n",
    "for lr_0, n, random_state, weight_decay in itertools.product(lr_0s, ns, random_states, weight_decays):\n",
    "    count += 1\n",
    "    model_name = '{}_lr_0={}_n={}_random_state={}_weight_decay={}_corrected'\\\n",
    "    .format(prior_type, lr_0, n, random_state, weight_decay)\n",
    "#     print('    \"python ../src/OXPETS_main.py --dataset_path=\\'{}\\' --experiments_path=\\'{}\\' --lr_0={} --model_name=\\'{}\\' --n={} --prior_path=\\'{}\\' --prior_type=\\'{}\\' --random_state={} --tune --wandb --wandb_project=\\'{}\\' --weight_decay={}\"'\\\n",
    "#           .format(dataset_path, experiments_path, lr_0, model_name, n, prior_path, prior_type, random_state, wandb_project, weight_decay))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>prior_scale</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>random_state</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.902402</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.923423</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lr_0     n prior_scale prior_type random_state   val_acc  weight_decay\n",
       "0  0.0100  3441        None    adapted         1001  0.902402        0.0000\n",
       "1  0.0100  3441        None    adapted         2001  0.905405        0.0010\n",
       "2  0.0100  3441        None    adapted         3001  0.923423        0.0010\n",
       "3  0.0100   370        None    adapted         1001  0.675676        0.0001\n",
       "4  0.0100   370        None    adapted         2001  0.635135        0.0010\n",
       "5  0.0001   370        None    adapted         3001  0.540541        0.0000\n",
       "6  0.1000    37        None    adapted         1001  0.135135        0.0100\n",
       "7  0.1000    37        None    adapted         2001  0.135135        0.0100\n",
       "8  0.1000    37        None    adapted         3001  0.162162        0.0100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Find the best hypers for nonlearned\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/tuned_OXPETS'\n",
    "lr_0s = np.logspace(-1, -4, num=4)\n",
    "prior_scales = [None]\n",
    "prior_type = 'adapted'\n",
    "ns = [3441, 370, 37]\n",
    "random_states = [1001, 2001, 3001]\n",
    "weight_decays = np.append(np.logspace(-2, -6, num=5), 0)\n",
    "adapted_hyperparameters = get_best_hyperparameters(experiments_path, lr_0s, ns, prior_scales, prior_type, random_states, weight_decays,add_name='_corrected')\n",
    "adapted_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [37]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "columns = ['lr_0', 'n', 'random_state', 'val_acc', 'val_loss', 'val_nll', 'weight_decay']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "for n, random_state in itertools.product(ns, random_states):\n",
    "    best_val_loss = np.inf\n",
    "    best_val_nll = np.inf\n",
    "    best_hyperparameters = None\n",
    "    for lr_0, weight_decay in itertools.product(lr_0s, weight_decays):\n",
    "        model_name = 'adapted_lr_0={}_n={}_random_state={}_weight_decay={}_corrected'\\\n",
    "        .format(lr_0, n, random_state, weight_decay)\n",
    "        path =  '{}/{}.csv'.format(experiments_path, model_name)\n",
    "        val_loss = get_val_loss(get_df(path))\n",
    "        val_nll = get_val_nll(get_df(path))\n",
    "        val_acc = get_val_acc(get_df(path))\n",
    "        best_hyperparameters = [lr_0, n, random_state, val_acc, val_loss, val_nll, weight_decay]\n",
    "        #if val_loss < best_val_loss: best_val_loss = val_loss; best_hyperparameters = [lr_0, n, random_state, val_acc, val_loss, val_nll, weight_decay]\n",
    "        #if val_nll < best_val_nll: best_val_nll = val_nll; best_hyperparameters = [lr_0, n, random_state, val_acc, val_loss, val_nll, weight_decay]\n",
    "        df.loc[df.shape[0]] = best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>random_state</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.058874</td>\n",
       "      <td>1.045218</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.103653</td>\n",
       "      <td>1.101044</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.482554</td>\n",
       "      <td>1.479962</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.565403</td>\n",
       "      <td>1.564960</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.599938</td>\n",
       "      <td>1.599892</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.638192</td>\n",
       "      <td>1.638192</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.108044</td>\n",
       "      <td>1.087820</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.273953</td>\n",
       "      <td>1.265679</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.310786</td>\n",
       "      <td>1.309538</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.313955</td>\n",
       "      <td>1.313824</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.314161</td>\n",
       "      <td>1.314148</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.314226</td>\n",
       "      <td>1.314226</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.247717</td>\n",
       "      <td>1.183088</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.222165</td>\n",
       "      <td>1.212545</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.216632</td>\n",
       "      <td>1.215627</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.215845</td>\n",
       "      <td>1.215744</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.216138</td>\n",
       "      <td>1.216128</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.215736</td>\n",
       "      <td>1.215736</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.275734</td>\n",
       "      <td>1.191175</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.200915</td>\n",
       "      <td>1.192081</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.193132</td>\n",
       "      <td>1.192245</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.192282</td>\n",
       "      <td>1.192193</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.192269</td>\n",
       "      <td>1.192261</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.192265</td>\n",
       "      <td>1.192265</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.072047</td>\n",
       "      <td>1.057848</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.092298</td>\n",
       "      <td>1.089736</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.528328</td>\n",
       "      <td>1.525658</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.710526</td>\n",
       "      <td>1.710071</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.624986</td>\n",
       "      <td>1.624938</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.734709</td>\n",
       "      <td>1.734709</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.283537</td>\n",
       "      <td>1.200441</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.210705</td>\n",
       "      <td>1.202022</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.203068</td>\n",
       "      <td>1.202196</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.202290</td>\n",
       "      <td>1.202203</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.202217</td>\n",
       "      <td>1.202208</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.202222</td>\n",
       "      <td>1.202222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.545870</td>\n",
       "      <td>0.531087</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.561511</td>\n",
       "      <td>0.558960</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>1.014575</td>\n",
       "      <td>1.011782</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>1.015785</td>\n",
       "      <td>1.015308</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>1.021630</td>\n",
       "      <td>1.021580</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.968178</td>\n",
       "      <td>0.968178</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.571310</td>\n",
       "      <td>0.551639</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.707384</td>\n",
       "      <td>0.699309</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.754096</td>\n",
       "      <td>0.752871</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.760500</td>\n",
       "      <td>0.760371</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.759591</td>\n",
       "      <td>0.759578</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.762895</td>\n",
       "      <td>0.762895</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.690965</td>\n",
       "      <td>0.627813</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.664229</td>\n",
       "      <td>0.654802</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.658519</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.658552</td>\n",
       "      <td>0.658453</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.657592</td>\n",
       "      <td>0.657582</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.658200</td>\n",
       "      <td>0.658200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.721645</td>\n",
       "      <td>0.638568</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.648051</td>\n",
       "      <td>0.639371</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.640275</td>\n",
       "      <td>0.639403</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.639464</td>\n",
       "      <td>0.639377</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.639429</td>\n",
       "      <td>0.639421</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr_0     n  random_state   val_acc  val_loss   val_nll  weight_decay\n",
       "0   0.1000  37.0        1001.0  0.135135  1.058874  1.045218      0.010000\n",
       "1   0.1000  37.0        1001.0  0.135135  1.103653  1.101044      0.001000\n",
       "2   0.1000  37.0        1001.0  0.135135  1.482554  1.479962      0.000100\n",
       "3   0.1000  37.0        1001.0  0.135135  1.565403  1.564960      0.000010\n",
       "4   0.1000  37.0        1001.0  0.135135  1.599938  1.599892      0.000001\n",
       "5   0.1000  37.0        1001.0  0.135135  1.638192  1.638192      0.000000\n",
       "6   0.0100  37.0        1001.0  0.135135  1.108044  1.087820      0.010000\n",
       "7   0.0100  37.0        1001.0  0.135135  1.273953  1.265679      0.001000\n",
       "8   0.0100  37.0        1001.0  0.135135  1.310786  1.309538      0.000100\n",
       "9   0.0100  37.0        1001.0  0.135135  1.313955  1.313824      0.000010\n",
       "10  0.0100  37.0        1001.0  0.135135  1.314161  1.314148      0.000001\n",
       "11  0.0100  37.0        1001.0  0.135135  1.314226  1.314226      0.000000\n",
       "12  0.0010  37.0        1001.0  0.135135  1.247717  1.183088      0.010000\n",
       "13  0.0010  37.0        1001.0  0.135135  1.222165  1.212545      0.001000\n",
       "14  0.0010  37.0        1001.0  0.135135  1.216632  1.215627      0.000100\n",
       "15  0.0010  37.0        1001.0  0.135135  1.215845  1.215744      0.000010\n",
       "16  0.0010  37.0        1001.0  0.135135  1.216138  1.216128      0.000001\n",
       "17  0.0010  37.0        1001.0  0.135135  1.215736  1.215736      0.000000\n",
       "18  0.0001  37.0        1001.0  0.135135  1.275734  1.191175      0.010000\n",
       "19  0.0001  37.0        1001.0  0.135135  1.200915  1.192081      0.001000\n",
       "20  0.0001  37.0        1001.0  0.135135  1.193132  1.192245      0.000100\n",
       "21  0.0001  37.0        1001.0  0.135135  1.192282  1.192193      0.000010\n",
       "22  0.0001  37.0        1001.0  0.135135  1.192269  1.192261      0.000001\n",
       "23  0.0001  37.0        1001.0  0.135135  1.192265  1.192265      0.000000\n",
       "24  0.1000  37.0        2001.0  0.135135  1.072047  1.057848      0.010000\n",
       "25  0.1000  37.0        2001.0  0.135135  1.092298  1.089736      0.001000\n",
       "26  0.1000  37.0        2001.0  0.135135  1.528328  1.525658      0.000100\n",
       "27  0.1000  37.0        2001.0  0.135135  1.710526  1.710071      0.000010\n",
       "28  0.1000  37.0        2001.0  0.135135  1.624986  1.624938      0.000001\n",
       "29  0.1000  37.0        2001.0  0.135135  1.734709  1.734709      0.000000\n",
       "..     ...   ...           ...       ...       ...       ...           ...\n",
       "42  0.0001  37.0        2001.0  0.135135  1.283537  1.200441      0.010000\n",
       "43  0.0001  37.0        2001.0  0.135135  1.210705  1.202022      0.001000\n",
       "44  0.0001  37.0        2001.0  0.135135  1.203068  1.202196      0.000100\n",
       "45  0.0001  37.0        2001.0  0.135135  1.202290  1.202203      0.000010\n",
       "46  0.0001  37.0        2001.0  0.135135  1.202217  1.202208      0.000001\n",
       "47  0.0001  37.0        2001.0  0.135135  1.202222  1.202222      0.000000\n",
       "48  0.1000  37.0        3001.0  0.162162  0.545870  0.531087      0.010000\n",
       "49  0.1000  37.0        3001.0  0.162162  0.561511  0.558960      0.001000\n",
       "50  0.1000  37.0        3001.0  0.162162  1.014575  1.011782      0.000100\n",
       "51  0.1000  37.0        3001.0  0.162162  1.015785  1.015308      0.000010\n",
       "52  0.1000  37.0        3001.0  0.162162  1.021630  1.021580      0.000001\n",
       "53  0.1000  37.0        3001.0  0.162162  0.968178  0.968178      0.000000\n",
       "54  0.0100  37.0        3001.0  0.162162  0.571310  0.551639      0.010000\n",
       "55  0.0100  37.0        3001.0  0.162162  0.707384  0.699309      0.001000\n",
       "56  0.0100  37.0        3001.0  0.162162  0.754096  0.752871      0.000100\n",
       "57  0.0100  37.0        3001.0  0.162162  0.760500  0.760371      0.000010\n",
       "58  0.0100  37.0        3001.0  0.162162  0.759591  0.759578      0.000001\n",
       "59  0.0100  37.0        3001.0  0.162162  0.762895  0.762895      0.000000\n",
       "60  0.0010  37.0        3001.0  0.162162  0.690965  0.627813      0.010000\n",
       "61  0.0010  37.0        3001.0  0.162162  0.664229  0.654802      0.001000\n",
       "62  0.0010  37.0        3001.0  0.162162  0.658519  0.657534      0.000100\n",
       "63  0.0010  37.0        3001.0  0.162162  0.658552  0.658453      0.000010\n",
       "64  0.0010  37.0        3001.0  0.162162  0.657592  0.657582      0.000001\n",
       "65  0.0010  37.0        3001.0  0.162162  0.658200  0.658200      0.000000\n",
       "66  0.0001  37.0        3001.0  0.162162  0.721645  0.638568      0.010000\n",
       "67  0.0001  37.0        3001.0  0.162162  0.648051  0.639371      0.001000\n",
       "68  0.0001  37.0        3001.0  0.162162  0.640275  0.639403      0.000100\n",
       "69  0.0001  37.0        3001.0  0.162162  0.639464  0.639377      0.000010\n",
       "70  0.0001  37.0        3001.0  0.162162  0.639429  0.639421      0.000001\n",
       "71  0.0001  37.0        3001.0  0.162162  0.639419  0.639419      0.000000\n",
       "\n",
       "[72 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.01 --model_name='adapted_lr_0=0.01_n=3441_random_state=1001_weight_decay=0.0_corrected' --n=3441 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='adapted' --random_state=1001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.0\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.01 --model_name='adapted_lr_0=0.01_n=3441_random_state=2001_weight_decay=0.001_corrected' --n=3441 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='adapted' --random_state=2001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.001\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.01 --model_name='adapted_lr_0=0.01_n=3441_random_state=3001_weight_decay=0.001_corrected' --n=3441 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='adapted' --random_state=3001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.001\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.01 --model_name='adapted_lr_0=0.01_n=370_random_state=1001_weight_decay=0.0001_corrected' --n=370 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='adapted' --random_state=1001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.0001\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.01 --model_name='adapted_lr_0=0.01_n=370_random_state=2001_weight_decay=0.001_corrected' --n=370 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='adapted' --random_state=2001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.001\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.0001 --model_name='adapted_lr_0=0.0001_n=370_random_state=3001_weight_decay=0.0_corrected' --n=370 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='adapted' --random_state=3001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.0\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.1 --model_name='adapted_lr_0=0.1_n=37_random_state=1001_weight_decay=0.01_corrected' --n=37 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='adapted' --random_state=1001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.01\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.1 --model_name='adapted_lr_0=0.1_n=37_random_state=2001_weight_decay=0.01_corrected' --n=37 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='adapted' --random_state=2001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.01\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.1 --model_name='adapted_lr_0=0.1_n=37_random_state=3001_weight_decay=0.01_corrected' --n=37 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='adapted' --random_state=3001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.01\"\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "####### Make new run commands with the best hypers\n",
    "dataset_path = '../oxpets_dataset'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS'\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "prior_type = 'adapted'\n",
    "wandb_project = 'retrained_OXPETS'\n",
    "\n",
    "\n",
    "count = -1\n",
    "for row_index, row in adapted_hyperparameters.iterrows():\n",
    "    count += 1\n",
    "    model_name = '{}_lr_0={}_n={}_random_state={}_weight_decay={}_corrected'\\\n",
    "    .format(prior_type, row.lr_0, int(row.n), int(row.random_state), row.weight_decay)\n",
    "    print('    \"python ../src/OXPETS_main.py --dataset_path=\\'{}\\' --experiments_path=\\'{}\\' --lr_0={} --model_name=\\'{}\\' --n={} --prior_path=\\'{}\\' --prior_type=\\'{}\\' --random_state={} --wandb --wandb_project=\\'{}\\' --weight_decay={}\"'\\\n",
    "          .format(dataset_path, experiments_path, row.lr_0, model_name, int(row.n), prior_path, prior_type, int(row.random_state), wandb_project, row.weight_decay))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>prior_scale</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>random_state</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_prior</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_nll</th>\n",
       "      <th>train_prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.854081</td>\n",
       "      <td>0.659033</td>\n",
       "      <td>0.659033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.867176</td>\n",
       "      <td>0.579947</td>\n",
       "      <td>0.544586</td>\n",
       "      <td>0.035361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035516</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.035361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3441</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.869879</td>\n",
       "      <td>0.557198</td>\n",
       "      <td>0.523561</td>\n",
       "      <td>0.033637</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033801</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.033637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.577203</td>\n",
       "      <td>1.711945</td>\n",
       "      <td>1.710178</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.001767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.554506</td>\n",
       "      <td>1.878757</td>\n",
       "      <td>1.866707</td>\n",
       "      <td>0.012050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.012050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>370</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.533362</td>\n",
       "      <td>1.778537</td>\n",
       "      <td>1.778537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.140283</td>\n",
       "      <td>0.140283</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.070150</td>\n",
       "      <td>3.627272</td>\n",
       "      <td>3.612332</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015848</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.014940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.053620</td>\n",
       "      <td>3.703639</td>\n",
       "      <td>3.687906</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016719</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.015733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>adapted</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.084853</td>\n",
       "      <td>3.576377</td>\n",
       "      <td>3.560486</td>\n",
       "      <td>0.015891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016958</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.015891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n prior_scale prior_type random_state  test_acc  test_loss  test_nll  \\\n",
       "0  3441        None    adapted         1001  0.854081   0.659033  0.659033   \n",
       "1  3441        None    adapted         2001  0.867176   0.579947  0.544586   \n",
       "2  3441        None    adapted         3001  0.869879   0.557198  0.523561   \n",
       "3   370        None    adapted         1001  0.577203   1.711945  1.710178   \n",
       "4   370        None    adapted         2001  0.554506   1.878757  1.866707   \n",
       "5   370        None    adapted         3001  0.533362   1.778537  1.778537   \n",
       "6    37        None    adapted         1001  0.070150   3.627272  3.612332   \n",
       "7    37        None    adapted         2001  0.053620   3.703639  3.687906   \n",
       "8    37        None    adapted         3001  0.084853   3.576377  3.560486   \n",
       "\n",
       "   test_prior  train_acc  train_loss  train_nll  train_prior  \n",
       "0    0.000000   1.000000    0.000024   0.000024     0.000000  \n",
       "1    0.035361   1.000000    0.035516   0.000155     0.035361  \n",
       "2    0.033637   1.000000    0.033801   0.000165     0.033637  \n",
       "3    0.001767   1.000000    0.001815   0.000048     0.001767  \n",
       "4    0.012050   1.000000    0.012261   0.000211     0.012050  \n",
       "5    0.000000   0.994595    0.140283   0.140283     0.000000  \n",
       "6    0.014940   1.000000    0.015848   0.000908     0.014940  \n",
       "7    0.015733   1.000000    0.016719   0.000986     0.015733  \n",
       "8    0.015891   1.000000    0.016958   0.001067     0.015891  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### nonlearned results\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS'\n",
    "results = get_results(adapted_hyperparameters, experiments_path,add_name='_corrected')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>n</th>\n",
       "      <th>37</th>\n",
       "      <th>370</th>\n",
       "      <th>3441</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.069541</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.863712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.053620</td>\n",
       "      <td>0.533362</td>\n",
       "      <td>0.854081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.084853</td>\n",
       "      <td>0.577203</td>\n",
       "      <td>0.869879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "n         37        370       3441\n",
       "mean  0.069541  0.555024  0.863712\n",
       "min   0.053620  0.533362  0.854081\n",
       "max   0.084853  0.577203  0.869879"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([results.groupby(['n']).mean()['test_acc'],results.groupby(['n']).min()['test_acc'],results.groupby(['n']).max()['test_acc']],index=['mean','min','max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '../oxpets_dataset'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/tuned_OXPETS'\n",
    "lr_0s = np.logspace(-1, -4, num=4)\n",
    "ns = [3441, 370, 37]\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "#prior_scales = np.logspace(0, 9, num=10)\n",
    "prior_scales = [1e0]\n",
    "random_states = [1001, 2001, 3001]\n",
    "weight_decays = np.append(np.logspace(-2, -6, num=5), 0)\n",
    "wandb_project = 'tuned_OXPETS'\n",
    "prior_type = 'learned'\n",
    "count = -1\n",
    "\n",
    "for lr_0, n, random_state, weight_decay, prior_scale in itertools.product(lr_0s, ns, random_states, weight_decays,prior_scales):\n",
    "    count += 1\n",
    "    model_name = '{}_lr_0={}_n={}_prior_scale={}_random_state={}_weight_decay={}'\\\n",
    "    .format(prior_type, lr_0, n, prior_scale, random_state, weight_decay)\n",
    "#     print('    \"python ../src/OXPETS_main.py --dataset_path=\\'{}\\' --experiments_path=\\'{}\\' --lr_0={} --model_name=\\'{}\\' --n={} --prior_path=\\'{}\\' --prior_type=\\'{}\\' --prior_scale={} --random_state={} --tune --wandb --wandb_project=\\'{}\\' --weight_decay={}\"'\\\n",
    "#           .format(dataset_path, experiments_path, lr_0, model_name, n, prior_path, prior_type, prior_scale, random_state, wandb_project, weight_decay))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>prior_scale</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>random_state</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3441</td>\n",
       "      <td>100</td>\n",
       "      <td>learned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.917417</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3441</td>\n",
       "      <td>10</td>\n",
       "      <td>learned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3441</td>\n",
       "      <td>1000</td>\n",
       "      <td>learned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.912913</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>370</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>learned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.10</td>\n",
       "      <td>370</td>\n",
       "      <td>1000</td>\n",
       "      <td>learned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>learned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>37</td>\n",
       "      <td>10000</td>\n",
       "      <td>learned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>37</td>\n",
       "      <td>10000</td>\n",
       "      <td>learned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01</td>\n",
       "      <td>37</td>\n",
       "      <td>10000</td>\n",
       "      <td>learned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lr_0     n prior_scale prior_type random_state   val_acc  weight_decay\n",
       "0  0.01  3441         100    learned         1001  0.917417      0.001000\n",
       "1  0.01  3441          10    learned         2001  0.905405      0.000001\n",
       "2  0.01  3441        1000    learned         3001  0.912913      0.000010\n",
       "3  0.01   370       1e+09    learned         1001  0.689189      0.000010\n",
       "4  0.10   370        1000    learned         2001  0.594595      0.000010\n",
       "5  0.10   370           1    learned         3001  0.648649      0.000010\n",
       "6  0.01    37       10000    learned         1001  0.135135      0.010000\n",
       "7  0.01    37       10000    learned         2001  0.135135      0.010000\n",
       "8  0.01    37       10000    learned         3001  0.162162      0.010000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Find the best hypers for nonlearned\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/tuned_OXPETS'\n",
    "lr_0s = np.logspace(-1, -4, num=4)\n",
    "#prior_scales = [1e0]\n",
    "prior_scales = [1e0,10,100,1e3,1e4,1e5,1e6,1e7,1e8,1e9]\n",
    "prior_type = 'learned'\n",
    "ns = [3441, 370, 37]\n",
    "random_states = [1001, 2001, 3001]\n",
    "weight_decays = np.append(np.logspace(-2, -6, num=5), 0)\n",
    "learned_hyperparameters = get_best_hyperparameters(experiments_path, lr_0s, ns, prior_scales, prior_type, random_states, weight_decays)\n",
    "learned_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.01 --model_name='learned_lr_0=0.01_n=3441_prior_scale=100_random_state=1001_weight_decay=0.001' --n=3441 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='learned' --prior_scale=1.0 --random_state=1001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.001\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.01 --model_name='learned_lr_0=0.01_n=3441_prior_scale=10_random_state=2001_weight_decay=1e-06' --n=3441 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='learned' --prior_scale=1.0 --random_state=2001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=1e-06\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.01 --model_name='learned_lr_0=0.01_n=3441_prior_scale=1000.0_random_state=3001_weight_decay=1e-05' --n=3441 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='learned' --prior_scale=1.0 --random_state=3001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=1e-05\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.01 --model_name='learned_lr_0=0.01_n=370_prior_scale=1000000000.0_random_state=1001_weight_decay=1e-05' --n=370 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='learned' --prior_scale=1.0 --random_state=1001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=1e-05\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.1 --model_name='learned_lr_0=0.1_n=370_prior_scale=1000.0_random_state=2001_weight_decay=1e-05' --n=370 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='learned' --prior_scale=1.0 --random_state=2001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=1e-05\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.1 --model_name='learned_lr_0=0.1_n=370_prior_scale=1.0_random_state=3001_weight_decay=1e-05' --n=370 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='learned' --prior_scale=1.0 --random_state=3001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=1e-05\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.01 --model_name='learned_lr_0=0.01_n=37_prior_scale=10000.0_random_state=1001_weight_decay=0.01' --n=37 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='learned' --prior_scale=1.0 --random_state=1001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.01\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.01 --model_name='learned_lr_0=0.01_n=37_prior_scale=10000.0_random_state=2001_weight_decay=0.01' --n=37 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='learned' --prior_scale=1.0 --random_state=2001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.01\"\n",
      "    \"python ../src/OXPETS_main.py --dataset_path='../oxpets_dataset' --experiments_path='/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS' --lr_0=0.01 --model_name='learned_lr_0=0.01_n=37_prior_scale=10000.0_random_state=3001_weight_decay=0.01' --n=37 --prior_path='/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior' --prior_type='learned' --prior_scale=1.0 --random_state=3001 --wandb --wandb_project='retrained_OXPETS' --weight_decay=0.01\"\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "####### Make new run commands with the best hypers\n",
    "dataset_path = '../oxpets_dataset'\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS'\n",
    "prior_path = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "prior_type = 'learned'\n",
    "wandb_project = 'retrained_OXPETS'\n",
    "\n",
    "count = -1\n",
    "for row_index, row in learned_hyperparameters.iterrows():\n",
    "    count += 1\n",
    "    model_name = '{}_lr_0={}_n={}_prior_scale={}_random_state={}_weight_decay={}'\\\n",
    "    .format(prior_type, row.lr_0, int(row.n), row.prior_scale, int(row.random_state), row.weight_decay)   \n",
    "    print('    \"python ../src/OXPETS_main.py --dataset_path=\\'{}\\' --experiments_path=\\'{}\\' --lr_0={} --model_name=\\'{}\\' --n={} --prior_path=\\'{}\\' --prior_type=\\'{}\\' --prior_scale={} --random_state={} --wandb --wandb_project=\\'{}\\' --weight_decay={}\"'\\\n",
    "           .format(dataset_path, experiments_path, row.lr_0, model_name, int(row.n), prior_path, prior_type, prior_scale, int(row.random_state), wandb_project, row.weight_decay))\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>prior_scale</th>\n",
       "      <th>prior_type</th>\n",
       "      <th>random_state</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_prior</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_nll</th>\n",
       "      <th>train_prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3441</td>\n",
       "      <td>100</td>\n",
       "      <td>learned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.859576</td>\n",
       "      <td>-1484.726880</td>\n",
       "      <td>0.559501</td>\n",
       "      <td>1485.286377</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1583.700607</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>1583.701050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3441</td>\n",
       "      <td>10</td>\n",
       "      <td>learned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.867458</td>\n",
       "      <td>-1484.936099</td>\n",
       "      <td>0.529720</td>\n",
       "      <td>1485.465820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1583.892207</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>1583.892456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3441</td>\n",
       "      <td>1000</td>\n",
       "      <td>learned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.863576</td>\n",
       "      <td>-1484.912000</td>\n",
       "      <td>0.553703</td>\n",
       "      <td>1485.465698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1583.892081</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>1583.892334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>learned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.556153</td>\n",
       "      <td>-1483.753706</td>\n",
       "      <td>1.735783</td>\n",
       "      <td>1485.489502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-14730.434570</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>14730.435547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>370</td>\n",
       "      <td>1000</td>\n",
       "      <td>learned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.565806</td>\n",
       "      <td>-1483.884221</td>\n",
       "      <td>1.606492</td>\n",
       "      <td>1485.490723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-14730.446289</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>14730.447266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>learned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.586414</td>\n",
       "      <td>-1483.831912</td>\n",
       "      <td>1.658925</td>\n",
       "      <td>1485.490845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-14730.447266</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>14730.448242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37</td>\n",
       "      <td>10000</td>\n",
       "      <td>learned</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.025467</td>\n",
       "      <td>-1481.574507</td>\n",
       "      <td>3.818809</td>\n",
       "      <td>1485.393311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-147294.640625</td>\n",
       "      <td>0.178541</td>\n",
       "      <td>147294.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>10000</td>\n",
       "      <td>learned</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.037370</td>\n",
       "      <td>-1481.639218</td>\n",
       "      <td>3.753354</td>\n",
       "      <td>1485.392578</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>-147294.500000</td>\n",
       "      <td>0.253638</td>\n",
       "      <td>147294.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37</td>\n",
       "      <td>10000</td>\n",
       "      <td>learned</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.033337</td>\n",
       "      <td>-1481.358470</td>\n",
       "      <td>4.034843</td>\n",
       "      <td>1485.393311</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>-147294.218750</td>\n",
       "      <td>0.595780</td>\n",
       "      <td>147294.812500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n prior_scale prior_type random_state  test_acc    test_loss  test_nll  \\\n",
       "0  3441         100    learned         1001  0.859576 -1484.726880  0.559501   \n",
       "1  3441          10    learned         2001  0.867458 -1484.936099  0.529720   \n",
       "2  3441        1000    learned         3001  0.863576 -1484.912000  0.553703   \n",
       "3   370       1e+09    learned         1001  0.556153 -1483.753706  1.735783   \n",
       "4   370        1000    learned         2001  0.565806 -1483.884221  1.606492   \n",
       "5   370           1    learned         3001  0.586414 -1483.831912  1.658925   \n",
       "6    37       10000    learned         1001  0.025467 -1481.574507  3.818809   \n",
       "7    37       10000    learned         2001  0.037370 -1481.639218  3.753354   \n",
       "8    37       10000    learned         3001  0.033337 -1481.358470  4.034843   \n",
       "\n",
       "    test_prior  train_acc     train_loss  train_nll    train_prior  \n",
       "0  1485.286377   1.000000   -1583.700607   0.000442    1583.701050  \n",
       "1  1485.465820   1.000000   -1583.892207   0.000247    1583.892456  \n",
       "2  1485.465698   1.000000   -1583.892081   0.000244    1583.892334  \n",
       "3  1485.489502   1.000000  -14730.434570   0.000877   14730.435547  \n",
       "4  1485.490723   1.000000  -14730.446289   0.000922   14730.447266  \n",
       "5  1485.490845   1.000000  -14730.447266   0.000848   14730.448242  \n",
       "6  1485.393311   1.000000 -147294.640625   0.178541  147294.812500  \n",
       "7  1485.392578   0.918919 -147294.500000   0.253638  147294.750000  \n",
       "8  1485.393311   0.810811 -147294.218750   0.595780  147294.812500  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### nonlearned results\n",
    "experiments_path = '/cluster/tufts/hugheslab/eharve06/bdl-transfer-learning/experiments/retrained_OXPETS'\n",
    "results = get_results(learned_hyperparameters, experiments_path)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>n</th>\n",
       "      <th>37</th>\n",
       "      <th>370</th>\n",
       "      <th>3441</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.032058</td>\n",
       "      <td>0.569458</td>\n",
       "      <td>0.863536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.025467</td>\n",
       "      <td>0.556153</td>\n",
       "      <td>0.859576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.037370</td>\n",
       "      <td>0.586414</td>\n",
       "      <td>0.867458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "n         37        370       3441\n",
       "mean  0.032058  0.569458  0.863536\n",
       "min   0.025467  0.556153  0.859576\n",
       "max   0.037370  0.586414  0.867458"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([results.groupby(['n']).mean()['test_acc'],results.groupby(['n']).min()['test_acc'],results.groupby(['n']).max()['test_acc']],index=['mean','min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06, 1.e+07,\n",
       "       1.e+08, 1.e+09])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(0, 9, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
